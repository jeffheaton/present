{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/present/blob/master/WUSTL/CABI-Demand/demand_multivariate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDMHtf7ccifv"
   },
   "source": [
    "# Multivariate Projection\n",
    "\n",
    "First map Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJPIlxl8hAg5",
    "outputId": "da3c8e11-df72-4910-f7ad-37563c16d92a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Note: using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yN7476ZB3MTi"
   },
   "source": [
    "Load the three data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WEfyt5ShSeA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "PATH = \"/content/drive/MyDrive/projects/demand/\"\n",
    "\n",
    "df_sales = pd.read_csv(\"https://data.heatonresearch.com/wustl/CABI/demand-forecast/sales_train.csv\", parse_dates=['date'])\n",
    "df_items = pd.read_csv(\"https://data.heatonresearch.com/wustl/CABI/demand-forecast/items.csv\")\n",
    "df_resturant = pd.read_csv(\"https://data.heatonresearch.com/wustl/CABI/demand-forecast/resturants.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__jGovBB3QUR"
   },
   "source": [
    "Utility function to create sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kz2MmH3Cloi7"
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, window=1, lag=1, dropnan=True):\n",
    "    cols, names = list(), list()\n",
    "    # Input sequence (t-n, ... t-1)\n",
    "    for i in range(window, 0, -1):\n",
    "        cols.append(data.shift(i))\n",
    "        names += [('%s(t-%d)' % (col, i)) for col in data.columns]\n",
    "    # Current timestep (t=0)\n",
    "    cols.append(data)\n",
    "    names += [('%s(t)' % (col)) for col in data.columns]\n",
    "    # Target timestep (t=lag)\n",
    "    cols.append(data.shift(-lag))\n",
    "    names += [('%s(t+%d)' % (col, lag)) for col in data.columns]\n",
    "    # Put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # Drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmL154wv3YIR"
   },
   "source": [
    "Join the items and sales tables so that we can look up the store id for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3S7LIIqG3ihU",
    "outputId": "cd58ce73-16e1-498b-9e3b-9d63d2185b88"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c075177a-9c07-44be-8711-3f452d04f5e7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>store</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-10-14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-12-26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c075177a-9c07-44be-8711-3f452d04f5e7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c075177a-9c07-44be-8711-3f452d04f5e7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c075177a-9c07-44be-8711-3f452d04f5e7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   item  store       date  sales\n",
       "0     1      4 2020-12-01    1.0\n",
       "1     1      4 2021-10-14    1.0\n",
       "2     2      4 2020-04-30    1.0\n",
       "3     2      4 2020-06-09    1.0\n",
       "4     2      4 2020-12-26    1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items2 = df_items[['id','store_id']]\n",
    "df_train = df_sales.merge(df_items2,left_on='item_id',right_on='id')\n",
    "df_train[['date','item_id','item_count','store_id']]\n",
    "\n",
    "df_train = df_train.sort_values('date').groupby(['item_id', 'store_id', 'date'], as_index=False)\n",
    "df_train = df_train.agg({'item_count':['mean']})\n",
    "df_train.columns = ['item', 'store', 'date', 'sales']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "juImdYgR-rNi",
    "outputId": "3384356f-f73d-43f2-fef2-083840a41182"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ac894c9c-370b-4819-88e5-5f0a7eb7fa99\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>store</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>dow</th>\n",
       "      <th>doy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-10-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-12-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15636</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-08-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15637</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15638</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-11-20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15639</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15640</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15641 rows × 6 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac894c9c-370b-4819-88e5-5f0a7eb7fa99')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ac894c9c-370b-4819-88e5-5f0a7eb7fa99 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ac894c9c-370b-4819-88e5-5f0a7eb7fa99');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       item  store       date  sales  dow  doy\n",
       "0         1      4 2020-12-01    1.0    1  336\n",
       "1         1      4 2021-10-14    1.0    3  287\n",
       "2         2      4 2020-04-30    1.0    3  121\n",
       "3         2      4 2020-06-09    1.0    1  161\n",
       "4         2      4 2020-12-26    1.0    5  361\n",
       "...     ...    ...        ...    ...  ...  ...\n",
       "15636   100      2 2021-08-10    1.0    1  222\n",
       "15637   100      2 2021-11-08    1.0    0  312\n",
       "15638   100      2 2021-11-20    1.0    5  324\n",
       "15639   100      2 2021-12-03    1.0    4  337\n",
       "15640   100      2 2021-12-11    1.0    5  345\n",
       "\n",
       "[15641 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['dow'] = df_train['date'].dt.dayofweek\n",
    "df_train['doy'] = df_train['date'].dt.dayofyear\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSslf7_x3f_r"
   },
   "source": [
    "Build the sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "ZKf1jppTlvi4",
    "outputId": "54079c24-0231-47df-a22d-b885f2a9da85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3271d6de-ca18-4467-a011-13b24202e51d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item(t-29)</th>\n",
       "      <th>store(t-29)</th>\n",
       "      <th>sales(t-29)</th>\n",
       "      <th>dow(t-29)</th>\n",
       "      <th>doy(t-29)</th>\n",
       "      <th>item(t-28)</th>\n",
       "      <th>store(t-28)</th>\n",
       "      <th>sales(t-28)</th>\n",
       "      <th>dow(t-28)</th>\n",
       "      <th>doy(t-28)</th>\n",
       "      <th>...</th>\n",
       "      <th>item(t)</th>\n",
       "      <th>store(t)</th>\n",
       "      <th>sales(t)</th>\n",
       "      <th>dow(t)</th>\n",
       "      <th>doy(t)</th>\n",
       "      <th>item(t+30)</th>\n",
       "      <th>store(t+30)</th>\n",
       "      <th>sales(t+30)</th>\n",
       "      <th>dow(t+30)</th>\n",
       "      <th>doy(t+30)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3271d6de-ca18-4467-a011-13b24202e51d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3271d6de-ca18-4467-a011-13b24202e51d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3271d6de-ca18-4467-a011-13b24202e51d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    item(t-29)  store(t-29)  sales(t-29)  dow(t-29)  doy(t-29)  item(t-28)  \\\n",
       "29         1.0          4.0          1.0        1.0      336.0         1.0   \n",
       "30         1.0          4.0          1.0        3.0      287.0         2.0   \n",
       "31         2.0          4.0          1.0        3.0      121.0         2.0   \n",
       "32         2.0          4.0          1.0        1.0      161.0         2.0   \n",
       "33         2.0          4.0          1.0        5.0      361.0         2.0   \n",
       "\n",
       "    store(t-28)  sales(t-28)  dow(t-28)  doy(t-28)  ...  item(t)  store(t)  \\\n",
       "29          4.0          1.0        3.0      287.0  ...        3         1   \n",
       "30          4.0          1.0        3.0      121.0  ...        3         1   \n",
       "31          4.0          1.0        1.0      161.0  ...        3         1   \n",
       "32          4.0          1.0        5.0      361.0  ...        3         1   \n",
       "33          4.0          1.0        4.0      218.0  ...        3         1   \n",
       "\n",
       "    sales(t)  dow(t)  doy(t)  item(t+30)  store(t+30)  sales(t+30)  dow(t+30)  \\\n",
       "29       3.0       5      32         3.0          1.0          3.0        3.0   \n",
       "30       1.0       6      33         3.0          1.0          1.0        4.0   \n",
       "31       1.0       0      34         3.0          1.0          2.0        5.0   \n",
       "32       2.0       2      36         3.0          1.0          1.0        6.0   \n",
       "33       1.0       3      37         3.0          1.0          1.0        0.0   \n",
       "\n",
       "    doy(t+30)  \n",
       "29       65.0  \n",
       "30       66.0  \n",
       "31       67.0  \n",
       "32       68.0  \n",
       "33       69.0  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 29\n",
    "future_span = 30\n",
    "series = series_to_supervised(df_train.drop('date', axis=1), window=window, lag=future_span)\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMBAkJvR3nce"
   },
   "source": [
    "Remove sequences that did not have enough data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6D8BDtu-DWy"
   },
   "outputs": [],
   "source": [
    "# Remove edge cases, where there were not enough values to complete a series\n",
    "last_item = 'item(t-%d)' % window\n",
    "last_store = 'store(t-%d)' % window\n",
    "last_dow = 'dow(t-%d)' % window\n",
    "last_doy = 'doy(t-%d)' % window\n",
    "series = series[(series['store(t)'] == series[last_store])]\n",
    "series = series[(series['item(t)'] == series[last_item])]\n",
    "#series = series[(series['dow(t)'] == series[last_dow])]\n",
    "#series = series[(series['doy(t)'] == series[last_doy])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4quQLgwg3xfM"
   },
   "source": [
    "We will predict with sales, and our engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRhDirsoZ4dZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "def drop_column(df, col):\n",
    "  columns_to_drop = [('%s(t+%d)' % (col, future_span))]\n",
    "  for i in range(window, 0, -1):\n",
    "      columns_to_drop += [('%s(t-%d)' % (col, i))]\n",
    "  df.drop(columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "  df.drop([f\"{col}(t)\"], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "def cat_seq(df, col):\n",
    "  return to_categorical(df[col].values)\n",
    "\n",
    "# Label\n",
    "labels_col = 'sales(t+%d)' % future_span\n",
    "labels = series[labels_col]\n",
    "series.drop(labels_col, axis=1, inplace=True)\n",
    "series.drop('item(t+%d)' % future_span, axis=1, inplace=True)\n",
    "series.drop('store(t+%d)' % future_span, axis=1, inplace=True)\n",
    "series.drop('dow(t+%d)' % future_span, axis=1, inplace=True)\n",
    "series.drop('doy(t+%d)' % future_span, axis=1, inplace=True)\n",
    "\n",
    "# Get sales sequences\n",
    "series2 = series.copy()\n",
    "drop_column(series2, \"item\")\n",
    "drop_column(series2, \"store\")\n",
    "drop_column(series2, \"dow\")\n",
    "drop_column(series2, \"doy\")\n",
    "sales_series = series2.values\n",
    "\n",
    "# Day of week as a categorical\n",
    "series2 = series.copy()\n",
    "drop_column(series2, \"item\")\n",
    "drop_column(series2, \"store\")\n",
    "drop_column(series2, \"doy\")\n",
    "drop_column(series2, \"sales\")\n",
    "dow_series = series2.values\n",
    "\n",
    "# Get item sequences\n",
    "series2 = series.copy()\n",
    "drop_column(series2, \"item\")\n",
    "drop_column(series2, \"store\")\n",
    "drop_column(series2, \"dow\")\n",
    "drop_column(series2, \"sales\")\n",
    "doy_series = series2.values\n",
    "\n",
    "# Day of year\n",
    "t1 = sales_series.reshape(sales_series.shape + (1,))\n",
    "t2 = dow_series.reshape(dow_series.shape + (1,)) \n",
    "t3 = doy_series.reshape(doy_series.shape + (1,))\n",
    "x = np.concatenate([t1,t2,t3],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "woBI1ns6CBK1",
    "outputId": "60796692-0eba-4a74-f283-a036b40ca825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15641, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dow_series = cat_seq(df_train, 'dow')\n",
    "dow_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "lDBNmItkC7hB",
    "outputId": "28afc9a7-d593-4067-d15b-602ac0c659e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e80dd9f4-3a88-456f-aab0-dd292d029554\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item(t-29)</th>\n",
       "      <th>store(t-29)</th>\n",
       "      <th>sales(t-29)</th>\n",
       "      <th>dow(t-29)</th>\n",
       "      <th>doy(t-29)</th>\n",
       "      <th>item(t-28)</th>\n",
       "      <th>store(t-28)</th>\n",
       "      <th>sales(t-28)</th>\n",
       "      <th>dow(t-28)</th>\n",
       "      <th>doy(t-28)</th>\n",
       "      <th>...</th>\n",
       "      <th>item(t-1)</th>\n",
       "      <th>store(t-1)</th>\n",
       "      <th>sales(t-1)</th>\n",
       "      <th>dow(t-1)</th>\n",
       "      <th>doy(t-1)</th>\n",
       "      <th>item(t)</th>\n",
       "      <th>store(t)</th>\n",
       "      <th>sales(t)</th>\n",
       "      <th>dow(t)</th>\n",
       "      <th>doy(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15606</th>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15607</th>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15608</th>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15609</th>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15610</th>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13813 rows × 150 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e80dd9f4-3a88-456f-aab0-dd292d029554')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e80dd9f4-3a88-456f-aab0-dd292d029554 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e80dd9f4-3a88-456f-aab0-dd292d029554');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       item(t-29)  store(t-29)  sales(t-29)  dow(t-29)  doy(t-29)  item(t-28)  \\\n",
       "35            3.0          1.0          4.0        2.0        1.0         3.0   \n",
       "36            3.0          1.0          1.0        3.0        2.0         3.0   \n",
       "37            3.0          1.0          3.0        4.0        3.0         3.0   \n",
       "38            3.0          1.0          3.0        5.0        4.0         3.0   \n",
       "39            3.0          1.0          2.0        0.0        6.0         3.0   \n",
       "...           ...          ...          ...        ...        ...         ...   \n",
       "15606        97.0          4.0          1.0        4.0      148.0        97.0   \n",
       "15607        97.0          4.0          1.0        6.0      157.0        97.0   \n",
       "15608        97.0          4.0          2.0        1.0      159.0        97.0   \n",
       "15609        97.0          4.0          1.0        2.0      174.0        97.0   \n",
       "15610        97.0          4.0          1.0        4.0      176.0        97.0   \n",
       "\n",
       "       store(t-28)  sales(t-28)  dow(t-28)  doy(t-28)  ...  item(t-1)  \\\n",
       "35             1.0          1.0        3.0        2.0  ...        3.0   \n",
       "36             1.0          3.0        4.0        3.0  ...        3.0   \n",
       "37             1.0          3.0        5.0        4.0  ...        3.0   \n",
       "38             1.0          2.0        0.0        6.0  ...        3.0   \n",
       "39             1.0          1.0        1.0        7.0  ...        3.0   \n",
       "...            ...          ...        ...        ...  ...        ...   \n",
       "15606          4.0          1.0        6.0      157.0  ...       97.0   \n",
       "15607          4.0          2.0        1.0      159.0  ...       97.0   \n",
       "15608          4.0          1.0        2.0      174.0  ...       97.0   \n",
       "15609          4.0          1.0        4.0      176.0  ...       97.0   \n",
       "15610          4.0          1.0        1.0      180.0  ...       97.0   \n",
       "\n",
       "       store(t-1)  sales(t-1)  dow(t-1)  doy(t-1)  item(t)  store(t)  \\\n",
       "35            1.0         3.0       4.0      38.0        3         1   \n",
       "36            1.0         1.0       5.0      39.0        3         1   \n",
       "37            1.0         1.0       6.0      40.0        3         1   \n",
       "38            1.0         3.0       0.0      41.0        3         1   \n",
       "39            1.0         1.0       1.0      42.0        3         1   \n",
       "...           ...         ...       ...       ...      ...       ...   \n",
       "15606         4.0         1.0       4.0     344.0       97         4   \n",
       "15607         4.0         1.0       1.0     348.0       97         4   \n",
       "15608         4.0         1.0       6.0     353.0       97         4   \n",
       "15609         4.0         1.0       2.0     356.0       97         4   \n",
       "15610         4.0         1.0       1.0     362.0       97         4   \n",
       "\n",
       "       sales(t)  dow(t)  doy(t)  \n",
       "35          1.0       5      39  \n",
       "36          1.0       6      40  \n",
       "37          3.0       0      41  \n",
       "38          1.0       1      42  \n",
       "39          2.0       2      43  \n",
       "...         ...     ...     ...  \n",
       "15606       1.0       1     348  \n",
       "15607       1.0       6     353  \n",
       "15608       1.0       2     356  \n",
       "15609       1.0       1     362  \n",
       "15610       1.0       4     365  \n",
       "\n",
       "[13813 rows x 150 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0gn1hXDk4jY",
    "outputId": "980c015c-cc52-4fa2-cf99-bbb2528f4fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13813, 30, 1)\n",
      "(13813, 30, 1)\n",
      "(13813, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "print(t1.shape)\n",
    "print(t2.shape)\n",
    "print(t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mrMep9homxN"
   },
   "outputs": [],
   "source": [
    "#store_series = to_categorical(series['store(t)'].values)\n",
    "#store_series.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLrgz7RK33f1"
   },
   "source": [
    "Extract the predictors (x sequences) and the label (future prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eS7mDtENnrcq",
    "outputId": "cb90cd26-fbda-4fa7-8ca1-e91f59252740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape (8287, 30, 3)\n",
      "Validation set shape (5526, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(x, labels.values, test_size=0.4, random_state=0)\n",
    "print('Train set shape', X_train.shape)\n",
    "print('Validation set shape', X_valid.shape)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ip9va59y3_MR"
   },
   "source": [
    "Final preparation for the x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iBXBGPXzw-D",
    "outputId": "824325e2-c95c-42f8-e451-06fb8fa67b5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape (8287, 30, 3)\n",
      "Validation set shape (5526, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Train set shape', X_train.shape)\n",
    "print('Validation set shape', X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IazoyOgL4D5T"
   },
   "source": [
    "Construct the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSX-MNvjz81I",
    "outputId": "6cc129b8-bd15-485b-c17b-6444d5951281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 23, 64)            1600      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 5, 64)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 320)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                16050     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,701\n",
      "Trainable params: 17,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Flatten, Dropout\n",
    "import keras\n",
    "\n",
    "epochs = 500\n",
    "batch = 256\n",
    "lr = 0.0003\n",
    "adam = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=8, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer=adam)\n",
    "model.summary()\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "#model.add(Dense(1))\n",
    "#model.compile(loss='mse', optimizer=adam)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_StxCza4IRx"
   },
   "source": [
    "Fit the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5KiECgn1P4s",
    "outputId": "e79368fd-ffec-4509-bed4-7da0c0c28bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "259/259 - 4s - loss: 836.5165 - val_loss: 297.8695 - 4s/epoch - 16ms/step\n",
      "Epoch 2/500\n",
      "259/259 - 1s - loss: 322.0128 - val_loss: 203.7074 - 798ms/epoch - 3ms/step\n",
      "Epoch 3/500\n",
      "259/259 - 1s - loss: 265.6661 - val_loss: 168.8148 - 800ms/epoch - 3ms/step\n",
      "Epoch 4/500\n",
      "259/259 - 1s - loss: 244.9824 - val_loss: 169.5669 - 780ms/epoch - 3ms/step\n",
      "Epoch 5/500\n",
      "259/259 - 1s - loss: 233.4389 - val_loss: 177.0822 - 784ms/epoch - 3ms/step\n",
      "Epoch 6/500\n",
      "259/259 - 1s - loss: 214.3590 - val_loss: 143.1815 - 762ms/epoch - 3ms/step\n",
      "Epoch 7/500\n",
      "259/259 - 1s - loss: 211.3273 - val_loss: 155.2563 - 761ms/epoch - 3ms/step\n",
      "Epoch 8/500\n",
      "259/259 - 1s - loss: 212.6535 - val_loss: 135.1019 - 767ms/epoch - 3ms/step\n",
      "Epoch 9/500\n",
      "259/259 - 1s - loss: 210.0567 - val_loss: 133.0762 - 795ms/epoch - 3ms/step\n",
      "Epoch 10/500\n",
      "259/259 - 1s - loss: 207.3924 - val_loss: 141.5475 - 768ms/epoch - 3ms/step\n",
      "Epoch 11/500\n",
      "259/259 - 1s - loss: 204.0821 - val_loss: 137.4507 - 758ms/epoch - 3ms/step\n",
      "Epoch 12/500\n",
      "259/259 - 1s - loss: 203.3337 - val_loss: 127.0948 - 764ms/epoch - 3ms/step\n",
      "Epoch 13/500\n",
      "259/259 - 1s - loss: 212.7521 - val_loss: 129.1105 - 766ms/epoch - 3ms/step\n",
      "Epoch 14/500\n",
      "259/259 - 1s - loss: 196.3525 - val_loss: 125.0847 - 768ms/epoch - 3ms/step\n",
      "Epoch 15/500\n",
      "259/259 - 1s - loss: 197.1012 - val_loss: 120.4082 - 768ms/epoch - 3ms/step\n",
      "Epoch 16/500\n",
      "259/259 - 1s - loss: 191.3039 - val_loss: 121.5622 - 767ms/epoch - 3ms/step\n",
      "Epoch 17/500\n",
      "259/259 - 1s - loss: 196.6027 - val_loss: 153.1010 - 763ms/epoch - 3ms/step\n",
      "Epoch 18/500\n",
      "259/259 - 1s - loss: 190.0275 - val_loss: 129.6413 - 764ms/epoch - 3ms/step\n",
      "Epoch 19/500\n",
      "259/259 - 1s - loss: 191.3564 - val_loss: 122.5581 - 772ms/epoch - 3ms/step\n",
      "Epoch 20/500\n",
      "259/259 - 1s - loss: 188.6027 - val_loss: 120.8363 - 762ms/epoch - 3ms/step\n",
      "Epoch 21/500\n",
      "259/259 - 1s - loss: 192.8283 - val_loss: 145.2633 - 770ms/epoch - 3ms/step\n",
      "Epoch 22/500\n",
      "259/259 - 1s - loss: 189.4942 - val_loss: 126.6278 - 807ms/epoch - 3ms/step\n",
      "Epoch 23/500\n",
      "259/259 - 1s - loss: 183.6621 - val_loss: 117.8884 - 800ms/epoch - 3ms/step\n",
      "Epoch 24/500\n",
      "259/259 - 1s - loss: 182.8420 - val_loss: 128.6258 - 793ms/epoch - 3ms/step\n",
      "Epoch 25/500\n",
      "259/259 - 1s - loss: 183.3492 - val_loss: 118.9431 - 760ms/epoch - 3ms/step\n",
      "Epoch 26/500\n",
      "259/259 - 1s - loss: 179.9000 - val_loss: 120.7703 - 780ms/epoch - 3ms/step\n",
      "Epoch 27/500\n",
      "259/259 - 1s - loss: 181.9960 - val_loss: 119.0502 - 765ms/epoch - 3ms/step\n",
      "Epoch 28/500\n",
      "259/259 - 1s - loss: 175.0740 - val_loss: 132.9471 - 767ms/epoch - 3ms/step\n",
      "Epoch 29/500\n",
      "259/259 - 1s - loss: 186.5445 - val_loss: 124.7086 - 758ms/epoch - 3ms/step\n",
      "Epoch 30/500\n",
      "259/259 - 1s - loss: 183.2764 - val_loss: 119.6209 - 760ms/epoch - 3ms/step\n",
      "Epoch 31/500\n",
      "259/259 - 1s - loss: 175.3568 - val_loss: 139.5299 - 762ms/epoch - 3ms/step\n",
      "Epoch 32/500\n",
      "259/259 - 1s - loss: 180.0730 - val_loss: 115.4934 - 763ms/epoch - 3ms/step\n",
      "Epoch 33/500\n",
      "259/259 - 1s - loss: 183.1964 - val_loss: 117.1958 - 760ms/epoch - 3ms/step\n",
      "Epoch 34/500\n",
      "259/259 - 1s - loss: 182.3613 - val_loss: 116.4566 - 770ms/epoch - 3ms/step\n",
      "Epoch 35/500\n",
      "259/259 - 1s - loss: 180.6908 - val_loss: 114.5581 - 768ms/epoch - 3ms/step\n",
      "Epoch 36/500\n",
      "259/259 - 1s - loss: 180.8674 - val_loss: 115.0547 - 759ms/epoch - 3ms/step\n",
      "Epoch 37/500\n",
      "259/259 - 1s - loss: 181.6277 - val_loss: 115.9838 - 774ms/epoch - 3ms/step\n",
      "Epoch 38/500\n",
      "259/259 - 1s - loss: 172.6665 - val_loss: 115.8807 - 767ms/epoch - 3ms/step\n",
      "Epoch 39/500\n",
      "259/259 - 1s - loss: 181.1666 - val_loss: 117.9349 - 762ms/epoch - 3ms/step\n",
      "Epoch 40/500\n",
      "259/259 - 1s - loss: 176.6186 - val_loss: 132.4773 - 761ms/epoch - 3ms/step\n",
      "Epoch 41/500\n",
      "259/259 - 1s - loss: 175.2420 - val_loss: 116.2343 - 780ms/epoch - 3ms/step\n",
      "Epoch 42/500\n",
      "259/259 - 1s - loss: 178.6555 - val_loss: 112.7341 - 766ms/epoch - 3ms/step\n",
      "Epoch 43/500\n",
      "259/259 - 1s - loss: 173.6577 - val_loss: 121.3351 - 764ms/epoch - 3ms/step\n",
      "Epoch 44/500\n",
      "259/259 - 1s - loss: 173.4921 - val_loss: 114.2290 - 758ms/epoch - 3ms/step\n",
      "Epoch 45/500\n",
      "259/259 - 1s - loss: 182.1019 - val_loss: 110.7321 - 770ms/epoch - 3ms/step\n",
      "Epoch 46/500\n",
      "259/259 - 1s - loss: 173.7617 - val_loss: 118.5209 - 763ms/epoch - 3ms/step\n",
      "Epoch 47/500\n",
      "259/259 - 1s - loss: 169.6653 - val_loss: 116.6821 - 760ms/epoch - 3ms/step\n",
      "Epoch 48/500\n",
      "259/259 - 1s - loss: 170.2811 - val_loss: 113.9820 - 773ms/epoch - 3ms/step\n",
      "Epoch 49/500\n",
      "259/259 - 1s - loss: 169.9585 - val_loss: 112.9727 - 767ms/epoch - 3ms/step\n",
      "Epoch 50/500\n",
      "259/259 - 1s - loss: 173.6886 - val_loss: 113.8746 - 773ms/epoch - 3ms/step\n",
      "Epoch 51/500\n",
      "259/259 - 1s - loss: 172.5173 - val_loss: 114.8029 - 774ms/epoch - 3ms/step\n",
      "Epoch 52/500\n",
      "259/259 - 1s - loss: 169.9992 - val_loss: 123.1289 - 760ms/epoch - 3ms/step\n",
      "Epoch 53/500\n",
      "259/259 - 1s - loss: 174.6437 - val_loss: 117.8265 - 769ms/epoch - 3ms/step\n",
      "Epoch 54/500\n",
      "259/259 - 1s - loss: 172.1160 - val_loss: 117.0902 - 768ms/epoch - 3ms/step\n",
      "Epoch 55/500\n",
      "259/259 - 1s - loss: 169.2660 - val_loss: 122.8258 - 785ms/epoch - 3ms/step\n",
      "Epoch 56/500\n",
      "259/259 - 1s - loss: 169.8110 - val_loss: 132.7759 - 768ms/epoch - 3ms/step\n",
      "Epoch 57/500\n",
      "259/259 - 1s - loss: 166.2466 - val_loss: 108.7062 - 766ms/epoch - 3ms/step\n",
      "Epoch 58/500\n",
      "259/259 - 1s - loss: 170.6786 - val_loss: 131.5383 - 764ms/epoch - 3ms/step\n",
      "Epoch 59/500\n",
      "259/259 - 1s - loss: 169.6791 - val_loss: 129.8142 - 760ms/epoch - 3ms/step\n",
      "Epoch 60/500\n",
      "259/259 - 1s - loss: 166.6787 - val_loss: 121.1910 - 758ms/epoch - 3ms/step\n",
      "Epoch 61/500\n",
      "259/259 - 1s - loss: 162.4305 - val_loss: 122.6394 - 757ms/epoch - 3ms/step\n",
      "Epoch 62/500\n",
      "259/259 - 1s - loss: 165.7882 - val_loss: 113.1421 - 762ms/epoch - 3ms/step\n",
      "Epoch 63/500\n",
      "259/259 - 1s - loss: 168.8347 - val_loss: 109.2758 - 793ms/epoch - 3ms/step\n",
      "Epoch 64/500\n",
      "259/259 - 1s - loss: 171.5254 - val_loss: 107.6270 - 767ms/epoch - 3ms/step\n",
      "Epoch 65/500\n",
      "259/259 - 1s - loss: 162.4755 - val_loss: 107.9168 - 764ms/epoch - 3ms/step\n",
      "Epoch 66/500\n",
      "259/259 - 1s - loss: 168.3995 - val_loss: 109.4770 - 768ms/epoch - 3ms/step\n",
      "Epoch 67/500\n",
      "259/259 - 1s - loss: 167.5813 - val_loss: 112.5660 - 760ms/epoch - 3ms/step\n",
      "Epoch 68/500\n",
      "259/259 - 1s - loss: 161.1156 - val_loss: 108.4869 - 761ms/epoch - 3ms/step\n",
      "Epoch 69/500\n",
      "259/259 - 1s - loss: 162.8697 - val_loss: 119.2303 - 761ms/epoch - 3ms/step\n",
      "Epoch 70/500\n",
      "259/259 - 1s - loss: 163.8017 - val_loss: 113.1643 - 785ms/epoch - 3ms/step\n",
      "Epoch 71/500\n",
      "259/259 - 1s - loss: 165.7178 - val_loss: 113.4254 - 767ms/epoch - 3ms/step\n",
      "Epoch 72/500\n",
      "259/259 - 1s - loss: 165.4008 - val_loss: 108.6125 - 766ms/epoch - 3ms/step\n",
      "Epoch 73/500\n",
      "259/259 - 1s - loss: 157.5011 - val_loss: 123.8697 - 758ms/epoch - 3ms/step\n",
      "Epoch 74/500\n",
      "259/259 - 1s - loss: 162.7432 - val_loss: 114.8990 - 763ms/epoch - 3ms/step\n",
      "Epoch 75/500\n",
      "259/259 - 1s - loss: 163.2306 - val_loss: 107.0869 - 766ms/epoch - 3ms/step\n",
      "Epoch 76/500\n",
      "259/259 - 1s - loss: 163.3965 - val_loss: 107.0081 - 762ms/epoch - 3ms/step\n",
      "Epoch 77/500\n",
      "259/259 - 1s - loss: 160.5103 - val_loss: 109.3329 - 769ms/epoch - 3ms/step\n",
      "Epoch 78/500\n",
      "259/259 - 1s - loss: 162.0696 - val_loss: 129.1902 - 772ms/epoch - 3ms/step\n",
      "Epoch 79/500\n",
      "259/259 - 1s - loss: 159.2344 - val_loss: 117.9335 - 778ms/epoch - 3ms/step\n",
      "Epoch 80/500\n",
      "259/259 - 1s - loss: 159.2230 - val_loss: 128.0598 - 771ms/epoch - 3ms/step\n",
      "Epoch 81/500\n",
      "259/259 - 1s - loss: 150.0866 - val_loss: 123.5051 - 764ms/epoch - 3ms/step\n",
      "Epoch 82/500\n",
      "259/259 - 1s - loss: 155.8734 - val_loss: 115.2266 - 763ms/epoch - 3ms/step\n",
      "Epoch 83/500\n",
      "259/259 - 1s - loss: 157.9812 - val_loss: 103.5722 - 760ms/epoch - 3ms/step\n",
      "Epoch 84/500\n",
      "259/259 - 1s - loss: 154.2184 - val_loss: 106.5586 - 785ms/epoch - 3ms/step\n",
      "Epoch 85/500\n",
      "259/259 - 1s - loss: 154.5223 - val_loss: 102.5487 - 763ms/epoch - 3ms/step\n",
      "Epoch 86/500\n",
      "259/259 - 1s - loss: 151.0813 - val_loss: 106.2179 - 761ms/epoch - 3ms/step\n",
      "Epoch 87/500\n",
      "259/259 - 1s - loss: 157.6347 - val_loss: 106.9953 - 761ms/epoch - 3ms/step\n",
      "Epoch 88/500\n",
      "259/259 - 1s - loss: 156.1145 - val_loss: 99.8584 - 760ms/epoch - 3ms/step\n",
      "Epoch 89/500\n",
      "259/259 - 1s - loss: 146.9025 - val_loss: 107.9941 - 763ms/epoch - 3ms/step\n",
      "Epoch 90/500\n",
      "259/259 - 1s - loss: 157.5469 - val_loss: 100.8354 - 759ms/epoch - 3ms/step\n",
      "Epoch 91/500\n",
      "259/259 - 1s - loss: 152.9762 - val_loss: 103.8565 - 757ms/epoch - 3ms/step\n",
      "Epoch 92/500\n",
      "259/259 - 1s - loss: 151.5971 - val_loss: 101.0630 - 761ms/epoch - 3ms/step\n",
      "Epoch 93/500\n",
      "259/259 - 1s - loss: 149.6823 - val_loss: 111.1363 - 776ms/epoch - 3ms/step\n",
      "Epoch 94/500\n",
      "259/259 - 1s - loss: 146.6954 - val_loss: 101.6608 - 765ms/epoch - 3ms/step\n",
      "Epoch 95/500\n",
      "259/259 - 1s - loss: 146.0550 - val_loss: 100.5358 - 770ms/epoch - 3ms/step\n",
      "Epoch 96/500\n",
      "259/259 - 1s - loss: 142.1176 - val_loss: 127.6093 - 760ms/epoch - 3ms/step\n",
      "Epoch 97/500\n",
      "259/259 - 1s - loss: 151.0730 - val_loss: 121.9178 - 757ms/epoch - 3ms/step\n",
      "Epoch 98/500\n",
      "259/259 - 1s - loss: 151.4755 - val_loss: 113.8115 - 763ms/epoch - 3ms/step\n",
      "Epoch 99/500\n",
      "259/259 - 1s - loss: 148.5957 - val_loss: 100.0659 - 784ms/epoch - 3ms/step\n",
      "Epoch 100/500\n",
      "259/259 - 1s - loss: 147.8015 - val_loss: 107.0448 - 763ms/epoch - 3ms/step\n",
      "Epoch 101/500\n",
      "259/259 - 1s - loss: 145.7970 - val_loss: 100.4886 - 760ms/epoch - 3ms/step\n",
      "Epoch 102/500\n",
      "259/259 - 1s - loss: 150.6356 - val_loss: 99.8086 - 762ms/epoch - 3ms/step\n",
      "Epoch 103/500\n",
      "259/259 - 1s - loss: 147.4132 - val_loss: 106.0319 - 759ms/epoch - 3ms/step\n",
      "Epoch 104/500\n",
      "259/259 - 1s - loss: 143.0432 - val_loss: 100.3923 - 772ms/epoch - 3ms/step\n",
      "Epoch 105/500\n",
      "259/259 - 1s - loss: 149.6108 - val_loss: 107.9238 - 756ms/epoch - 3ms/step\n",
      "Epoch 106/500\n",
      "259/259 - 1s - loss: 151.4623 - val_loss: 112.5066 - 764ms/epoch - 3ms/step\n",
      "Epoch 107/500\n",
      "259/259 - 1s - loss: 148.7349 - val_loss: 97.9251 - 772ms/epoch - 3ms/step\n",
      "Epoch 108/500\n",
      "259/259 - 1s - loss: 147.0811 - val_loss: 107.6851 - 772ms/epoch - 3ms/step\n",
      "Epoch 109/500\n",
      "259/259 - 1s - loss: 138.3856 - val_loss: 108.2108 - 756ms/epoch - 3ms/step\n",
      "Epoch 110/500\n",
      "259/259 - 1s - loss: 145.7898 - val_loss: 102.4790 - 771ms/epoch - 3ms/step\n",
      "Epoch 111/500\n",
      "259/259 - 1s - loss: 143.9613 - val_loss: 104.7207 - 755ms/epoch - 3ms/step\n",
      "Epoch 112/500\n",
      "259/259 - 1s - loss: 134.4899 - val_loss: 107.7385 - 761ms/epoch - 3ms/step\n",
      "Epoch 113/500\n",
      "259/259 - 1s - loss: 141.0156 - val_loss: 93.4035 - 766ms/epoch - 3ms/step\n",
      "Epoch 114/500\n",
      "259/259 - 1s - loss: 131.9241 - val_loss: 104.3570 - 780ms/epoch - 3ms/step\n",
      "Epoch 115/500\n",
      "259/259 - 1s - loss: 140.1383 - val_loss: 94.7598 - 764ms/epoch - 3ms/step\n",
      "Epoch 116/500\n",
      "259/259 - 1s - loss: 143.8792 - val_loss: 96.6274 - 762ms/epoch - 3ms/step\n",
      "Epoch 117/500\n",
      "259/259 - 1s - loss: 137.6612 - val_loss: 100.3350 - 764ms/epoch - 3ms/step\n",
      "Epoch 118/500\n",
      "259/259 - 1s - loss: 139.9249 - val_loss: 122.2713 - 764ms/epoch - 3ms/step\n",
      "Epoch 119/500\n",
      "259/259 - 1s - loss: 145.5142 - val_loss: 97.0029 - 759ms/epoch - 3ms/step\n",
      "Epoch 120/500\n",
      "259/259 - 1s - loss: 135.0395 - val_loss: 100.8186 - 765ms/epoch - 3ms/step\n",
      "Epoch 121/500\n",
      "259/259 - 1s - loss: 138.3966 - val_loss: 95.2315 - 764ms/epoch - 3ms/step\n",
      "Epoch 122/500\n",
      "259/259 - 1s - loss: 137.1679 - val_loss: 106.4934 - 774ms/epoch - 3ms/step\n",
      "Epoch 123/500\n",
      "259/259 - 1s - loss: 137.7544 - val_loss: 91.4565 - 769ms/epoch - 3ms/step\n",
      "Epoch 124/500\n",
      "259/259 - 1s - loss: 130.8448 - val_loss: 97.7666 - 767ms/epoch - 3ms/step\n",
      "Epoch 125/500\n",
      "259/259 - 1s - loss: 144.7319 - val_loss: 119.3462 - 757ms/epoch - 3ms/step\n",
      "Epoch 126/500\n",
      "259/259 - 1s - loss: 129.5241 - val_loss: 99.0035 - 758ms/epoch - 3ms/step\n",
      "Epoch 127/500\n",
      "259/259 - 1s - loss: 134.3656 - val_loss: 94.2590 - 760ms/epoch - 3ms/step\n",
      "Epoch 128/500\n",
      "259/259 - 1s - loss: 134.2455 - val_loss: 95.8179 - 764ms/epoch - 3ms/step\n",
      "Epoch 129/500\n",
      "259/259 - 1s - loss: 133.8776 - val_loss: 96.8864 - 787ms/epoch - 3ms/step\n",
      "Epoch 130/500\n",
      "259/259 - 1s - loss: 132.4817 - val_loss: 95.7673 - 767ms/epoch - 3ms/step\n",
      "Epoch 131/500\n",
      "259/259 - 1s - loss: 133.0261 - val_loss: 90.0180 - 767ms/epoch - 3ms/step\n",
      "Epoch 132/500\n",
      "259/259 - 1s - loss: 127.6916 - val_loss: 98.5797 - 764ms/epoch - 3ms/step\n",
      "Epoch 133/500\n",
      "259/259 - 1s - loss: 133.4945 - val_loss: 86.1791 - 767ms/epoch - 3ms/step\n",
      "Epoch 134/500\n",
      "259/259 - 1s - loss: 131.1750 - val_loss: 96.4901 - 762ms/epoch - 3ms/step\n",
      "Epoch 135/500\n",
      "259/259 - 1s - loss: 123.9250 - val_loss: 94.0560 - 766ms/epoch - 3ms/step\n",
      "Epoch 136/500\n",
      "259/259 - 1s - loss: 130.0957 - val_loss: 94.6872 - 776ms/epoch - 3ms/step\n",
      "Epoch 137/500\n",
      "259/259 - 1s - loss: 131.7152 - val_loss: 101.3000 - 761ms/epoch - 3ms/step\n",
      "Epoch 138/500\n",
      "259/259 - 1s - loss: 132.0541 - val_loss: 100.1690 - 764ms/epoch - 3ms/step\n",
      "Epoch 139/500\n",
      "259/259 - 1s - loss: 123.5829 - val_loss: 97.9180 - 772ms/epoch - 3ms/step\n",
      "Epoch 140/500\n",
      "259/259 - 1s - loss: 136.0916 - val_loss: 89.2267 - 776ms/epoch - 3ms/step\n",
      "Epoch 141/500\n",
      "259/259 - 1s - loss: 129.4686 - val_loss: 97.2362 - 763ms/epoch - 3ms/step\n",
      "Epoch 142/500\n",
      "259/259 - 1s - loss: 122.5931 - val_loss: 88.3108 - 763ms/epoch - 3ms/step\n",
      "Epoch 143/500\n",
      "259/259 - 1s - loss: 130.9321 - val_loss: 84.9804 - 765ms/epoch - 3ms/step\n",
      "Epoch 144/500\n",
      "259/259 - 1s - loss: 129.1450 - val_loss: 94.3172 - 798ms/epoch - 3ms/step\n",
      "Epoch 145/500\n",
      "259/259 - 1s - loss: 127.9065 - val_loss: 101.1883 - 770ms/epoch - 3ms/step\n",
      "Epoch 146/500\n",
      "259/259 - 1s - loss: 137.1861 - val_loss: 90.1822 - 762ms/epoch - 3ms/step\n",
      "Epoch 147/500\n",
      "259/259 - 1s - loss: 129.2800 - val_loss: 103.0211 - 768ms/epoch - 3ms/step\n",
      "Epoch 148/500\n",
      "259/259 - 1s - loss: 128.6663 - val_loss: 87.2091 - 768ms/epoch - 3ms/step\n",
      "Epoch 149/500\n",
      "259/259 - 1s - loss: 129.8858 - val_loss: 94.0791 - 764ms/epoch - 3ms/step\n",
      "Epoch 150/500\n",
      "259/259 - 1s - loss: 131.8550 - val_loss: 87.9969 - 764ms/epoch - 3ms/step\n",
      "Epoch 151/500\n",
      "259/259 - 1s - loss: 126.5185 - val_loss: 97.4999 - 763ms/epoch - 3ms/step\n",
      "Epoch 152/500\n",
      "259/259 - 1s - loss: 123.3484 - val_loss: 111.1141 - 775ms/epoch - 3ms/step\n",
      "Epoch 153/500\n",
      "259/259 - 1s - loss: 130.6461 - val_loss: 85.8913 - 764ms/epoch - 3ms/step\n",
      "Epoch 154/500\n",
      "259/259 - 1s - loss: 128.7645 - val_loss: 84.2185 - 771ms/epoch - 3ms/step\n",
      "Epoch 155/500\n",
      "259/259 - 1s - loss: 122.7351 - val_loss: 92.4617 - 770ms/epoch - 3ms/step\n",
      "Epoch 156/500\n",
      "259/259 - 1s - loss: 126.3515 - val_loss: 87.3541 - 772ms/epoch - 3ms/step\n",
      "Epoch 157/500\n",
      "259/259 - 1s - loss: 126.2743 - val_loss: 85.7855 - 761ms/epoch - 3ms/step\n",
      "Epoch 158/500\n",
      "259/259 - 1s - loss: 133.1106 - val_loss: 89.3886 - 760ms/epoch - 3ms/step\n",
      "Epoch 159/500\n",
      "259/259 - 1s - loss: 125.7048 - val_loss: 105.6927 - 756ms/epoch - 3ms/step\n",
      "Epoch 160/500\n",
      "259/259 - 1s - loss: 125.3030 - val_loss: 103.2444 - 782ms/epoch - 3ms/step\n",
      "Epoch 161/500\n",
      "259/259 - 1s - loss: 124.5395 - val_loss: 89.2488 - 760ms/epoch - 3ms/step\n",
      "Epoch 162/500\n",
      "259/259 - 1s - loss: 127.4363 - val_loss: 82.7049 - 765ms/epoch - 3ms/step\n",
      "Epoch 163/500\n",
      "259/259 - 1s - loss: 123.8439 - val_loss: 88.5687 - 759ms/epoch - 3ms/step\n",
      "Epoch 164/500\n",
      "259/259 - 1s - loss: 127.4536 - val_loss: 81.8185 - 759ms/epoch - 3ms/step\n",
      "Epoch 165/500\n",
      "259/259 - 1s - loss: 126.2118 - val_loss: 92.2524 - 758ms/epoch - 3ms/step\n",
      "Epoch 166/500\n",
      "259/259 - 1s - loss: 123.7379 - val_loss: 93.7715 - 766ms/epoch - 3ms/step\n",
      "Epoch 167/500\n",
      "259/259 - 1s - loss: 122.2830 - val_loss: 85.8507 - 774ms/epoch - 3ms/step\n",
      "Epoch 168/500\n",
      "259/259 - 1s - loss: 127.5048 - val_loss: 80.4512 - 774ms/epoch - 3ms/step\n",
      "Epoch 169/500\n",
      "259/259 - 1s - loss: 126.6674 - val_loss: 89.9993 - 758ms/epoch - 3ms/step\n",
      "Epoch 170/500\n",
      "259/259 - 1s - loss: 125.3342 - val_loss: 82.0246 - 763ms/epoch - 3ms/step\n",
      "Epoch 171/500\n",
      "259/259 - 1s - loss: 122.9138 - val_loss: 79.6664 - 766ms/epoch - 3ms/step\n",
      "Epoch 172/500\n",
      "259/259 - 1s - loss: 123.1858 - val_loss: 87.2138 - 765ms/epoch - 3ms/step\n",
      "Epoch 173/500\n",
      "259/259 - 1s - loss: 116.4407 - val_loss: 86.1846 - 762ms/epoch - 3ms/step\n",
      "Epoch 174/500\n",
      "259/259 - 1s - loss: 119.3504 - val_loss: 80.8123 - 761ms/epoch - 3ms/step\n",
      "Epoch 175/500\n",
      "259/259 - 1s - loss: 119.0122 - val_loss: 85.7218 - 761ms/epoch - 3ms/step\n",
      "Epoch 176/500\n",
      "259/259 - 1s - loss: 121.3192 - val_loss: 87.9795 - 774ms/epoch - 3ms/step\n",
      "Epoch 177/500\n",
      "259/259 - 1s - loss: 126.8846 - val_loss: 94.5085 - 759ms/epoch - 3ms/step\n",
      "Epoch 178/500\n",
      "259/259 - 1s - loss: 120.9746 - val_loss: 82.3589 - 768ms/epoch - 3ms/step\n",
      "Epoch 179/500\n",
      "259/259 - 1s - loss: 121.3727 - val_loss: 86.3464 - 762ms/epoch - 3ms/step\n",
      "Epoch 180/500\n",
      "259/259 - 1s - loss: 128.4703 - val_loss: 81.7175 - 765ms/epoch - 3ms/step\n",
      "Epoch 181/500\n",
      "259/259 - 1s - loss: 122.4160 - val_loss: 91.1404 - 760ms/epoch - 3ms/step\n",
      "Epoch 182/500\n",
      "259/259 - 1s - loss: 115.8872 - val_loss: 89.2490 - 762ms/epoch - 3ms/step\n",
      "Epoch 183/500\n",
      "259/259 - 1s - loss: 119.2049 - val_loss: 79.9727 - 763ms/epoch - 3ms/step\n",
      "Epoch 184/500\n",
      "259/259 - 1s - loss: 121.6547 - val_loss: 80.1487 - 779ms/epoch - 3ms/step\n",
      "Epoch 185/500\n",
      "259/259 - 1s - loss: 123.3384 - val_loss: 84.0355 - 765ms/epoch - 3ms/step\n",
      "Epoch 186/500\n",
      "259/259 - 1s - loss: 123.5340 - val_loss: 84.8476 - 764ms/epoch - 3ms/step\n",
      "Epoch 187/500\n",
      "259/259 - 1s - loss: 117.3770 - val_loss: 88.5843 - 781ms/epoch - 3ms/step\n",
      "Epoch 188/500\n",
      "259/259 - 1s - loss: 118.5168 - val_loss: 80.5954 - 777ms/epoch - 3ms/step\n",
      "Epoch 189/500\n",
      "259/259 - 1s - loss: 122.8367 - val_loss: 80.1824 - 764ms/epoch - 3ms/step\n",
      "Epoch 190/500\n",
      "259/259 - 1s - loss: 121.0101 - val_loss: 81.0786 - 765ms/epoch - 3ms/step\n",
      "Epoch 191/500\n",
      "259/259 - 1s - loss: 124.5967 - val_loss: 103.5222 - 766ms/epoch - 3ms/step\n",
      "Epoch 192/500\n",
      "259/259 - 1s - loss: 111.0981 - val_loss: 85.6220 - 783ms/epoch - 3ms/step\n",
      "Epoch 193/500\n",
      "259/259 - 1s - loss: 119.3942 - val_loss: 84.0505 - 759ms/epoch - 3ms/step\n",
      "Epoch 194/500\n",
      "259/259 - 1s - loss: 112.9981 - val_loss: 102.4119 - 765ms/epoch - 3ms/step\n",
      "Epoch 195/500\n",
      "259/259 - 1s - loss: 119.4216 - val_loss: 84.5902 - 756ms/epoch - 3ms/step\n",
      "Epoch 196/500\n",
      "259/259 - 1s - loss: 120.2230 - val_loss: 86.6979 - 759ms/epoch - 3ms/step\n",
      "Epoch 197/500\n",
      "259/259 - 1s - loss: 118.5263 - val_loss: 94.1236 - 764ms/epoch - 3ms/step\n",
      "Epoch 198/500\n",
      "259/259 - 1s - loss: 111.7509 - val_loss: 81.9716 - 762ms/epoch - 3ms/step\n",
      "Epoch 199/500\n",
      "259/259 - 1s - loss: 113.5228 - val_loss: 78.4994 - 768ms/epoch - 3ms/step\n",
      "Epoch 200/500\n",
      "259/259 - 1s - loss: 119.9782 - val_loss: 78.4786 - 776ms/epoch - 3ms/step\n",
      "Epoch 201/500\n",
      "259/259 - 1s - loss: 119.1834 - val_loss: 80.4811 - 762ms/epoch - 3ms/step\n",
      "Epoch 202/500\n",
      "259/259 - 1s - loss: 115.2779 - val_loss: 88.6809 - 761ms/epoch - 3ms/step\n",
      "Epoch 203/500\n",
      "259/259 - 1s - loss: 117.3644 - val_loss: 90.3138 - 774ms/epoch - 3ms/step\n",
      "Epoch 204/500\n",
      "259/259 - 1s - loss: 117.4147 - val_loss: 81.0740 - 772ms/epoch - 3ms/step\n",
      "Epoch 205/500\n",
      "259/259 - 1s - loss: 120.3551 - val_loss: 80.7597 - 758ms/epoch - 3ms/step\n",
      "Epoch 206/500\n",
      "259/259 - 1s - loss: 118.9107 - val_loss: 84.8179 - 766ms/epoch - 3ms/step\n",
      "Epoch 207/500\n",
      "259/259 - 1s - loss: 113.2241 - val_loss: 78.6814 - 787ms/epoch - 3ms/step\n",
      "Epoch 208/500\n",
      "259/259 - 1s - loss: 119.7333 - val_loss: 82.9009 - 811ms/epoch - 3ms/step\n",
      "Epoch 209/500\n",
      "259/259 - 1s - loss: 114.5597 - val_loss: 84.5293 - 783ms/epoch - 3ms/step\n",
      "Epoch 210/500\n",
      "259/259 - 1s - loss: 113.4637 - val_loss: 82.5287 - 791ms/epoch - 3ms/step\n",
      "Epoch 211/500\n",
      "259/259 - 1s - loss: 112.5737 - val_loss: 83.7343 - 787ms/epoch - 3ms/step\n",
      "Epoch 212/500\n",
      "259/259 - 1s - loss: 116.5960 - val_loss: 94.1454 - 787ms/epoch - 3ms/step\n",
      "Epoch 213/500\n",
      "259/259 - 1s - loss: 113.0726 - val_loss: 88.2345 - 783ms/epoch - 3ms/step\n",
      "Epoch 214/500\n",
      "259/259 - 1s - loss: 117.1173 - val_loss: 80.2205 - 787ms/epoch - 3ms/step\n",
      "Epoch 215/500\n",
      "259/259 - 1s - loss: 112.0389 - val_loss: 79.6314 - 796ms/epoch - 3ms/step\n",
      "Epoch 216/500\n",
      "259/259 - 1s - loss: 112.2127 - val_loss: 91.8747 - 802ms/epoch - 3ms/step\n",
      "Epoch 217/500\n",
      "259/259 - 1s - loss: 117.5987 - val_loss: 82.0772 - 789ms/epoch - 3ms/step\n",
      "Epoch 218/500\n",
      "259/259 - 1s - loss: 123.3770 - val_loss: 97.3244 - 790ms/epoch - 3ms/step\n",
      "Epoch 219/500\n",
      "259/259 - 1s - loss: 115.1655 - val_loss: 74.8083 - 805ms/epoch - 3ms/step\n",
      "Epoch 220/500\n",
      "259/259 - 1s - loss: 115.1843 - val_loss: 78.9262 - 802ms/epoch - 3ms/step\n",
      "Epoch 221/500\n",
      "259/259 - 1s - loss: 117.9674 - val_loss: 92.1495 - 774ms/epoch - 3ms/step\n",
      "Epoch 222/500\n",
      "259/259 - 1s - loss: 112.7595 - val_loss: 76.0023 - 784ms/epoch - 3ms/step\n",
      "Epoch 223/500\n",
      "259/259 - 1s - loss: 117.7427 - val_loss: 88.8893 - 777ms/epoch - 3ms/step\n",
      "Epoch 224/500\n",
      "259/259 - 1s - loss: 111.9443 - val_loss: 86.8655 - 809ms/epoch - 3ms/step\n",
      "Epoch 225/500\n",
      "259/259 - 1s - loss: 116.1551 - val_loss: 74.9530 - 798ms/epoch - 3ms/step\n",
      "Epoch 226/500\n",
      "259/259 - 1s - loss: 122.0780 - val_loss: 76.0226 - 773ms/epoch - 3ms/step\n",
      "Epoch 227/500\n",
      "259/259 - 1s - loss: 114.6187 - val_loss: 79.9218 - 765ms/epoch - 3ms/step\n",
      "Epoch 228/500\n",
      "259/259 - 1s - loss: 112.2651 - val_loss: 77.8049 - 762ms/epoch - 3ms/step\n",
      "Epoch 229/500\n",
      "259/259 - 1s - loss: 115.3085 - val_loss: 83.1313 - 768ms/epoch - 3ms/step\n",
      "Epoch 230/500\n",
      "259/259 - 1s - loss: 114.7281 - val_loss: 77.1092 - 768ms/epoch - 3ms/step\n",
      "Epoch 231/500\n",
      "259/259 - 1s - loss: 112.1027 - val_loss: 86.8274 - 765ms/epoch - 3ms/step\n",
      "Epoch 232/500\n",
      "259/259 - 1s - loss: 112.3891 - val_loss: 85.7925 - 775ms/epoch - 3ms/step\n",
      "Epoch 233/500\n",
      "259/259 - 1s - loss: 116.9061 - val_loss: 79.3562 - 763ms/epoch - 3ms/step\n",
      "Epoch 234/500\n",
      "259/259 - 1s - loss: 117.4668 - val_loss: 78.6438 - 772ms/epoch - 3ms/step\n",
      "Epoch 235/500\n",
      "259/259 - 1s - loss: 116.1394 - val_loss: 89.4406 - 764ms/epoch - 3ms/step\n",
      "Epoch 236/500\n",
      "259/259 - 1s - loss: 111.2347 - val_loss: 82.5688 - 767ms/epoch - 3ms/step\n",
      "Epoch 237/500\n",
      "259/259 - 1s - loss: 107.9165 - val_loss: 77.6031 - 760ms/epoch - 3ms/step\n",
      "Epoch 238/500\n",
      "259/259 - 1s - loss: 110.9526 - val_loss: 86.7501 - 760ms/epoch - 3ms/step\n",
      "Epoch 239/500\n",
      "259/259 - 1s - loss: 111.1071 - val_loss: 75.4576 - 760ms/epoch - 3ms/step\n",
      "Epoch 240/500\n",
      "259/259 - 1s - loss: 115.4128 - val_loss: 77.1053 - 777ms/epoch - 3ms/step\n",
      "Epoch 241/500\n",
      "259/259 - 1s - loss: 103.2910 - val_loss: 78.4210 - 763ms/epoch - 3ms/step\n",
      "Epoch 242/500\n",
      "259/259 - 1s - loss: 112.1229 - val_loss: 78.0214 - 758ms/epoch - 3ms/step\n",
      "Epoch 243/500\n",
      "259/259 - 1s - loss: 122.1077 - val_loss: 79.1208 - 759ms/epoch - 3ms/step\n",
      "Epoch 244/500\n",
      "259/259 - 1s - loss: 118.5800 - val_loss: 77.3413 - 757ms/epoch - 3ms/step\n",
      "Epoch 245/500\n",
      "259/259 - 1s - loss: 117.0816 - val_loss: 80.2134 - 764ms/epoch - 3ms/step\n",
      "Epoch 246/500\n",
      "259/259 - 1s - loss: 115.8368 - val_loss: 76.2633 - 761ms/epoch - 3ms/step\n",
      "Epoch 247/500\n",
      "259/259 - 1s - loss: 115.0416 - val_loss: 73.1288 - 763ms/epoch - 3ms/step\n",
      "Epoch 248/500\n",
      "259/259 - 1s - loss: 112.5593 - val_loss: 77.8264 - 772ms/epoch - 3ms/step\n",
      "Epoch 249/500\n",
      "259/259 - 1s - loss: 112.9849 - val_loss: 77.3793 - 758ms/epoch - 3ms/step\n",
      "Epoch 250/500\n",
      "259/259 - 1s - loss: 105.4943 - val_loss: 75.5690 - 764ms/epoch - 3ms/step\n",
      "Epoch 251/500\n",
      "259/259 - 1s - loss: 114.1861 - val_loss: 81.2640 - 759ms/epoch - 3ms/step\n",
      "Epoch 252/500\n",
      "259/259 - 1s - loss: 116.5367 - val_loss: 75.7631 - 762ms/epoch - 3ms/step\n",
      "Epoch 253/500\n",
      "259/259 - 1s - loss: 107.5087 - val_loss: 76.8481 - 754ms/epoch - 3ms/step\n",
      "Epoch 254/500\n",
      "259/259 - 1s - loss: 108.4137 - val_loss: 76.6090 - 760ms/epoch - 3ms/step\n",
      "Epoch 255/500\n",
      "259/259 - 1s - loss: 109.4100 - val_loss: 76.9953 - 765ms/epoch - 3ms/step\n",
      "Epoch 256/500\n",
      "259/259 - 1s - loss: 105.1565 - val_loss: 82.6269 - 788ms/epoch - 3ms/step\n",
      "Epoch 257/500\n",
      "259/259 - 1s - loss: 109.6196 - val_loss: 77.0201 - 773ms/epoch - 3ms/step\n",
      "Epoch 258/500\n",
      "259/259 - 1s - loss: 115.3972 - val_loss: 72.9046 - 765ms/epoch - 3ms/step\n",
      "Epoch 259/500\n",
      "259/259 - 1s - loss: 117.3530 - val_loss: 86.2834 - 763ms/epoch - 3ms/step\n",
      "Epoch 260/500\n",
      "259/259 - 1s - loss: 108.0446 - val_loss: 75.1476 - 762ms/epoch - 3ms/step\n",
      "Epoch 261/500\n",
      "259/259 - 1s - loss: 121.4221 - val_loss: 93.7950 - 766ms/epoch - 3ms/step\n",
      "Epoch 262/500\n",
      "259/259 - 1s - loss: 107.0209 - val_loss: 83.6691 - 764ms/epoch - 3ms/step\n",
      "Epoch 263/500\n",
      "259/259 - 1s - loss: 110.7086 - val_loss: 75.8267 - 769ms/epoch - 3ms/step\n",
      "Epoch 264/500\n",
      "259/259 - 1s - loss: 116.3607 - val_loss: 101.2770 - 772ms/epoch - 3ms/step\n",
      "Epoch 265/500\n",
      "259/259 - 1s - loss: 115.8736 - val_loss: 77.3709 - 776ms/epoch - 3ms/step\n",
      "Epoch 266/500\n",
      "259/259 - 1s - loss: 107.0829 - val_loss: 78.6490 - 777ms/epoch - 3ms/step\n",
      "Epoch 267/500\n",
      "259/259 - 1s - loss: 114.7706 - val_loss: 75.6694 - 765ms/epoch - 3ms/step\n",
      "Epoch 268/500\n",
      "259/259 - 1s - loss: 109.1153 - val_loss: 77.9316 - 773ms/epoch - 3ms/step\n",
      "Epoch 269/500\n",
      "259/259 - 1s - loss: 113.1514 - val_loss: 84.1690 - 764ms/epoch - 3ms/step\n",
      "Epoch 270/500\n",
      "259/259 - 1s - loss: 111.2966 - val_loss: 76.8652 - 759ms/epoch - 3ms/step\n",
      "Epoch 271/500\n",
      "259/259 - 1s - loss: 106.0215 - val_loss: 75.5316 - 765ms/epoch - 3ms/step\n",
      "Epoch 272/500\n",
      "259/259 - 1s - loss: 107.1740 - val_loss: 74.3540 - 783ms/epoch - 3ms/step\n",
      "Epoch 273/500\n",
      "259/259 - 1s - loss: 114.1460 - val_loss: 79.5074 - 766ms/epoch - 3ms/step\n",
      "Epoch 274/500\n",
      "259/259 - 1s - loss: 112.1919 - val_loss: 82.5781 - 763ms/epoch - 3ms/step\n",
      "Epoch 275/500\n",
      "259/259 - 1s - loss: 108.5571 - val_loss: 112.6520 - 767ms/epoch - 3ms/step\n",
      "Epoch 276/500\n",
      "259/259 - 1s - loss: 109.4077 - val_loss: 92.6582 - 766ms/epoch - 3ms/step\n",
      "Epoch 277/500\n",
      "259/259 - 1s - loss: 109.1805 - val_loss: 74.0398 - 766ms/epoch - 3ms/step\n",
      "Epoch 278/500\n",
      "259/259 - 1s - loss: 114.4988 - val_loss: 80.7803 - 767ms/epoch - 3ms/step\n",
      "Epoch 279/500\n",
      "259/259 - 1s - loss: 111.5968 - val_loss: 74.5071 - 763ms/epoch - 3ms/step\n",
      "Epoch 280/500\n",
      "259/259 - 1s - loss: 109.5614 - val_loss: 84.1021 - 775ms/epoch - 3ms/step\n",
      "Epoch 281/500\n",
      "259/259 - 1s - loss: 110.2228 - val_loss: 84.7872 - 765ms/epoch - 3ms/step\n",
      "Epoch 282/500\n",
      "259/259 - 1s - loss: 110.2131 - val_loss: 79.9483 - 767ms/epoch - 3ms/step\n",
      "Epoch 283/500\n",
      "259/259 - 1s - loss: 111.0993 - val_loss: 80.8690 - 763ms/epoch - 3ms/step\n",
      "Epoch 284/500\n",
      "259/259 - 1s - loss: 106.5675 - val_loss: 82.4247 - 769ms/epoch - 3ms/step\n",
      "Epoch 285/500\n",
      "259/259 - 1s - loss: 109.2470 - val_loss: 84.8005 - 765ms/epoch - 3ms/step\n",
      "Epoch 286/500\n",
      "259/259 - 1s - loss: 113.7348 - val_loss: 77.6910 - 767ms/epoch - 3ms/step\n",
      "Epoch 287/500\n",
      "259/259 - 1s - loss: 106.0924 - val_loss: 81.5803 - 767ms/epoch - 3ms/step\n",
      "Epoch 288/500\n",
      "259/259 - 1s - loss: 112.9475 - val_loss: 83.0378 - 785ms/epoch - 3ms/step\n",
      "Epoch 289/500\n",
      "259/259 - 1s - loss: 108.7909 - val_loss: 76.7913 - 763ms/epoch - 3ms/step\n",
      "Epoch 290/500\n",
      "259/259 - 1s - loss: 110.0301 - val_loss: 91.0192 - 761ms/epoch - 3ms/step\n",
      "Epoch 291/500\n",
      "259/259 - 1s - loss: 115.4938 - val_loss: 79.8480 - 764ms/epoch - 3ms/step\n",
      "Epoch 292/500\n",
      "259/259 - 1s - loss: 104.6715 - val_loss: 72.3806 - 764ms/epoch - 3ms/step\n",
      "Epoch 293/500\n",
      "259/259 - 1s - loss: 112.1205 - val_loss: 75.5158 - 763ms/epoch - 3ms/step\n",
      "Epoch 294/500\n",
      "259/259 - 1s - loss: 106.8222 - val_loss: 77.9332 - 766ms/epoch - 3ms/step\n",
      "Epoch 295/500\n",
      "259/259 - 1s - loss: 108.8789 - val_loss: 80.3484 - 760ms/epoch - 3ms/step\n",
      "Epoch 296/500\n",
      "259/259 - 1s - loss: 111.0751 - val_loss: 90.1590 - 776ms/epoch - 3ms/step\n",
      "Epoch 297/500\n",
      "259/259 - 1s - loss: 114.5862 - val_loss: 74.4645 - 767ms/epoch - 3ms/step\n",
      "Epoch 298/500\n",
      "259/259 - 1s - loss: 110.9336 - val_loss: 79.1070 - 786ms/epoch - 3ms/step\n",
      "Epoch 299/500\n",
      "259/259 - 1s - loss: 108.5059 - val_loss: 85.6237 - 766ms/epoch - 3ms/step\n",
      "Epoch 300/500\n",
      "259/259 - 1s - loss: 108.2562 - val_loss: 73.0671 - 782ms/epoch - 3ms/step\n",
      "Epoch 301/500\n",
      "259/259 - 1s - loss: 110.0734 - val_loss: 75.1981 - 760ms/epoch - 3ms/step\n",
      "Epoch 302/500\n",
      "259/259 - 1s - loss: 104.4594 - val_loss: 77.0470 - 763ms/epoch - 3ms/step\n",
      "Epoch 303/500\n",
      "259/259 - 1s - loss: 109.9020 - val_loss: 75.6526 - 765ms/epoch - 3ms/step\n",
      "Epoch 304/500\n",
      "259/259 - 1s - loss: 108.7025 - val_loss: 91.0468 - 783ms/epoch - 3ms/step\n",
      "Epoch 305/500\n",
      "259/259 - 1s - loss: 104.8353 - val_loss: 87.4002 - 777ms/epoch - 3ms/step\n",
      "Epoch 306/500\n",
      "259/259 - 1s - loss: 101.1634 - val_loss: 78.7157 - 772ms/epoch - 3ms/step\n",
      "Epoch 307/500\n",
      "259/259 - 1s - loss: 113.6673 - val_loss: 76.9090 - 760ms/epoch - 3ms/step\n",
      "Epoch 308/500\n",
      "259/259 - 1s - loss: 107.3737 - val_loss: 71.7332 - 763ms/epoch - 3ms/step\n",
      "Epoch 309/500\n",
      "259/259 - 1s - loss: 110.3077 - val_loss: 75.3389 - 764ms/epoch - 3ms/step\n",
      "Epoch 310/500\n",
      "259/259 - 1s - loss: 111.0011 - val_loss: 77.6302 - 766ms/epoch - 3ms/step\n",
      "Epoch 311/500\n",
      "259/259 - 1s - loss: 104.4918 - val_loss: 75.4347 - 761ms/epoch - 3ms/step\n",
      "Epoch 312/500\n",
      "259/259 - 1s - loss: 106.1564 - val_loss: 74.8737 - 781ms/epoch - 3ms/step\n",
      "Epoch 313/500\n",
      "259/259 - 1s - loss: 112.8078 - val_loss: 75.8720 - 762ms/epoch - 3ms/step\n",
      "Epoch 314/500\n",
      "259/259 - 1s - loss: 110.2439 - val_loss: 80.6175 - 768ms/epoch - 3ms/step\n",
      "Epoch 315/500\n",
      "259/259 - 1s - loss: 107.9441 - val_loss: 77.6413 - 765ms/epoch - 3ms/step\n",
      "Epoch 316/500\n",
      "259/259 - 1s - loss: 107.2763 - val_loss: 81.0350 - 776ms/epoch - 3ms/step\n",
      "Epoch 317/500\n",
      "259/259 - 1s - loss: 105.4412 - val_loss: 79.0068 - 756ms/epoch - 3ms/step\n",
      "Epoch 318/500\n",
      "259/259 - 1s - loss: 108.5832 - val_loss: 95.6450 - 762ms/epoch - 3ms/step\n",
      "Epoch 319/500\n",
      "259/259 - 1s - loss: 113.6305 - val_loss: 73.0349 - 759ms/epoch - 3ms/step\n",
      "Epoch 320/500\n",
      "259/259 - 1s - loss: 111.1468 - val_loss: 81.0853 - 785ms/epoch - 3ms/step\n",
      "Epoch 321/500\n",
      "259/259 - 1s - loss: 111.4974 - val_loss: 74.7325 - 765ms/epoch - 3ms/step\n",
      "Epoch 322/500\n",
      "259/259 - 1s - loss: 108.6135 - val_loss: 74.9598 - 754ms/epoch - 3ms/step\n",
      "Epoch 323/500\n",
      "259/259 - 1s - loss: 111.8875 - val_loss: 74.3694 - 765ms/epoch - 3ms/step\n",
      "Epoch 324/500\n",
      "259/259 - 1s - loss: 107.4199 - val_loss: 95.9661 - 768ms/epoch - 3ms/step\n",
      "Epoch 325/500\n",
      "259/259 - 1s - loss: 106.1559 - val_loss: 76.0305 - 764ms/epoch - 3ms/step\n",
      "Epoch 326/500\n",
      "259/259 - 1s - loss: 100.4982 - val_loss: 73.9396 - 759ms/epoch - 3ms/step\n",
      "Epoch 327/500\n",
      "259/259 - 1s - loss: 110.5242 - val_loss: 69.8566 - 767ms/epoch - 3ms/step\n",
      "Epoch 328/500\n",
      "259/259 - 1s - loss: 109.4903 - val_loss: 75.6456 - 774ms/epoch - 3ms/step\n",
      "Epoch 329/500\n",
      "259/259 - 1s - loss: 118.8271 - val_loss: 72.3021 - 770ms/epoch - 3ms/step\n",
      "Epoch 330/500\n",
      "259/259 - 1s - loss: 109.8753 - val_loss: 70.4331 - 771ms/epoch - 3ms/step\n",
      "Epoch 331/500\n",
      "259/259 - 1s - loss: 106.3625 - val_loss: 71.8911 - 771ms/epoch - 3ms/step\n",
      "Epoch 332/500\n",
      "259/259 - 1s - loss: 104.7900 - val_loss: 76.7402 - 766ms/epoch - 3ms/step\n",
      "Epoch 333/500\n",
      "259/259 - 1s - loss: 106.8713 - val_loss: 71.8981 - 762ms/epoch - 3ms/step\n",
      "Epoch 334/500\n",
      "259/259 - 1s - loss: 110.6951 - val_loss: 76.8986 - 759ms/epoch - 3ms/step\n",
      "Epoch 335/500\n",
      "259/259 - 1s - loss: 109.5013 - val_loss: 76.5975 - 784ms/epoch - 3ms/step\n",
      "Epoch 336/500\n",
      "259/259 - 1s - loss: 112.3669 - val_loss: 75.2431 - 766ms/epoch - 3ms/step\n",
      "Epoch 337/500\n",
      "259/259 - 1s - loss: 112.4035 - val_loss: 74.0900 - 762ms/epoch - 3ms/step\n",
      "Epoch 338/500\n",
      "259/259 - 1s - loss: 102.1077 - val_loss: 75.9754 - 764ms/epoch - 3ms/step\n",
      "Epoch 339/500\n",
      "259/259 - 1s - loss: 102.4152 - val_loss: 73.1296 - 763ms/epoch - 3ms/step\n",
      "Epoch 340/500\n",
      "259/259 - 1s - loss: 111.7056 - val_loss: 78.7943 - 770ms/epoch - 3ms/step\n",
      "Epoch 341/500\n",
      "259/259 - 1s - loss: 105.5344 - val_loss: 75.4609 - 760ms/epoch - 3ms/step\n",
      "Epoch 342/500\n",
      "259/259 - 1s - loss: 104.7451 - val_loss: 76.1509 - 766ms/epoch - 3ms/step\n",
      "Epoch 343/500\n",
      "259/259 - 1s - loss: 103.3993 - val_loss: 83.3204 - 775ms/epoch - 3ms/step\n",
      "Epoch 344/500\n",
      "259/259 - 1s - loss: 105.7792 - val_loss: 80.3413 - 771ms/epoch - 3ms/step\n",
      "Epoch 345/500\n",
      "259/259 - 1s - loss: 109.6055 - val_loss: 77.9747 - 767ms/epoch - 3ms/step\n",
      "Epoch 346/500\n",
      "259/259 - 1s - loss: 117.3360 - val_loss: 84.7673 - 781ms/epoch - 3ms/step\n",
      "Epoch 347/500\n",
      "259/259 - 1s - loss: 105.1299 - val_loss: 78.2049 - 771ms/epoch - 3ms/step\n",
      "Epoch 348/500\n",
      "259/259 - 1s - loss: 107.2016 - val_loss: 83.3182 - 762ms/epoch - 3ms/step\n",
      "Epoch 349/500\n",
      "259/259 - 1s - loss: 115.8354 - val_loss: 71.5262 - 767ms/epoch - 3ms/step\n",
      "Epoch 350/500\n",
      "259/259 - 1s - loss: 102.6970 - val_loss: 73.5942 - 764ms/epoch - 3ms/step\n",
      "Epoch 351/500\n",
      "259/259 - 1s - loss: 107.2701 - val_loss: 72.3894 - 785ms/epoch - 3ms/step\n",
      "Epoch 352/500\n",
      "259/259 - 1s - loss: 108.5414 - val_loss: 74.4713 - 762ms/epoch - 3ms/step\n",
      "Epoch 353/500\n",
      "259/259 - 1s - loss: 110.5984 - val_loss: 72.8266 - 767ms/epoch - 3ms/step\n",
      "Epoch 354/500\n",
      "259/259 - 1s - loss: 106.1036 - val_loss: 74.0879 - 768ms/epoch - 3ms/step\n",
      "Epoch 355/500\n",
      "259/259 - 1s - loss: 110.5065 - val_loss: 79.3779 - 769ms/epoch - 3ms/step\n",
      "Epoch 356/500\n",
      "259/259 - 1s - loss: 107.9636 - val_loss: 75.5716 - 765ms/epoch - 3ms/step\n",
      "Epoch 357/500\n",
      "259/259 - 1s - loss: 109.1261 - val_loss: 79.4564 - 771ms/epoch - 3ms/step\n",
      "Epoch 358/500\n",
      "259/259 - 1s - loss: 108.6181 - val_loss: 73.3259 - 768ms/epoch - 3ms/step\n",
      "Epoch 359/500\n",
      "259/259 - 1s - loss: 105.8296 - val_loss: 104.3192 - 779ms/epoch - 3ms/step\n",
      "Epoch 360/500\n",
      "259/259 - 1s - loss: 108.9651 - val_loss: 90.1411 - 762ms/epoch - 3ms/step\n",
      "Epoch 361/500\n",
      "259/259 - 1s - loss: 112.0279 - val_loss: 73.4455 - 756ms/epoch - 3ms/step\n",
      "Epoch 362/500\n",
      "259/259 - 1s - loss: 105.7500 - val_loss: 75.7651 - 772ms/epoch - 3ms/step\n",
      "Epoch 363/500\n",
      "259/259 - 1s - loss: 112.2605 - val_loss: 74.7509 - 774ms/epoch - 3ms/step\n",
      "Epoch 364/500\n",
      "259/259 - 1s - loss: 101.6964 - val_loss: 73.7889 - 763ms/epoch - 3ms/step\n",
      "Epoch 365/500\n",
      "259/259 - 1s - loss: 111.6649 - val_loss: 76.9035 - 759ms/epoch - 3ms/step\n",
      "Epoch 366/500\n",
      "259/259 - 1s - loss: 104.5065 - val_loss: 76.8673 - 761ms/epoch - 3ms/step\n",
      "Epoch 367/500\n",
      "259/259 - 1s - loss: 111.0792 - val_loss: 73.4805 - 786ms/epoch - 3ms/step\n",
      "Epoch 368/500\n",
      "259/259 - 1s - loss: 103.2231 - val_loss: 84.5923 - 767ms/epoch - 3ms/step\n",
      "Epoch 369/500\n",
      "259/259 - 1s - loss: 105.1934 - val_loss: 72.7704 - 766ms/epoch - 3ms/step\n",
      "Epoch 370/500\n",
      "259/259 - 1s - loss: 115.7912 - val_loss: 80.9428 - 764ms/epoch - 3ms/step\n",
      "Epoch 371/500\n",
      "259/259 - 1s - loss: 107.8090 - val_loss: 75.9577 - 758ms/epoch - 3ms/step\n",
      "Epoch 372/500\n",
      "259/259 - 1s - loss: 101.2108 - val_loss: 75.1345 - 766ms/epoch - 3ms/step\n",
      "Epoch 373/500\n",
      "259/259 - 1s - loss: 104.6243 - val_loss: 71.8348 - 764ms/epoch - 3ms/step\n",
      "Epoch 374/500\n",
      "259/259 - 1s - loss: 107.4858 - val_loss: 70.8893 - 769ms/epoch - 3ms/step\n",
      "Epoch 375/500\n",
      "259/259 - 1s - loss: 106.9821 - val_loss: 75.8356 - 786ms/epoch - 3ms/step\n",
      "Epoch 376/500\n",
      "259/259 - 1s - loss: 102.6552 - val_loss: 75.7424 - 767ms/epoch - 3ms/step\n",
      "Epoch 377/500\n",
      "Restoring model weights from the end of the best epoch: 327.\n",
      "259/259 - 1s - loss: 102.3874 - val_loss: 73.3539 - 769ms/epoch - 3ms/step\n",
      "Epoch 377: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "cnn_history = model.fit(X_train, Y_train, callbacks=[monitor],\n",
    "    validation_data=(X_valid, Y_valid), epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-Q08cT94MU5"
   },
   "source": [
    "Predict and evaluate the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gyUB1nSG9fhr",
    "outputId": "f46d18af-0ad6-4c1e-97d1-56ae9d27e58a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rmse: 7.447884492904997\n",
      "Validation rmse: 8.358024863700136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "cnn_train_pred = model.predict(X_train)\n",
    "cnn_valid_pred = model.predict(X_valid)\n",
    "print('Train rmse:', np.sqrt(mean_squared_error(Y_train, cnn_train_pred)))\n",
    "print('Validation rmse:', np.sqrt(mean_squared_error(Y_valid, cnn_valid_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYNHiuuk4QAk"
   },
   "source": [
    "Train rmse: 8.260069977016887\n",
    "Validation rmse: 10.943058830677673\n",
    "\n",
    "Plot the training curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "qbAvkOwmCdao",
    "outputId": "7dbd3cb4-0a34-4734-909a-8b1f68a152e5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fig, axes = plt.subplots(2, 2, sharex=True, sharey=True,figsize=(22,12))\n",
    "#ax1, ax2 = axes[0]\n",
    "#ax3, ax4 = axes[1]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(cnn_history.history['loss'], label='Train loss')\n",
    "plt.plot(cnn_history.history['val_loss'], label='Validation loss')\n",
    "fig.legend()\n",
    "fig.suptitle('CNN')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KI0FnhjDHX4_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
