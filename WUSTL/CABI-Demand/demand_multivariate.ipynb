{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/present/blob/master/WUSTL/CABI-Demand/demand_multivariate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# Washington University [Olin School of Business](https://olin.wustl.edu/EN-US/Pages/default.aspx)\n",
    "[Center for Analytics and Business Insights](https://olin.wustl.edu/EN-US/Faculty-Research/research-centers/center-analytics-business-insights/Pages/default.aspx) (CABI)  \n",
    "[Deep Learning for Demand Forecasting](https://github.com/jeffheaton/present/tree/master/WUSTL/CABI-Demand)  \n",
    "Copyright 2022 by [Jeff Heaton](https://www.youtube.com/c/HeatonResearch), Released under [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) \n",
    "\n",
    "## Multivariate Projection\n",
    "\n",
    "First map Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJPIlxl8hAg5",
    "outputId": "da3c8e11-df72-4910-f7ad-37563c16d92a"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yN7476ZB3MTi"
   },
   "source": [
    "Load the three data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WEfyt5ShSeA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "PATH = \"/content/drive/MyDrive/projects/demand/\"\n",
    "\n",
    "df_sales = pd.read_csv(\"https://data.heatonresearch.com/wustl/CABI/demand-forecast/sales_train.csv\", parse_dates=['date'])\n",
    "df_items = pd.read_csv(\"https://data.heatonresearch.com/wustl/CABI/demand-forecast/items.csv\")\n",
    "df_resturant = pd.read_csv(\"https://data.heatonresearch.com/wustl/CABI/demand-forecast/resturants.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__jGovBB3QUR"
   },
   "source": [
    "Utility function to create sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kz2MmH3Cloi7"
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, window=1, lag=1, dropnan=True):\n",
    "    cols, names = list(), list()\n",
    "    # Input sequence (t-n, ... t-1)\n",
    "    for i in range(window, 0, -1):\n",
    "        cols.append(data.shift(i))\n",
    "        names += [('%s(t-%d)' % (col, i)) for col in data.columns]\n",
    "    # Current timestep (t=0)\n",
    "    cols.append(data)\n",
    "    names += [('%s(t)' % (col)) for col in data.columns]\n",
    "    # Target timestep (t=lag)\n",
    "    cols.append(data.shift(-lag))\n",
    "    names += [('%s(t+%d)' % (col, lag)) for col in data.columns]\n",
    "    # Put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # Drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmL154wv3YIR"
   },
   "source": [
    "Join the items and sales tables so that we can look up the store id for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3S7LIIqG3ihU",
    "outputId": "cd58ce73-16e1-498b-9e3b-9d63d2185b88"
   },
   "outputs": [],
   "source": [
    "df_items2 = df_items[['id','store_id']]\n",
    "df_train = df_sales.merge(df_items2,left_on='item_id',right_on='id')\n",
    "df_train[['date','item_id','item_count','store_id']]\n",
    "\n",
    "df_train = df_train.sort_values('date').groupby(['item_id', 'store_id', 'date'], as_index=False)\n",
    "df_train = df_train.agg({'item_count':['mean']})\n",
    "df_train.columns = ['item', 'store', 'date', 'sales']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "juImdYgR-rNi",
    "outputId": "3384356f-f73d-43f2-fef2-083840a41182"
   },
   "outputs": [],
   "source": [
    "df_train['dow'] = df_train['date'].dt.dayofweek\n",
    "df_train['doy'] = df_train['date'].dt.dayofyear\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSslf7_x3f_r"
   },
   "source": [
    "Build the sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "ZKf1jppTlvi4",
    "outputId": "54079c24-0231-47df-a22d-b885f2a9da85"
   },
   "outputs": [],
   "source": [
    "window = 29\n",
    "future_span = 30\n",
    "series = series_to_supervised(df_train.drop('date', axis=1), window=window, lag=future_span)\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMBAkJvR3nce"
   },
   "source": [
    "Remove sequences that did not have enough data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6D8BDtu-DWy"
   },
   "outputs": [],
   "source": [
    "# Remove edge cases, where there were not enough values to complete a series\n",
    "last_item = 'item(t-%d)' % window\n",
    "last_store = 'store(t-%d)' % window\n",
    "last_dow = 'dow(t-%d)' % window\n",
    "last_doy = 'doy(t-%d)' % window\n",
    "series = series[(series['store(t)'] == series[last_store])]\n",
    "series = series[(series['item(t)'] == series[last_item])]\n",
    "#series = series[(series['dow(t)'] == series[last_dow])]\n",
    "#series = series[(series['doy(t)'] == series[last_doy])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4quQLgwg3xfM"
   },
   "source": [
    "We will predict with sales, and our engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRhDirsoZ4dZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "def drop_column(df, col):\n",
    "  columns_to_drop = [('%s(t+%d)' % (col, future_span))]\n",
    "  for i in range(window, 0, -1):\n",
    "      columns_to_drop += [('%s(t-%d)' % (col, i))]\n",
    "  df.drop(columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "  df.drop([f\"{col}(t)\"], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "def cat_seq(df, col):\n",
    "  return to_categorical(df[col].values)\n",
    "\n",
    "# Label\n",
    "labels_col = 'sales(t+%d)' % future_span\n",
    "labels = series[labels_col]\n",
    "series.drop(labels_col, axis=1, inplace=True)\n",
    "series.drop('item(t+%d)' % future_span, axis=1, inplace=True)\n",
    "series.drop('store(t+%d)' % future_span, axis=1, inplace=True)\n",
    "series.drop('dow(t+%d)' % future_span, axis=1, inplace=True)\n",
    "series.drop('doy(t+%d)' % future_span, axis=1, inplace=True)\n",
    "\n",
    "# Get sales sequences\n",
    "series2 = series.copy()\n",
    "drop_column(series2, \"item\")\n",
    "drop_column(series2, \"store\")\n",
    "drop_column(series2, \"dow\")\n",
    "drop_column(series2, \"doy\")\n",
    "sales_series = series2.values\n",
    "\n",
    "# Day of week as a categorical\n",
    "series2 = series.copy()\n",
    "drop_column(series2, \"item\")\n",
    "drop_column(series2, \"store\")\n",
    "drop_column(series2, \"doy\")\n",
    "drop_column(series2, \"sales\")\n",
    "dow_series = series2.values\n",
    "\n",
    "# Get item sequences\n",
    "series2 = series.copy()\n",
    "drop_column(series2, \"item\")\n",
    "drop_column(series2, \"store\")\n",
    "drop_column(series2, \"dow\")\n",
    "drop_column(series2, \"sales\")\n",
    "doy_series = series2.values\n",
    "\n",
    "# Day of year\n",
    "t1 = sales_series.reshape(sales_series.shape + (1,))\n",
    "t2 = dow_series.reshape(dow_series.shape + (1,)) \n",
    "t3 = doy_series.reshape(doy_series.shape + (1,))\n",
    "x = np.concatenate([t1,t2,t3],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "woBI1ns6CBK1",
    "outputId": "60796692-0eba-4a74-f283-a036b40ca825"
   },
   "outputs": [],
   "source": [
    "dow_series = cat_seq(df_train, 'dow')\n",
    "dow_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "lDBNmItkC7hB",
    "outputId": "28afc9a7-d593-4067-d15b-602ac0c659e7"
   },
   "outputs": [],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0gn1hXDk4jY",
    "outputId": "980c015c-cc52-4fa2-cf99-bbb2528f4fd1"
   },
   "outputs": [],
   "source": [
    "print(t1.shape)\n",
    "print(t2.shape)\n",
    "print(t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mrMep9homxN"
   },
   "outputs": [],
   "source": [
    "#store_series = to_categorical(series['store(t)'].values)\n",
    "#store_series.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLrgz7RK33f1"
   },
   "source": [
    "Extract the predictors (x sequences) and the label (future prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eS7mDtENnrcq",
    "outputId": "cb90cd26-fbda-4fa7-8ca1-e91f59252740"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(x, labels.values, test_size=0.4, random_state=0)\n",
    "print('Train set shape', X_train.shape)\n",
    "print('Validation set shape', X_valid.shape)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ip9va59y3_MR"
   },
   "source": [
    "Final preparation for the x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iBXBGPXzw-D",
    "outputId": "824325e2-c95c-42f8-e451-06fb8fa67b5c"
   },
   "outputs": [],
   "source": [
    "print('Train set shape', X_train.shape)\n",
    "print('Validation set shape', X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IazoyOgL4D5T"
   },
   "source": [
    "Construct the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSX-MNvjz81I",
    "outputId": "6cc129b8-bd15-485b-c17b-6444d5951281"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Flatten, Dropout\n",
    "import keras\n",
    "\n",
    "epochs = 500\n",
    "batch = 256\n",
    "lr = 0.0003\n",
    "adam = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=8, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer=adam)\n",
    "model.summary()\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "#model.add(Dense(1))\n",
    "#model.compile(loss='mse', optimizer=adam)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_StxCza4IRx"
   },
   "source": [
    "Fit the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5KiECgn1P4s",
    "outputId": "e79368fd-ffec-4509-bed4-7da0c0c28bb6"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "cnn_history = model.fit(X_train, Y_train, callbacks=[monitor],\n",
    "    validation_data=(X_valid, Y_valid), epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-Q08cT94MU5"
   },
   "source": [
    "Predict and evaluate the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gyUB1nSG9fhr",
    "outputId": "f46d18af-0ad6-4c1e-97d1-56ae9d27e58a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "cnn_train_pred = model.predict(X_train)\n",
    "cnn_valid_pred = model.predict(X_valid)\n",
    "print('Train rmse:', np.sqrt(mean_squared_error(Y_train, cnn_train_pred)))\n",
    "print('Validation rmse:', np.sqrt(mean_squared_error(Y_valid, cnn_valid_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYNHiuuk4QAk"
   },
   "source": [
    "Train rmse: 8.260069977016887\n",
    "Validation rmse: 10.943058830677673\n",
    "\n",
    "Plot the training curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "qbAvkOwmCdao",
    "outputId": "7dbd3cb4-0a34-4734-909a-8b1f68a152e5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fig, axes = plt.subplots(2, 2, sharex=True, sharey=True,figsize=(22,12))\n",
    "#ax1, ax2 = axes[0]\n",
    "#ax3, ax4 = axes[1]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(cnn_history.history['loss'], label='Train loss')\n",
    "plt.plot(cnn_history.history['val_loss'], label='Validation loss')\n",
    "fig.legend()\n",
    "fig.suptitle('CNN')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KI0FnhjDHX4_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
