{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Univariate Projection\n",
        "\n",
        "First map Google drive."
      ],
      "metadata": {
        "id": "eDMHtf7ccifv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJPIlxl8hAg5",
        "outputId": "24cf6180-5f85-4b99-8c12-3ebf41c2d091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the three data files."
      ],
      "metadata": {
        "id": "yN7476ZB3MTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "PATH = \"/content/drive/MyDrive/projects/demand/\"\n",
        "\n",
        "df_sales = pd.read_csv(\"https://data.heatonresearch.com/wustl/CABI/demand-forecast/sales_train.csv\", parse_dates=['date'])\n",
        "df_items = pd.read_csv(\"https://data.heatonresearch.com/wustl/CABI/demand-forecast/items.csv\")\n",
        "df_resturant = pd.read_csv(\"https://data.heatonresearch.com/wustl/CABI/demand-forecast/resturants.csv\")"
      ],
      "metadata": {
        "id": "5WEfyt5ShSeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utility function to create sequences."
      ],
      "metadata": {
        "id": "__jGovBB3QUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def series_to_supervised(data, window=1, lag=1, dropnan=True):\n",
        "    cols, names = list(), list()\n",
        "    # Input sequence (t-n, ... t-1)\n",
        "    for i in range(window, 0, -1):\n",
        "        cols.append(data.shift(i))\n",
        "        names += [('%s(t-%d)' % (col, i)) for col in data.columns]\n",
        "    # Current timestep (t=0)\n",
        "    cols.append(data)\n",
        "    names += [('%s(t)' % (col)) for col in data.columns]\n",
        "    # Target timestep (t=lag)\n",
        "    cols.append(data.shift(-lag))\n",
        "    names += [('%s(t+%d)' % (col, lag)) for col in data.columns]\n",
        "    # Put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # Drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg"
      ],
      "metadata": {
        "id": "Kz2MmH3Cloi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join the items and sales tables so that we can look up the store id for each item."
      ],
      "metadata": {
        "id": "DmL154wv3YIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_items2 = df_items[['id','store_id']]\n",
        "df_train = df_sales.merge(df_items2,left_on='item_id',right_on='id')\n",
        "df_train[['date','item_id','item_count','store_id']]\n",
        "\n",
        "df_train = df_train.sort_values('date').groupby(['item_id', 'store_id', 'date'], as_index=False)\n",
        "df_train = df_train.agg({'item_count':['mean']})\n",
        "df_train.columns = ['item', 'store', 'date', 'sales']\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3S7LIIqG3ihU",
        "outputId": "c2a01492-14cd-4531-bec1-27df79eb51ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   item  store       date  sales\n",
              "0     1      4 2020-12-01    1.0\n",
              "1     1      4 2021-10-14    1.0\n",
              "2     2      4 2020-04-30    1.0\n",
              "3     2      4 2020-06-09    1.0\n",
              "4     2      4 2020-12-26    1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69a0d74c-fb10-4de2-aa79-96b34dc7b2e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item</th>\n",
              "      <th>store</th>\n",
              "      <th>date</th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2020-12-01</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2021-10-14</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2020-04-30</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2020-06-09</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2020-12-26</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69a0d74c-fb10-4de2-aa79-96b34dc7b2e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69a0d74c-fb10-4de2-aa79-96b34dc7b2e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69a0d74c-fb10-4de2-aa79-96b34dc7b2e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the sequence data."
      ],
      "metadata": {
        "id": "DSslf7_x3f_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window = 29\n",
        "future_span = 30\n",
        "series = series_to_supervised(df_train.drop('date', axis=1), window=window, lag=future_span)\n",
        "series.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "ZKf1jppTlvi4",
        "outputId": "b8881533-e136-4a5c-f441-235af743caa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    item(t-29)  store(t-29)  sales(t-29)  item(t-28)  store(t-28)  \\\n",
              "29         1.0          4.0          1.0         1.0          4.0   \n",
              "30         1.0          4.0          1.0         2.0          4.0   \n",
              "31         2.0          4.0          1.0         2.0          4.0   \n",
              "32         2.0          4.0          1.0         2.0          4.0   \n",
              "33         2.0          4.0          1.0         2.0          4.0   \n",
              "\n",
              "    sales(t-28)  item(t-27)  store(t-27)  sales(t-27)  item(t-26)  ...  \\\n",
              "29          1.0         2.0          4.0          1.0         2.0  ...   \n",
              "30          1.0         2.0          4.0          1.0         2.0  ...   \n",
              "31          1.0         2.0          4.0          1.0         2.0  ...   \n",
              "32          1.0         2.0          4.0          1.0         3.0  ...   \n",
              "33          1.0         3.0          1.0          4.0         3.0  ...   \n",
              "\n",
              "    sales(t-2)  item(t-1)  store(t-1)  sales(t-1)  item(t)  store(t)  \\\n",
              "29         2.0        3.0         1.0         2.0        3         1   \n",
              "30         2.0        3.0         1.0         3.0        3         1   \n",
              "31         3.0        3.0         1.0         1.0        3         1   \n",
              "32         1.0        3.0         1.0         1.0        3         1   \n",
              "33         1.0        3.0         1.0         2.0        3         1   \n",
              "\n",
              "    sales(t)  item(t+30)  store(t+30)  sales(t+30)  \n",
              "29       3.0         3.0          1.0          3.0  \n",
              "30       1.0         3.0          1.0          1.0  \n",
              "31       1.0         3.0          1.0          2.0  \n",
              "32       2.0         3.0          1.0          1.0  \n",
              "33       1.0         3.0          1.0          1.0  \n",
              "\n",
              "[5 rows x 93 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7fdcbc2-77d3-4316-bc9d-665f4f754916\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item(t-29)</th>\n",
              "      <th>store(t-29)</th>\n",
              "      <th>sales(t-29)</th>\n",
              "      <th>item(t-28)</th>\n",
              "      <th>store(t-28)</th>\n",
              "      <th>sales(t-28)</th>\n",
              "      <th>item(t-27)</th>\n",
              "      <th>store(t-27)</th>\n",
              "      <th>sales(t-27)</th>\n",
              "      <th>item(t-26)</th>\n",
              "      <th>...</th>\n",
              "      <th>sales(t-2)</th>\n",
              "      <th>item(t-1)</th>\n",
              "      <th>store(t-1)</th>\n",
              "      <th>sales(t-1)</th>\n",
              "      <th>item(t)</th>\n",
              "      <th>store(t)</th>\n",
              "      <th>sales(t)</th>\n",
              "      <th>item(t+30)</th>\n",
              "      <th>store(t+30)</th>\n",
              "      <th>sales(t+30)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 93 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7fdcbc2-77d3-4316-bc9d-665f4f754916')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7fdcbc2-77d3-4316-bc9d-665f4f754916 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7fdcbc2-77d3-4316-bc9d-665f4f754916');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove sequences that did not have enough data."
      ],
      "metadata": {
        "id": "gMBAkJvR3nce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove edge cases, where there were not enough values to complete a series\n",
        "last_item = 'item(t-%d)' % window\n",
        "last_store = 'store(t-%d)' % window\n",
        "series = series[(series['store(t)'] == series[last_store])]\n",
        "series = series[(series['item(t)'] == series[last_item])]"
      ],
      "metadata": {
        "id": "_6D8BDtu-DWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will just predict using the sales column."
      ],
      "metadata": {
        "id": "4quQLgwg3xfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all but the sales column\n",
        "columns_to_drop = [('%s(t+%d)' % (col, future_span)) for col in ['item', 'store']]\n",
        "for i in range(window, 0, -1):\n",
        "    columns_to_drop += [('%s(t-%d)' % (col, i)) for col in ['item', 'store']]\n",
        "series.drop(columns_to_drop, axis=1, inplace=True)\n",
        "series.drop(['item(t)', 'store(t)'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "RRhDirsoZ4dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the predictors (x sequences) and the label (future prediction)"
      ],
      "metadata": {
        "id": "tLrgz7RK33f1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Label\n",
        "labels_col = 'sales(t+%d)' % future_span\n",
        "labels = series[labels_col]\n",
        "series = series.drop(labels_col, axis=1)\n",
        "\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(series, labels.values, test_size=0.4, random_state=0)\n",
        "print('Train set shape', X_train.shape)\n",
        "print('Validation set shape', X_valid.shape)\n",
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "eS7mDtENnrcq",
        "outputId": "320ca2d0-2e81-44a2-9e61-26a6d0100513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape (8287, 30)\n",
            "Validation set shape (5526, 30)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      sales(t-29)  sales(t-28)  sales(t-27)  sales(t-26)  sales(t-25)  \\\n",
              "4894         20.0         10.0         12.0         12.0         16.0   \n",
              "3204          8.0          9.0          9.0         13.0         16.0   \n",
              "7790         38.0         57.0         72.0         64.0         75.0   \n",
              "4236        192.0        181.0        177.0        213.0        247.0   \n",
              "5074         16.0         15.0         16.0          3.0         10.0   \n",
              "\n",
              "      sales(t-24)  sales(t-23)  sales(t-22)  sales(t-21)  sales(t-20)  ...  \\\n",
              "4894         10.0         19.0         21.0         12.0          6.0  ...   \n",
              "3204         13.0          2.0          8.0          5.0          9.0  ...   \n",
              "7790         37.0         28.0         35.0         53.0         45.0  ...   \n",
              "4236        301.0        293.0        166.0        227.0        207.0  ...   \n",
              "5074          8.0          8.0         14.0         18.0         20.0  ...   \n",
              "\n",
              "      sales(t-9)  sales(t-8)  sales(t-7)  sales(t-6)  sales(t-5)  sales(t-4)  \\\n",
              "4894        19.0        18.0        10.0        16.0        16.0        22.0   \n",
              "3204         5.0         2.0         4.0         7.0        15.0        18.0   \n",
              "7790        21.0        34.0        39.0        71.0        73.0        55.0   \n",
              "4236       289.0       152.0       180.0       201.0       190.0       268.0   \n",
              "5074        12.0        19.0        10.0        14.0        10.0         9.0   \n",
              "\n",
              "      sales(t-3)  sales(t-2)  sales(t-1)  sales(t)  \n",
              "4894        20.0        22.0        19.0      12.0  \n",
              "3204        12.0         3.0         7.0      10.0  \n",
              "7790        27.0        30.0        34.0      40.0  \n",
              "4236       294.0       299.0       176.0     155.0  \n",
              "5074         8.0         4.0        15.0      11.0  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8830732-eeb0-430a-88bc-8ab0b89190a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sales(t-29)</th>\n",
              "      <th>sales(t-28)</th>\n",
              "      <th>sales(t-27)</th>\n",
              "      <th>sales(t-26)</th>\n",
              "      <th>sales(t-25)</th>\n",
              "      <th>sales(t-24)</th>\n",
              "      <th>sales(t-23)</th>\n",
              "      <th>sales(t-22)</th>\n",
              "      <th>sales(t-21)</th>\n",
              "      <th>sales(t-20)</th>\n",
              "      <th>...</th>\n",
              "      <th>sales(t-9)</th>\n",
              "      <th>sales(t-8)</th>\n",
              "      <th>sales(t-7)</th>\n",
              "      <th>sales(t-6)</th>\n",
              "      <th>sales(t-5)</th>\n",
              "      <th>sales(t-4)</th>\n",
              "      <th>sales(t-3)</th>\n",
              "      <th>sales(t-2)</th>\n",
              "      <th>sales(t-1)</th>\n",
              "      <th>sales(t)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4894</th>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3204</th>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7790</th>\n",
              "      <td>38.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4236</th>\n",
              "      <td>192.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>301.0</td>\n",
              "      <td>293.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>227.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>...</td>\n",
              "      <td>289.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>155.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5074</th>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8830732-eeb0-430a-88bc-8ab0b89190a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8830732-eeb0-430a-88bc-8ab0b89190a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8830732-eeb0-430a-88bc-8ab0b89190a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final preparation for the x and y."
      ],
      "metadata": {
        "id": "ip9va59y3_MR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_series = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_valid_series = X_valid.values.reshape((X_valid.shape[0], X_valid.shape[1], 1))\n",
        "print('Train set shape', X_train_series.shape)\n",
        "print('Validation set shape', X_valid_series.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iBXBGPXzw-D",
        "outputId": "f8691d5f-af85-47e2-b400-b4f3311b9db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape (8287, 30, 1)\n",
            "Validation set shape (5526, 30, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct the neural network."
      ],
      "metadata": {
        "id": "IazoyOgL4D5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Flatten, Dropout\n",
        "import keras\n",
        "\n",
        "epochs = 500 \n",
        "batch = 256\n",
        "lr = 0.0003\n",
        "adam = tf.keras.optimizers.Adam(lr)\n",
        "\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=8, activation='relu', input_shape=(X_train_series.shape[1], X_train_series.shape[2])))\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(50, activation='relu'))\n",
        "model_cnn.add(Dropout(0.2))\n",
        "model_cnn.add(Dense(1))\n",
        "model_cnn.compile(loss='mse', optimizer=adam)\n",
        "model_cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSX-MNvjz81I",
        "outputId": "92e6041e-aab2-42ae-fa7a-e862bc29da60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 23, 64)            576       \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 11, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 704)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                35250     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,877\n",
            "Trainable params: 35,877\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the neural network."
      ],
      "metadata": {
        "id": "T_StxCza4IRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, \n",
        "        verbose=1, mode='auto', restore_best_weights=True)\n",
        "\n",
        "cnn_history = model_cnn.fit(X_train_series, Y_train, callbacks=[monitor],\n",
        "    validation_data=(X_valid_series, Y_valid), epochs=epochs, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5KiECgn1P4s",
        "outputId": "771ede79-0e31-4ef7-9610-abad152ea897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "259/259 - 4s - loss: 534.3746 - val_loss: 243.1342 - 4s/epoch - 17ms/step\n",
            "Epoch 2/500\n",
            "259/259 - 1s - loss: 325.4191 - val_loss: 223.7078 - 771ms/epoch - 3ms/step\n",
            "Epoch 3/500\n",
            "259/259 - 1s - loss: 310.7113 - val_loss: 223.1814 - 767ms/epoch - 3ms/step\n",
            "Epoch 4/500\n",
            "259/259 - 1s - loss: 295.9442 - val_loss: 199.8398 - 752ms/epoch - 3ms/step\n",
            "Epoch 5/500\n",
            "259/259 - 1s - loss: 288.7663 - val_loss: 198.0298 - 764ms/epoch - 3ms/step\n",
            "Epoch 6/500\n",
            "259/259 - 1s - loss: 280.0478 - val_loss: 181.2358 - 772ms/epoch - 3ms/step\n",
            "Epoch 7/500\n",
            "259/259 - 1s - loss: 259.7377 - val_loss: 188.6393 - 758ms/epoch - 3ms/step\n",
            "Epoch 8/500\n",
            "259/259 - 1s - loss: 257.7482 - val_loss: 169.3279 - 753ms/epoch - 3ms/step\n",
            "Epoch 9/500\n",
            "259/259 - 1s - loss: 255.9915 - val_loss: 169.6519 - 774ms/epoch - 3ms/step\n",
            "Epoch 10/500\n",
            "259/259 - 1s - loss: 250.1288 - val_loss: 169.8029 - 761ms/epoch - 3ms/step\n",
            "Epoch 11/500\n",
            "259/259 - 1s - loss: 255.9437 - val_loss: 163.6035 - 760ms/epoch - 3ms/step\n",
            "Epoch 12/500\n",
            "259/259 - 1s - loss: 237.3178 - val_loss: 170.1131 - 755ms/epoch - 3ms/step\n",
            "Epoch 13/500\n",
            "259/259 - 1s - loss: 239.6099 - val_loss: 153.8241 - 755ms/epoch - 3ms/step\n",
            "Epoch 14/500\n",
            "259/259 - 1s - loss: 241.2914 - val_loss: 149.6889 - 753ms/epoch - 3ms/step\n",
            "Epoch 15/500\n",
            "259/259 - 1s - loss: 235.4144 - val_loss: 159.8309 - 765ms/epoch - 3ms/step\n",
            "Epoch 16/500\n",
            "259/259 - 1s - loss: 231.6831 - val_loss: 186.4010 - 744ms/epoch - 3ms/step\n",
            "Epoch 17/500\n",
            "259/259 - 1s - loss: 238.8115 - val_loss: 164.1463 - 756ms/epoch - 3ms/step\n",
            "Epoch 18/500\n",
            "259/259 - 1s - loss: 219.2342 - val_loss: 142.5362 - 758ms/epoch - 3ms/step\n",
            "Epoch 19/500\n",
            "259/259 - 1s - loss: 234.5049 - val_loss: 159.9804 - 751ms/epoch - 3ms/step\n",
            "Epoch 20/500\n",
            "259/259 - 1s - loss: 231.6323 - val_loss: 153.7183 - 750ms/epoch - 3ms/step\n",
            "Epoch 21/500\n",
            "259/259 - 1s - loss: 231.4603 - val_loss: 136.7291 - 752ms/epoch - 3ms/step\n",
            "Epoch 22/500\n",
            "259/259 - 1s - loss: 225.0202 - val_loss: 143.7498 - 751ms/epoch - 3ms/step\n",
            "Epoch 23/500\n",
            "259/259 - 1s - loss: 212.7610 - val_loss: 143.1392 - 766ms/epoch - 3ms/step\n",
            "Epoch 24/500\n",
            "259/259 - 1s - loss: 207.0441 - val_loss: 150.4412 - 751ms/epoch - 3ms/step\n",
            "Epoch 25/500\n",
            "259/259 - 1s - loss: 217.9191 - val_loss: 139.8079 - 747ms/epoch - 3ms/step\n",
            "Epoch 26/500\n",
            "259/259 - 1s - loss: 217.7003 - val_loss: 157.4917 - 772ms/epoch - 3ms/step\n",
            "Epoch 27/500\n",
            "259/259 - 1s - loss: 213.3011 - val_loss: 140.5591 - 807ms/epoch - 3ms/step\n",
            "Epoch 28/500\n",
            "259/259 - 1s - loss: 206.3794 - val_loss: 129.5227 - 796ms/epoch - 3ms/step\n",
            "Epoch 29/500\n",
            "259/259 - 1s - loss: 213.6339 - val_loss: 137.1772 - 807ms/epoch - 3ms/step\n",
            "Epoch 30/500\n",
            "259/259 - 1s - loss: 205.6140 - val_loss: 126.5738 - 820ms/epoch - 3ms/step\n",
            "Epoch 31/500\n",
            "259/259 - 1s - loss: 209.4032 - val_loss: 127.3860 - 801ms/epoch - 3ms/step\n",
            "Epoch 32/500\n",
            "259/259 - 1s - loss: 200.0793 - val_loss: 128.7689 - 800ms/epoch - 3ms/step\n",
            "Epoch 33/500\n",
            "259/259 - 1s - loss: 194.4818 - val_loss: 126.2912 - 850ms/epoch - 3ms/step\n",
            "Epoch 34/500\n",
            "259/259 - 1s - loss: 208.8798 - val_loss: 153.0835 - 823ms/epoch - 3ms/step\n",
            "Epoch 35/500\n",
            "259/259 - 1s - loss: 205.5164 - val_loss: 126.0270 - 783ms/epoch - 3ms/step\n",
            "Epoch 36/500\n",
            "259/259 - 1s - loss: 191.0493 - val_loss: 128.2174 - 756ms/epoch - 3ms/step\n",
            "Epoch 37/500\n",
            "259/259 - 1s - loss: 194.6040 - val_loss: 120.4376 - 752ms/epoch - 3ms/step\n",
            "Epoch 38/500\n",
            "259/259 - 1s - loss: 200.6400 - val_loss: 132.8907 - 753ms/epoch - 3ms/step\n",
            "Epoch 39/500\n",
            "259/259 - 1s - loss: 203.5839 - val_loss: 163.7641 - 749ms/epoch - 3ms/step\n",
            "Epoch 40/500\n",
            "259/259 - 1s - loss: 200.6718 - val_loss: 127.5075 - 770ms/epoch - 3ms/step\n",
            "Epoch 41/500\n",
            "259/259 - 1s - loss: 184.3470 - val_loss: 118.4742 - 754ms/epoch - 3ms/step\n",
            "Epoch 42/500\n",
            "259/259 - 1s - loss: 197.8071 - val_loss: 130.8764 - 749ms/epoch - 3ms/step\n",
            "Epoch 43/500\n",
            "259/259 - 1s - loss: 196.3720 - val_loss: 125.8956 - 751ms/epoch - 3ms/step\n",
            "Epoch 44/500\n",
            "259/259 - 1s - loss: 194.5611 - val_loss: 128.4588 - 764ms/epoch - 3ms/step\n",
            "Epoch 45/500\n",
            "259/259 - 1s - loss: 187.0020 - val_loss: 121.3136 - 752ms/epoch - 3ms/step\n",
            "Epoch 46/500\n",
            "259/259 - 1s - loss: 193.2585 - val_loss: 117.9051 - 751ms/epoch - 3ms/step\n",
            "Epoch 47/500\n",
            "259/259 - 1s - loss: 196.9094 - val_loss: 114.7912 - 749ms/epoch - 3ms/step\n",
            "Epoch 48/500\n",
            "259/259 - 1s - loss: 189.8666 - val_loss: 116.4225 - 761ms/epoch - 3ms/step\n",
            "Epoch 49/500\n",
            "259/259 - 1s - loss: 188.7653 - val_loss: 115.4200 - 751ms/epoch - 3ms/step\n",
            "Epoch 50/500\n",
            "259/259 - 1s - loss: 179.6857 - val_loss: 112.8607 - 749ms/epoch - 3ms/step\n",
            "Epoch 51/500\n",
            "259/259 - 1s - loss: 179.3693 - val_loss: 134.7600 - 753ms/epoch - 3ms/step\n",
            "Epoch 52/500\n",
            "259/259 - 1s - loss: 195.5674 - val_loss: 117.4685 - 749ms/epoch - 3ms/step\n",
            "Epoch 53/500\n",
            "259/259 - 1s - loss: 187.8603 - val_loss: 115.2012 - 753ms/epoch - 3ms/step\n",
            "Epoch 54/500\n",
            "259/259 - 1s - loss: 181.1244 - val_loss: 122.7212 - 766ms/epoch - 3ms/step\n",
            "Epoch 55/500\n",
            "259/259 - 1s - loss: 181.5116 - val_loss: 127.4135 - 749ms/epoch - 3ms/step\n",
            "Epoch 56/500\n",
            "259/259 - 1s - loss: 164.5179 - val_loss: 115.1248 - 749ms/epoch - 3ms/step\n",
            "Epoch 57/500\n",
            "259/259 - 1s - loss: 179.9965 - val_loss: 126.3080 - 760ms/epoch - 3ms/step\n",
            "Epoch 58/500\n",
            "259/259 - 1s - loss: 179.0893 - val_loss: 110.4287 - 770ms/epoch - 3ms/step\n",
            "Epoch 59/500\n",
            "259/259 - 1s - loss: 177.1024 - val_loss: 136.8620 - 757ms/epoch - 3ms/step\n",
            "Epoch 60/500\n",
            "259/259 - 1s - loss: 189.1442 - val_loss: 141.6964 - 752ms/epoch - 3ms/step\n",
            "Epoch 61/500\n",
            "259/259 - 1s - loss: 187.0331 - val_loss: 108.3848 - 756ms/epoch - 3ms/step\n",
            "Epoch 62/500\n",
            "259/259 - 1s - loss: 174.6101 - val_loss: 115.9205 - 767ms/epoch - 3ms/step\n",
            "Epoch 63/500\n",
            "259/259 - 1s - loss: 182.4131 - val_loss: 111.5508 - 751ms/epoch - 3ms/step\n",
            "Epoch 64/500\n",
            "259/259 - 1s - loss: 174.3156 - val_loss: 113.6469 - 748ms/epoch - 3ms/step\n",
            "Epoch 65/500\n",
            "259/259 - 1s - loss: 179.6464 - val_loss: 107.2464 - 750ms/epoch - 3ms/step\n",
            "Epoch 66/500\n",
            "259/259 - 1s - loss: 174.0395 - val_loss: 122.6791 - 759ms/epoch - 3ms/step\n",
            "Epoch 67/500\n",
            "259/259 - 1s - loss: 173.8847 - val_loss: 106.4355 - 752ms/epoch - 3ms/step\n",
            "Epoch 68/500\n",
            "259/259 - 1s - loss: 174.5191 - val_loss: 111.7220 - 755ms/epoch - 3ms/step\n",
            "Epoch 69/500\n",
            "259/259 - 1s - loss: 182.5755 - val_loss: 106.4279 - 756ms/epoch - 3ms/step\n",
            "Epoch 70/500\n",
            "259/259 - 1s - loss: 179.0227 - val_loss: 111.6427 - 755ms/epoch - 3ms/step\n",
            "Epoch 71/500\n",
            "259/259 - 1s - loss: 170.4133 - val_loss: 124.5790 - 755ms/epoch - 3ms/step\n",
            "Epoch 72/500\n",
            "259/259 - 1s - loss: 173.4103 - val_loss: 108.1830 - 749ms/epoch - 3ms/step\n",
            "Epoch 73/500\n",
            "259/259 - 1s - loss: 170.0203 - val_loss: 119.0359 - 756ms/epoch - 3ms/step\n",
            "Epoch 74/500\n",
            "259/259 - 1s - loss: 174.1529 - val_loss: 119.8041 - 760ms/epoch - 3ms/step\n",
            "Epoch 75/500\n",
            "259/259 - 1s - loss: 165.5825 - val_loss: 119.5476 - 748ms/epoch - 3ms/step\n",
            "Epoch 76/500\n",
            "259/259 - 1s - loss: 160.1789 - val_loss: 103.8333 - 770ms/epoch - 3ms/step\n",
            "Epoch 77/500\n",
            "259/259 - 1s - loss: 178.4714 - val_loss: 109.0537 - 770ms/epoch - 3ms/step\n",
            "Epoch 78/500\n",
            "259/259 - 1s - loss: 171.1204 - val_loss: 123.4416 - 774ms/epoch - 3ms/step\n",
            "Epoch 79/500\n",
            "259/259 - 1s - loss: 167.1411 - val_loss: 105.3124 - 780ms/epoch - 3ms/step\n",
            "Epoch 80/500\n",
            "259/259 - 1s - loss: 169.5099 - val_loss: 135.6763 - 754ms/epoch - 3ms/step\n",
            "Epoch 81/500\n",
            "259/259 - 1s - loss: 166.2160 - val_loss: 117.7358 - 757ms/epoch - 3ms/step\n",
            "Epoch 82/500\n",
            "259/259 - 1s - loss: 170.8899 - val_loss: 119.9068 - 748ms/epoch - 3ms/step\n",
            "Epoch 83/500\n",
            "259/259 - 1s - loss: 165.2713 - val_loss: 109.3580 - 749ms/epoch - 3ms/step\n",
            "Epoch 84/500\n",
            "259/259 - 1s - loss: 173.5013 - val_loss: 108.1798 - 742ms/epoch - 3ms/step\n",
            "Epoch 85/500\n",
            "259/259 - 1s - loss: 171.1246 - val_loss: 116.8206 - 750ms/epoch - 3ms/step\n",
            "Epoch 86/500\n",
            "259/259 - 1s - loss: 172.5745 - val_loss: 109.7011 - 748ms/epoch - 3ms/step\n",
            "Epoch 87/500\n",
            "259/259 - 1s - loss: 163.8832 - val_loss: 109.9100 - 743ms/epoch - 3ms/step\n",
            "Epoch 88/500\n",
            "259/259 - 1s - loss: 167.1015 - val_loss: 109.8733 - 757ms/epoch - 3ms/step\n",
            "Epoch 89/500\n",
            "259/259 - 1s - loss: 174.8773 - val_loss: 104.4042 - 756ms/epoch - 3ms/step\n",
            "Epoch 90/500\n",
            "259/259 - 1s - loss: 176.4902 - val_loss: 111.6486 - 749ms/epoch - 3ms/step\n",
            "Epoch 91/500\n",
            "259/259 - 1s - loss: 164.6084 - val_loss: 116.6756 - 754ms/epoch - 3ms/step\n",
            "Epoch 92/500\n",
            "259/259 - 1s - loss: 167.3913 - val_loss: 127.4679 - 752ms/epoch - 3ms/step\n",
            "Epoch 93/500\n",
            "259/259 - 1s - loss: 168.3584 - val_loss: 104.2409 - 772ms/epoch - 3ms/step\n",
            "Epoch 94/500\n",
            "259/259 - 1s - loss: 166.8809 - val_loss: 103.7247 - 750ms/epoch - 3ms/step\n",
            "Epoch 95/500\n",
            "259/259 - 1s - loss: 156.8664 - val_loss: 109.3127 - 750ms/epoch - 3ms/step\n",
            "Epoch 96/500\n",
            "259/259 - 1s - loss: 164.8757 - val_loss: 101.9717 - 748ms/epoch - 3ms/step\n",
            "Epoch 97/500\n",
            "259/259 - 1s - loss: 165.6959 - val_loss: 115.0455 - 759ms/epoch - 3ms/step\n",
            "Epoch 98/500\n",
            "259/259 - 1s - loss: 155.7425 - val_loss: 106.0220 - 751ms/epoch - 3ms/step\n",
            "Epoch 99/500\n",
            "259/259 - 1s - loss: 164.2804 - val_loss: 105.9661 - 781ms/epoch - 3ms/step\n",
            "Epoch 100/500\n",
            "259/259 - 1s - loss: 157.8467 - val_loss: 109.6664 - 776ms/epoch - 3ms/step\n",
            "Epoch 101/500\n",
            "259/259 - 1s - loss: 174.3026 - val_loss: 102.4105 - 769ms/epoch - 3ms/step\n",
            "Epoch 102/500\n",
            "259/259 - 1s - loss: 166.4867 - val_loss: 104.7591 - 775ms/epoch - 3ms/step\n",
            "Epoch 103/500\n",
            "259/259 - 1s - loss: 158.4684 - val_loss: 103.1221 - 776ms/epoch - 3ms/step\n",
            "Epoch 104/500\n",
            "259/259 - 1s - loss: 168.2056 - val_loss: 103.3855 - 775ms/epoch - 3ms/step\n",
            "Epoch 105/500\n",
            "259/259 - 1s - loss: 167.2082 - val_loss: 106.8491 - 779ms/epoch - 3ms/step\n",
            "Epoch 106/500\n",
            "259/259 - 1s - loss: 165.4153 - val_loss: 106.1421 - 774ms/epoch - 3ms/step\n",
            "Epoch 107/500\n",
            "259/259 - 1s - loss: 162.8059 - val_loss: 102.2934 - 768ms/epoch - 3ms/step\n",
            "Epoch 108/500\n",
            "259/259 - 1s - loss: 156.5503 - val_loss: 100.2644 - 781ms/epoch - 3ms/step\n",
            "Epoch 109/500\n",
            "259/259 - 1s - loss: 156.0921 - val_loss: 98.7450 - 782ms/epoch - 3ms/step\n",
            "Epoch 110/500\n",
            "259/259 - 1s - loss: 166.4902 - val_loss: 142.6584 - 795ms/epoch - 3ms/step\n",
            "Epoch 111/500\n",
            "259/259 - 1s - loss: 162.3320 - val_loss: 104.1857 - 781ms/epoch - 3ms/step\n",
            "Epoch 112/500\n",
            "259/259 - 1s - loss: 164.0444 - val_loss: 103.5186 - 769ms/epoch - 3ms/step\n",
            "Epoch 113/500\n",
            "259/259 - 1s - loss: 155.1736 - val_loss: 106.7364 - 776ms/epoch - 3ms/step\n",
            "Epoch 114/500\n",
            "259/259 - 1s - loss: 157.3753 - val_loss: 104.1741 - 773ms/epoch - 3ms/step\n",
            "Epoch 115/500\n",
            "259/259 - 1s - loss: 157.8772 - val_loss: 106.8095 - 764ms/epoch - 3ms/step\n",
            "Epoch 116/500\n",
            "259/259 - 1s - loss: 162.8604 - val_loss: 110.3536 - 762ms/epoch - 3ms/step\n",
            "Epoch 117/500\n",
            "259/259 - 1s - loss: 157.9943 - val_loss: 102.6516 - 765ms/epoch - 3ms/step\n",
            "Epoch 118/500\n",
            "259/259 - 1s - loss: 155.6145 - val_loss: 112.3963 - 755ms/epoch - 3ms/step\n",
            "Epoch 119/500\n",
            "259/259 - 1s - loss: 160.0831 - val_loss: 104.8978 - 749ms/epoch - 3ms/step\n",
            "Epoch 120/500\n",
            "259/259 - 1s - loss: 160.6221 - val_loss: 99.5567 - 746ms/epoch - 3ms/step\n",
            "Epoch 121/500\n",
            "259/259 - 1s - loss: 161.2841 - val_loss: 100.5693 - 743ms/epoch - 3ms/step\n",
            "Epoch 122/500\n",
            "259/259 - 1s - loss: 162.7080 - val_loss: 116.6835 - 749ms/epoch - 3ms/step\n",
            "Epoch 123/500\n",
            "259/259 - 1s - loss: 159.8466 - val_loss: 111.7226 - 748ms/epoch - 3ms/step\n",
            "Epoch 124/500\n",
            "259/259 - 1s - loss: 159.5901 - val_loss: 109.0446 - 754ms/epoch - 3ms/step\n",
            "Epoch 125/500\n",
            "259/259 - 1s - loss: 161.9229 - val_loss: 101.2987 - 751ms/epoch - 3ms/step\n",
            "Epoch 126/500\n",
            "259/259 - 1s - loss: 154.9794 - val_loss: 98.0017 - 756ms/epoch - 3ms/step\n",
            "Epoch 127/500\n",
            "259/259 - 1s - loss: 151.7313 - val_loss: 101.7958 - 745ms/epoch - 3ms/step\n",
            "Epoch 128/500\n",
            "259/259 - 1s - loss: 156.1926 - val_loss: 98.4982 - 766ms/epoch - 3ms/step\n",
            "Epoch 129/500\n",
            "259/259 - 1s - loss: 161.2892 - val_loss: 101.1576 - 744ms/epoch - 3ms/step\n",
            "Epoch 130/500\n",
            "259/259 - 1s - loss: 153.5395 - val_loss: 116.1829 - 751ms/epoch - 3ms/step\n",
            "Epoch 131/500\n",
            "259/259 - 1s - loss: 163.8622 - val_loss: 99.1916 - 752ms/epoch - 3ms/step\n",
            "Epoch 132/500\n",
            "259/259 - 1s - loss: 155.6722 - val_loss: 102.6352 - 760ms/epoch - 3ms/step\n",
            "Epoch 133/500\n",
            "259/259 - 1s - loss: 169.8555 - val_loss: 104.1989 - 749ms/epoch - 3ms/step\n",
            "Epoch 134/500\n",
            "259/259 - 1s - loss: 148.4813 - val_loss: 101.7205 - 748ms/epoch - 3ms/step\n",
            "Epoch 135/500\n",
            "259/259 - 1s - loss: 155.7908 - val_loss: 100.7896 - 752ms/epoch - 3ms/step\n",
            "Epoch 136/500\n",
            "259/259 - 1s - loss: 156.5219 - val_loss: 101.6338 - 748ms/epoch - 3ms/step\n",
            "Epoch 137/500\n",
            "259/259 - 1s - loss: 163.2767 - val_loss: 108.4493 - 752ms/epoch - 3ms/step\n",
            "Epoch 138/500\n",
            "259/259 - 1s - loss: 163.2658 - val_loss: 118.8476 - 756ms/epoch - 3ms/step\n",
            "Epoch 139/500\n",
            "259/259 - 1s - loss: 165.7785 - val_loss: 99.2436 - 749ms/epoch - 3ms/step\n",
            "Epoch 140/500\n",
            "259/259 - 1s - loss: 155.4169 - val_loss: 100.0755 - 752ms/epoch - 3ms/step\n",
            "Epoch 141/500\n",
            "259/259 - 1s - loss: 154.4266 - val_loss: 106.4590 - 755ms/epoch - 3ms/step\n",
            "Epoch 142/500\n",
            "259/259 - 1s - loss: 151.3993 - val_loss: 119.7986 - 746ms/epoch - 3ms/step\n",
            "Epoch 143/500\n",
            "259/259 - 1s - loss: 154.5401 - val_loss: 106.6994 - 755ms/epoch - 3ms/step\n",
            "Epoch 144/500\n",
            "259/259 - 1s - loss: 152.4873 - val_loss: 108.2990 - 749ms/epoch - 3ms/step\n",
            "Epoch 145/500\n",
            "259/259 - 1s - loss: 158.7697 - val_loss: 110.5243 - 771ms/epoch - 3ms/step\n",
            "Epoch 146/500\n",
            "259/259 - 1s - loss: 156.5713 - val_loss: 102.6656 - 750ms/epoch - 3ms/step\n",
            "Epoch 147/500\n",
            "259/259 - 1s - loss: 166.0648 - val_loss: 122.2937 - 752ms/epoch - 3ms/step\n",
            "Epoch 148/500\n",
            "259/259 - 1s - loss: 162.6244 - val_loss: 109.6215 - 751ms/epoch - 3ms/step\n",
            "Epoch 149/500\n",
            "259/259 - 1s - loss: 155.8725 - val_loss: 101.0333 - 767ms/epoch - 3ms/step\n",
            "Epoch 150/500\n",
            "259/259 - 1s - loss: 155.6423 - val_loss: 102.0930 - 748ms/epoch - 3ms/step\n",
            "Epoch 151/500\n",
            "259/259 - 1s - loss: 162.5428 - val_loss: 100.3563 - 749ms/epoch - 3ms/step\n",
            "Epoch 152/500\n",
            "259/259 - 1s - loss: 156.1468 - val_loss: 99.4677 - 749ms/epoch - 3ms/step\n",
            "Epoch 153/500\n",
            "259/259 - 1s - loss: 146.1859 - val_loss: 98.7400 - 754ms/epoch - 3ms/step\n",
            "Epoch 154/500\n",
            "259/259 - 1s - loss: 158.3097 - val_loss: 107.2308 - 750ms/epoch - 3ms/step\n",
            "Epoch 155/500\n",
            "259/259 - 1s - loss: 159.9518 - val_loss: 99.3238 - 763ms/epoch - 3ms/step\n",
            "Epoch 156/500\n",
            "259/259 - 1s - loss: 153.7106 - val_loss: 104.0877 - 753ms/epoch - 3ms/step\n",
            "Epoch 157/500\n",
            "259/259 - 1s - loss: 154.8703 - val_loss: 100.7749 - 744ms/epoch - 3ms/step\n",
            "Epoch 158/500\n",
            "259/259 - 1s - loss: 160.0323 - val_loss: 113.1294 - 754ms/epoch - 3ms/step\n",
            "Epoch 159/500\n",
            "259/259 - 1s - loss: 155.3203 - val_loss: 98.7603 - 752ms/epoch - 3ms/step\n",
            "Epoch 160/500\n",
            "259/259 - 1s - loss: 161.7888 - val_loss: 105.7744 - 756ms/epoch - 3ms/step\n",
            "Epoch 161/500\n",
            "259/259 - 1s - loss: 158.6053 - val_loss: 126.4133 - 748ms/epoch - 3ms/step\n",
            "Epoch 162/500\n",
            "259/259 - 1s - loss: 166.0275 - val_loss: 98.7977 - 755ms/epoch - 3ms/step\n",
            "Epoch 163/500\n",
            "259/259 - 1s - loss: 162.5443 - val_loss: 100.6001 - 765ms/epoch - 3ms/step\n",
            "Epoch 164/500\n",
            "259/259 - 1s - loss: 164.1090 - val_loss: 105.8721 - 752ms/epoch - 3ms/step\n",
            "Epoch 165/500\n",
            "259/259 - 1s - loss: 159.3695 - val_loss: 99.6702 - 757ms/epoch - 3ms/step\n",
            "Epoch 166/500\n",
            "259/259 - 1s - loss: 155.8678 - val_loss: 106.0449 - 751ms/epoch - 3ms/step\n",
            "Epoch 167/500\n",
            "259/259 - 1s - loss: 152.2622 - val_loss: 119.4251 - 758ms/epoch - 3ms/step\n",
            "Epoch 168/500\n",
            "259/259 - 1s - loss: 169.7796 - val_loss: 104.0917 - 747ms/epoch - 3ms/step\n",
            "Epoch 169/500\n",
            "259/259 - 1s - loss: 151.0841 - val_loss: 97.5941 - 754ms/epoch - 3ms/step\n",
            "Epoch 170/500\n",
            "259/259 - 1s - loss: 152.8316 - val_loss: 96.9706 - 753ms/epoch - 3ms/step\n",
            "Epoch 171/500\n",
            "259/259 - 1s - loss: 152.9190 - val_loss: 95.7911 - 745ms/epoch - 3ms/step\n",
            "Epoch 172/500\n",
            "259/259 - 1s - loss: 155.7302 - val_loss: 100.0460 - 759ms/epoch - 3ms/step\n",
            "Epoch 173/500\n",
            "259/259 - 1s - loss: 154.3168 - val_loss: 102.4294 - 744ms/epoch - 3ms/step\n",
            "Epoch 174/500\n",
            "259/259 - 1s - loss: 158.4573 - val_loss: 112.1275 - 746ms/epoch - 3ms/step\n",
            "Epoch 175/500\n",
            "259/259 - 1s - loss: 167.2237 - val_loss: 99.2747 - 750ms/epoch - 3ms/step\n",
            "Epoch 176/500\n",
            "259/259 - 1s - loss: 152.9444 - val_loss: 102.7120 - 756ms/epoch - 3ms/step\n",
            "Epoch 177/500\n",
            "259/259 - 1s - loss: 149.3327 - val_loss: 99.1905 - 755ms/epoch - 3ms/step\n",
            "Epoch 178/500\n",
            "259/259 - 1s - loss: 151.1401 - val_loss: 100.0513 - 751ms/epoch - 3ms/step\n",
            "Epoch 179/500\n",
            "259/259 - 1s - loss: 151.7689 - val_loss: 97.6161 - 751ms/epoch - 3ms/step\n",
            "Epoch 180/500\n",
            "259/259 - 1s - loss: 156.4476 - val_loss: 99.3600 - 753ms/epoch - 3ms/step\n",
            "Epoch 181/500\n",
            "259/259 - 1s - loss: 157.5348 - val_loss: 109.5083 - 769ms/epoch - 3ms/step\n",
            "Epoch 182/500\n",
            "259/259 - 1s - loss: 154.2986 - val_loss: 104.0444 - 753ms/epoch - 3ms/step\n",
            "Epoch 183/500\n",
            "259/259 - 1s - loss: 159.3505 - val_loss: 101.5792 - 747ms/epoch - 3ms/step\n",
            "Epoch 184/500\n",
            "259/259 - 1s - loss: 152.1612 - val_loss: 98.8353 - 753ms/epoch - 3ms/step\n",
            "Epoch 185/500\n",
            "259/259 - 1s - loss: 158.0960 - val_loss: 112.7097 - 760ms/epoch - 3ms/step\n",
            "Epoch 186/500\n",
            "259/259 - 1s - loss: 158.7075 - val_loss: 100.7932 - 751ms/epoch - 3ms/step\n",
            "Epoch 187/500\n",
            "259/259 - 1s - loss: 150.9221 - val_loss: 99.3903 - 753ms/epoch - 3ms/step\n",
            "Epoch 188/500\n",
            "259/259 - 1s - loss: 151.3757 - val_loss: 101.3341 - 752ms/epoch - 3ms/step\n",
            "Epoch 189/500\n",
            "259/259 - 1s - loss: 143.7967 - val_loss: 104.7607 - 751ms/epoch - 3ms/step\n",
            "Epoch 190/500\n",
            "259/259 - 1s - loss: 151.5640 - val_loss: 128.6182 - 759ms/epoch - 3ms/step\n",
            "Epoch 191/500\n",
            "259/259 - 1s - loss: 148.0475 - val_loss: 98.2254 - 753ms/epoch - 3ms/step\n",
            "Epoch 192/500\n",
            "259/259 - 1s - loss: 162.6375 - val_loss: 120.2699 - 752ms/epoch - 3ms/step\n",
            "Epoch 193/500\n",
            "259/259 - 1s - loss: 162.0282 - val_loss: 98.9024 - 753ms/epoch - 3ms/step\n",
            "Epoch 194/500\n",
            "259/259 - 1s - loss: 150.8967 - val_loss: 98.0441 - 746ms/epoch - 3ms/step\n",
            "Epoch 195/500\n",
            "259/259 - 1s - loss: 150.9973 - val_loss: 101.2911 - 753ms/epoch - 3ms/step\n",
            "Epoch 196/500\n",
            "259/259 - 1s - loss: 148.8952 - val_loss: 102.9315 - 741ms/epoch - 3ms/step\n",
            "Epoch 197/500\n",
            "259/259 - 1s - loss: 155.6102 - val_loss: 102.3326 - 755ms/epoch - 3ms/step\n",
            "Epoch 198/500\n",
            "259/259 - 1s - loss: 143.3036 - val_loss: 98.2157 - 770ms/epoch - 3ms/step\n",
            "Epoch 199/500\n",
            "259/259 - 1s - loss: 154.6579 - val_loss: 97.6465 - 745ms/epoch - 3ms/step\n",
            "Epoch 200/500\n",
            "259/259 - 1s - loss: 152.6769 - val_loss: 99.6720 - 746ms/epoch - 3ms/step\n",
            "Epoch 201/500\n",
            "259/259 - 1s - loss: 151.0228 - val_loss: 106.7564 - 754ms/epoch - 3ms/step\n",
            "Epoch 202/500\n",
            "259/259 - 1s - loss: 139.3118 - val_loss: 101.6648 - 761ms/epoch - 3ms/step\n",
            "Epoch 203/500\n",
            "259/259 - 1s - loss: 157.7694 - val_loss: 98.9845 - 752ms/epoch - 3ms/step\n",
            "Epoch 204/500\n",
            "259/259 - 1s - loss: 151.1486 - val_loss: 98.6220 - 750ms/epoch - 3ms/step\n",
            "Epoch 205/500\n",
            "259/259 - 1s - loss: 145.1622 - val_loss: 96.4123 - 743ms/epoch - 3ms/step\n",
            "Epoch 206/500\n",
            "259/259 - 1s - loss: 151.8828 - val_loss: 95.4549 - 760ms/epoch - 3ms/step\n",
            "Epoch 207/500\n",
            "259/259 - 1s - loss: 152.2305 - val_loss: 115.8005 - 755ms/epoch - 3ms/step\n",
            "Epoch 208/500\n",
            "259/259 - 1s - loss: 141.9689 - val_loss: 100.4193 - 748ms/epoch - 3ms/step\n",
            "Epoch 209/500\n",
            "259/259 - 1s - loss: 155.4704 - val_loss: 127.6424 - 750ms/epoch - 3ms/step\n",
            "Epoch 210/500\n",
            "259/259 - 1s - loss: 154.5122 - val_loss: 100.3673 - 760ms/epoch - 3ms/step\n",
            "Epoch 211/500\n",
            "259/259 - 1s - loss: 145.5497 - val_loss: 99.5998 - 750ms/epoch - 3ms/step\n",
            "Epoch 212/500\n",
            "259/259 - 1s - loss: 158.7682 - val_loss: 96.5476 - 754ms/epoch - 3ms/step\n",
            "Epoch 213/500\n",
            "259/259 - 1s - loss: 162.6133 - val_loss: 100.1301 - 758ms/epoch - 3ms/step\n",
            "Epoch 214/500\n",
            "259/259 - 1s - loss: 140.9594 - val_loss: 103.9695 - 756ms/epoch - 3ms/step\n",
            "Epoch 215/500\n",
            "259/259 - 1s - loss: 150.2013 - val_loss: 110.3011 - 750ms/epoch - 3ms/step\n",
            "Epoch 216/500\n",
            "259/259 - 1s - loss: 155.0168 - val_loss: 99.6476 - 770ms/epoch - 3ms/step\n",
            "Epoch 217/500\n",
            "259/259 - 1s - loss: 150.6265 - val_loss: 102.0614 - 745ms/epoch - 3ms/step\n",
            "Epoch 218/500\n",
            "259/259 - 1s - loss: 150.9877 - val_loss: 117.5129 - 742ms/epoch - 3ms/step\n",
            "Epoch 219/500\n",
            "259/259 - 1s - loss: 146.5779 - val_loss: 105.7517 - 745ms/epoch - 3ms/step\n",
            "Epoch 220/500\n",
            "259/259 - 1s - loss: 147.0643 - val_loss: 108.5999 - 762ms/epoch - 3ms/step\n",
            "Epoch 221/500\n",
            "259/259 - 1s - loss: 151.3065 - val_loss: 106.0378 - 746ms/epoch - 3ms/step\n",
            "Epoch 222/500\n",
            "259/259 - 1s - loss: 142.9344 - val_loss: 98.1449 - 751ms/epoch - 3ms/step\n",
            "Epoch 223/500\n",
            "259/259 - 1s - loss: 149.1874 - val_loss: 103.6972 - 751ms/epoch - 3ms/step\n",
            "Epoch 224/500\n",
            "259/259 - 1s - loss: 147.0690 - val_loss: 99.3417 - 745ms/epoch - 3ms/step\n",
            "Epoch 225/500\n",
            "259/259 - 1s - loss: 149.8232 - val_loss: 98.7769 - 749ms/epoch - 3ms/step\n",
            "Epoch 226/500\n",
            "259/259 - 1s - loss: 142.8475 - val_loss: 95.7019 - 749ms/epoch - 3ms/step\n",
            "Epoch 227/500\n",
            "259/259 - 1s - loss: 150.6133 - val_loss: 119.1359 - 755ms/epoch - 3ms/step\n",
            "Epoch 228/500\n",
            "259/259 - 1s - loss: 147.8935 - val_loss: 97.7824 - 743ms/epoch - 3ms/step\n",
            "Epoch 229/500\n",
            "259/259 - 1s - loss: 145.2047 - val_loss: 100.4628 - 748ms/epoch - 3ms/step\n",
            "Epoch 230/500\n",
            "259/259 - 1s - loss: 148.8222 - val_loss: 100.0668 - 749ms/epoch - 3ms/step\n",
            "Epoch 231/500\n",
            "259/259 - 1s - loss: 141.7930 - val_loss: 101.7889 - 746ms/epoch - 3ms/step\n",
            "Epoch 232/500\n",
            "259/259 - 1s - loss: 145.3553 - val_loss: 98.4147 - 758ms/epoch - 3ms/step\n",
            "Epoch 233/500\n",
            "259/259 - 1s - loss: 153.2442 - val_loss: 99.7427 - 760ms/epoch - 3ms/step\n",
            "Epoch 234/500\n",
            "259/259 - 1s - loss: 149.5396 - val_loss: 104.3523 - 750ms/epoch - 3ms/step\n",
            "Epoch 235/500\n",
            "259/259 - 1s - loss: 141.9038 - val_loss: 103.2531 - 752ms/epoch - 3ms/step\n",
            "Epoch 236/500\n",
            "259/259 - 1s - loss: 152.1796 - val_loss: 109.8017 - 752ms/epoch - 3ms/step\n",
            "Epoch 237/500\n",
            "259/259 - 1s - loss: 138.8532 - val_loss: 102.3207 - 744ms/epoch - 3ms/step\n",
            "Epoch 238/500\n",
            "259/259 - 1s - loss: 154.6443 - val_loss: 99.1005 - 760ms/epoch - 3ms/step\n",
            "Epoch 239/500\n",
            "259/259 - 1s - loss: 148.7749 - val_loss: 104.3260 - 750ms/epoch - 3ms/step\n",
            "Epoch 240/500\n",
            "259/259 - 1s - loss: 144.8641 - val_loss: 97.7534 - 745ms/epoch - 3ms/step\n",
            "Epoch 241/500\n",
            "259/259 - 1s - loss: 150.3512 - val_loss: 99.7636 - 745ms/epoch - 3ms/step\n",
            "Epoch 242/500\n",
            "259/259 - 1s - loss: 146.9173 - val_loss: 97.6488 - 749ms/epoch - 3ms/step\n",
            "Epoch 243/500\n",
            "259/259 - 1s - loss: 148.5014 - val_loss: 98.5623 - 750ms/epoch - 3ms/step\n",
            "Epoch 244/500\n",
            "259/259 - 1s - loss: 140.6281 - val_loss: 100.9921 - 749ms/epoch - 3ms/step\n",
            "Epoch 245/500\n",
            "259/259 - 1s - loss: 149.7210 - val_loss: 108.9096 - 747ms/epoch - 3ms/step\n",
            "Epoch 246/500\n",
            "259/259 - 1s - loss: 143.7832 - val_loss: 103.3988 - 754ms/epoch - 3ms/step\n",
            "Epoch 247/500\n",
            "259/259 - 1s - loss: 143.0319 - val_loss: 112.6661 - 749ms/epoch - 3ms/step\n",
            "Epoch 248/500\n",
            "259/259 - 1s - loss: 141.2686 - val_loss: 117.7205 - 750ms/epoch - 3ms/step\n",
            "Epoch 249/500\n",
            "259/259 - 1s - loss: 152.1608 - val_loss: 102.3575 - 749ms/epoch - 3ms/step\n",
            "Epoch 250/500\n",
            "259/259 - 1s - loss: 148.0277 - val_loss: 98.1328 - 752ms/epoch - 3ms/step\n",
            "Epoch 251/500\n",
            "259/259 - 1s - loss: 149.4496 - val_loss: 115.9959 - 770ms/epoch - 3ms/step\n",
            "Epoch 252/500\n",
            "259/259 - 1s - loss: 138.9805 - val_loss: 100.0680 - 751ms/epoch - 3ms/step\n",
            "Epoch 253/500\n",
            "259/259 - 1s - loss: 141.7404 - val_loss: 98.7078 - 753ms/epoch - 3ms/step\n",
            "Epoch 254/500\n",
            "259/259 - 1s - loss: 149.1494 - val_loss: 104.3607 - 751ms/epoch - 3ms/step\n",
            "Epoch 255/500\n",
            "259/259 - 1s - loss: 149.2951 - val_loss: 105.2974 - 760ms/epoch - 3ms/step\n",
            "Epoch 256/500\n",
            "Restoring model weights from the end of the best epoch: 206.\n",
            "259/259 - 1s - loss: 138.2778 - val_loss: 116.4224 - 752ms/epoch - 3ms/step\n",
            "Epoch 256: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict and evaluate the validation data."
      ],
      "metadata": {
        "id": "O-Q08cT94MU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "cnn_train_pred = model_cnn.predict(X_train_series)\n",
        "cnn_valid_pred = model_cnn.predict(X_valid_series)\n",
        "print('Train rmse:', np.sqrt(mean_squared_error(Y_train, cnn_train_pred)))\n",
        "print('Validation rmse:', np.sqrt(mean_squared_error(Y_valid, cnn_valid_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyUB1nSG9fhr",
        "outputId": "4dc4371f-d940-456f-bf1d-7605893a21ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rmse: 9.176975122603912\n",
            "Validation rmse: 9.770104572641024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the training curve."
      ],
      "metadata": {
        "id": "wYNHiuuk4QAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#fig, axes = plt.subplots(2, 2, sharex=True, sharey=True,figsize=(22,12))\n",
        "#ax1, ax2 = axes[0]\n",
        "#ax3, ax4 = axes[1]\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(cnn_history.history['loss'], label='Train loss')\n",
        "plt.plot(cnn_history.history['val_loss'], label='Validation loss')\n",
        "fig.legend()\n",
        "fig.suptitle('CNN')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"MSE\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "qbAvkOwmCdao",
        "outputId": "db0f51b2-af63-46e8-cdbc-f6e891c58c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAEkCAYAAACR9x5gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3wUdf7H8dd3d9N7T0gICZBq6AiCAgKKvXewnOX01LuzlztPf57lTs/z9PA89dTzsGEBFRREepMeIJRAIEAgvfdGkp3fHzObAimUhGTdz/PxyGN3Z2Znv5vAvvdbR2mahhBCCNGXmXq7AEIIIURXJKyEEEL0eRJWQggh+jwJKyGEEH2epbcLIIQQPS05OTnYYrF8ACQhX9L7Miuwq7Gx8Z5Ro0YVtN4hYSWE+MWzWCwfhIaGJgQFBZWaTCYZAt1HWa1WVVhYmJiXl/cBcGXrffINQwjhCJKCgoIqJKj6NpPJpAUFBZWj14Db7uuF8gghxJlmkqCyD8bf6bhskrASogNKqelKqS1KqSqlVK5S6kel1HlKqeeVUppS6sZWx1qMbVHG4/8Zj8e0OmawUko+MB1QXl6eOT4+PjE+Pj4xMDBwWHBw8FDb47q6OtXZc1evXu3+q1/9qv/JvF54ePiQ3NzcX1Q3zy/qzQjRXZRSjwJPA78BfgKOAhcDVwHVQAnwZ6XUXE3Tmjo4TQnwEjCt50ss+rLQ0NCmvXv3pgI8+uij/Tw9PZteeOGFfNv+hoYGnJyc2n3uxIkTayZOnFhzhoraZ0nNSohjKKV8gBeABzVN+0bTtGpN0xo0Tfte07QnjMMWoQfYrZ2cahYwVCk1qYeLLOzQddddFzV9+vTIoUOHxt9///0RK1ascB8+fHh8QkJC4ogRI+JTUlJcAH744QevyZMnDwY96G644YaoMWPGxEVERAx56aWXgrt6neeffz4kJibmrJiYmLNeeOGFYICKigrT+eefPzguLi4xJibmrPfff98P4IEHHggfNGjQWbGxsYn33ntvRE++/5MlNSshjjcOcAW+7eQYDXgWeFMp9bnx+Fg1wF+Al4HzuruQ4tQ8MSel/768SvfuPGdsqFfNa9cPyzzZ5+Xm5jpv3bp1r8VioaSkxLR58+a9Tk5OfPfdd15PPvlkxE8//XTg2Oekp6e7rlu3Lq2srMyckJCQ9MQTTxS6uLi027y8Zs0a988//zwgOTl5j6ZpjBo1KmHq1KmV+/fvdwkNDW1YuXJlOkBxcbE5Ly/PvHDhQr+DBw/uMplMFBUVmU/+N9FzpGYlxPECgCJN0xo7O0jTtPlAIXBPJ4e9B0QqpS7pxvKJX4hrr7221GLR6wwlJSXmSy+9dFBMTMxZTz75ZP99+/a5tvecadOmlbm5uWlhYWGN/v7+DVlZWR1WOlauXOl56aWXlnl7e1t9fHysl112WemKFSu8Ro4cWbtmzRrv+++/P3zRokWeAQEBTQEBAU0uLi7Wm266KWrWrFm+np6e1h5626dEalZCHK8YCFRKWboKLOBPwEfAJ+3t1DStXin1IvAicHP3FlOcilOpAfWU1oHw1FNPhU+aNKlyyZIlB9LS0pynTJkS195zWteizGYzjY2NnQ7QaM/QoUPrt27dmjp37lyfZ599Nnzp0qUVf//733O3b9++Z/78+d5z5szxe+edd4I3bNiw79TeWfeTmpUQx1sP1ANXd3WgpmlLgHTggU4O+wjwBa7tltKJX6SKigpzRETEUYD33nsvsDvOOXny5KqFCxf6VlZWmioqKkwLFy70mzx5cmVGRoaTl5eX9YEHHih59NFH87Zv3+5eXl5uKikpMd90003l7777bubevXu7tan0dEnNSohjaJpWrpR6DnhbKdUILAYagAuAyeh9Ua09A8zr5HyNSqn/A2b2UJHFL8BTTz2Vd88990S/+uqr/S688MKy7jjneeedVzN9+vTikSNHJgDcdtttheeee27t3Llzvf/whz9EmEwmLBaL9u9///twWVmZ+fLLLx9cX1+vAF588cU+UwMFUHLxRSHap5SaATwCJACVQDL6YIlpwGBN025tdexC4BIgWtO0DKXU/4AsTdP+ZOw3ATuAszRNO+lmG3F6UlJSMoYNG1bU2+UQJyYlJSVw2LBhUa23Sc1KiA5omvYZ8Fk7u9a1c+ylxzz+1TGPrbSzhIwQ4sRIn5UQQog+T8JKCCFEnydhJYQQos+TsBJCCNHnSVgJIYTo8ySshBCih40dOzZ27ty53q23vfDCC8EzZsyI7Og5Y8aMiVu9erU7wKRJkwa3t1bfo48+2u+5554L6ey1P/nkE9/k5OTmpZsefvjhft99953Xyb+LtlovsHsmSFgJIUQPu+GGG0pmz57t33rb3Llz/W+99daSE3n+qlWr0gMDAzu6FE2nvvvuO98dO3a42R6/+eabOVdffXXlqZyrN0lYCSFED7vttttKly9f7mO70GJaWppzQUGB00UXXVQ1Y8aMyKSkpITBgwef9cgjj/Rr7/mtL6b41FNPhUZFRSWNGjUqbv/+/S62Y15//fXApKSkhLi4uMSLLrpoUGVlpWnJkiUeS5cu9f3Tn/4UER8fn7h7926X6667Luqjjz7yA5g3b55XQkJCYmxsbOINN9wQVVtbq2yv98gjj/RLTExMiI2NTdy2bVu7i+ra5Ofnmy+44IJBsbGxicOGDYvfuHGjG8CCBQs8bReZTEhISCwtLTUdPnzYafTo0XHx8fGJMTExZy1atMjzRH6HMilYCOFYvnuwPwWp3bvuXXBiDVe/3eHyRCEhIU3Dhg2rnjNnjs+tt95aNmvWLP8rrrii1GQy8Y9//CM7JCSkqbGxkfHjx8dt3LjRbezYsbXtnWfNmjXu3377rf/OnTtTGxoaGD58eOKIESNqAGbMmFH62GOPFQH8/ve/7zdz5szAZ555puCCCy4ou/zyy8vvvPPO0tbnqqmpUffdd1/04sWL04YOHVp/zTXXRL322mtBzz33XAFAYGBgY2pq6p5XXnkl6JVXXgn58ssvD3f0/p588sl+w4YNq1m6dOmB+fPne91xxx3Re/fuTX399ddDZ86ceXjatGnV5eXlJnd3d+ubb74ZNHXq1PJXX301r7GxkcrKyhOqNEnNSgghzoAbb7yx5Msvv/QD+Oabb/xvu+22EoBZs2b5JyYmJiQmJibu37/fNSUlpcNazIoVKzwvvfTSMi8vL6u/v7912rRpzWsIJicnu40aNSouNjY2ce7cuQG7d+/utDaUkpLiGhERUT906NB6gF/96lfFa9eube7Lmj59einAmDFjajIzM106Og/Apk2bvO6+++5igCuvvLKyrKzMUlJSYjrnnHOqHn/88f4vvfRScFFRkdnJyYlzzjmnevbs2YGPPvpov02bNrn5+fmd0KVIpGYlhHAsndSAetL06dPLnnnmmf5r1651r6urM02YMKFm7969zv/6179CkpOT9wQFBTVdd911UXV1dadUibj33nuj58yZkz5u3LjamTNnBqxateq0BlG4urpqABaLRTuVy5AA/OUvf8m7+uqry+fNm+czYcKE+AULFuy/5JJLqlavXp02d+5cn7vuuiv6t7/9bf5vf/vb4q7OJTUrIYQ4A3x8fKzjxo2rvOeee6KuueaaEoDS0lKzm5ub1d/fvykzM9OycuVKn87OMWXKlKqFCxf6VlVVqdLSUtOSJUt8bftqampMkZGRDfX19eqLL75oHszh6enZVFFRcdxn/bBhw+qys7Odd+3a5QLw8ccfB0yYMOGUBl6MHTu28qOPPgoAfZSgn59fo7+/v3X37t0uY8aMqX355Zfzhg4dWr1r1y7Xffv2OUdERDQ89thjRbfffnvh1q1bT6hJVmpWQghxhtx8880lt99++6DZs2cfBBg3blxtUlJSzaBBg5LCwsKOjho1qqqz55933nk111xzTUlSUtJZAQEBDUOHDq227Xv66adzxowZk+Dv7984cuTIqqqqKjPAjBkzSu6///6od999N2TOnDkHbMe7u7tr7777bsYNN9wwqKmpiWHDhtU8/vjjhafyvl599dWcGTNmRMXGxia6ublZ//e//x0C+Nvf/ha8bt06b6WUFhcXV3v99deXf/DBB/4zZ84MtVgsmru7e9Nnn3126EReQy4RIoT4xZNLhNiX9i4RIs2AQggh+jwJKyGEEH2ehJUQQog+z64HWAQGBmpRUVG9XQwhRB/36quvsnv37gFKndII7F+c+vr6xhEjRqT0djnaY7VaFXDc3Cu7DquoqCi2bNnS28UQQvRxhw4dwsvLi4CAACSwYNeuXUd7uwztsVqtqrCw0AfYdew+uw4rIYQ4EREREWRlZVFYeEojs39x8vLyLE1NTYG9XY52WIFdjY2N9xy7Q8JKCPGL5+TkRHR0dG8Xo89ITEzcqWna6N4ux8mQARZCCCH6PAkrIYQQfZ6ElRBCiD5PwkoIIUSfJ2ElhBCiz3PIsNqcUcLri9NoaDqha34JIYToZQ4ZVlsPl/LW8nSONkpYCSGEPXDIsDKb9BnsTXJ5FCGEsAuOHVZNElZCCGEPHDuspGYlhBB2wSHDymQsZGm1SlgJIYQ9cMiwskjNSggh7IpDhpXJCKtG6bMSQgi74JBhZbY1A0rNSggh7IJjhpWtGVD6rIQQwi44dFhJzUoIIeyDQ4dVo9SshBDCLjhkWNmGrkszoBBC2IceDSulVIZSaqdSartSaouxzV8ptUQptd+49TO2K6XUTKVUulJqh1JqZE+Vq7kZUJYGFEIIu3AmalaTNU0brmnaaOPx08AyTdNigGXGY4BLgBjj517gnZ4qkMyzEkII+9IbzYBXAbOM+7OAq1tt/1jTbQB8lVJhPVEAU/NoQKlaCSGEPejpsNKAxUqpZKXUvca2EE3Tco37eUCIcT8cyGz13CxjW7czN/dZ9cTZhRBCdDdLD5//PE3TspVSwcASpdTe1js1TdOUUifVFmeE3r0AkZGRp1QokxHRMsBCCCHsQ4/WrDRNyzZuC4BvgTFAvq15z7gtMA7PBvq3enqEse3Yc/5H07TRmqaNDgoKOqVyWYy0knlWQghhH3osrJRSHkopL9t9YBqwC5gP3GEcdgcwz7g/H7jdGBV4DlDeqrmwW5mlZiWEEHalJ5sBQ4Bvld4/ZAE+1zRtkVJqM/CVUupu4DBwo3H8QuBSIB2oAe7sqYLJPCshhLAvPRZWmqYdBIa1s70YmNrOdg14sKfK05qsDSiEEPbFIVewkCsFCyGEfXHosJIrBQshhH1wzLBSspCtEELYE4cMK5NcIkQIIeyKQ4aVRQZYCCGEXXHIsJKh60IIYV8cMqxk6LoQQtgXxw4r6bMSQgi74NBhJUPXhRDCPjhmWEmflRBC2BWHDCvb0HWZZyWEEPbBIcPKLPOshBDCrjhkWLXMs+rlggghhDghDhlWtnlWUrMSQgj74JBhZWsGbGySsBJCCHvgkGFlZJXMsxJCCDvhkGGllMKkZJ6VEELYC4cMKwCLySQ1KyGEsBMOG1Ymk9SshBDCXjhsWJmVkknBQghhJxw2rEwmJcstCSGEnXDYsLKYlMyzEkIIO+GwYWWWmpUQQtgNhw0rk5KwEkIIe+GwYSU1KyGEsB+OHVbSZyWEEHbBocNK5lkJIYR9cNywknlWQghhNxw2rEwydF0IIeyGw4aVRQZYCCGE3XDYsNKHrvd2KYQQQpwIhw0rfei6pJUQQtgDhw0rk0khFwoWQgj74LBhZZGh60IIYTccNqzMstySEELYDYcNK5MJCSshhLATPR5WSimzUmqbUuoH43G0UmqjUipdKfWlUsrZ2O5iPE439kf1ZLlkuSUhhLAfZ6Jm9RCwp9XjV4E3NE0bDJQCdxvb7wZKje1vGMf1GLPJJDUrIYSwEz0aVkqpCOAy4APjsQKmAHOMQ2YBVxv3rzIeY+yfahzfI8wKWcFCCCHsRE/XrN4EngRsE5oCgDJN0xqNx1lAuHE/HMgEMPaXG8f3CLlEiBBC2I8eCyul1OVAgaZpyd183nuVUluUUlsKCwtP+Txy8UUhhLAfPVmzOhe4UimVAXyB3vz3T8BXKWUxjokAso372UB/AGO/D1B87Ek1TfuPpmmjNU0bHRQUdMqFs5glrIQQwl70WFhpmvYHTdMiNE2LAm4GlmuaNgNYAVxvHHYHMM+4P994jLF/uab1XKeSScloQCGEsBe9Mc/qKeBRpVQ6ep/Uh8b2D4EAY/ujwNM9WQi5+KIQQtgPS9eHnD5N01YCK437B4Ex7RxTB9xwJsoDcvFFIYSwJw67goXUrIQQwn44dFhJn5UQQtgHhw0rk0kuviiEEPbCYcNKX3Vd0koIIeyB44aVrGAhhBB2w6HDSrJKCCHsg0OHldSshBDCPjhsWMnagEIIYT8cNqwsMnRdCCHshsOGlUmaAYUQwm44bFiZjes6yioWQgjR9zluWBnvXNYHFEKIvs+Bw0p/63JpeyGE6PscOKz0W+m3EkKIvs9hw8pk9FnJiEAhhOj7HDaszCYZYCGEEPbCYcPKYoSVDLAQQoi+z2HDyiQ1KyGEsBsOG1Zm6bMSQgi74bBhZatZyWhAIYTo+xw2rCwSVkIIYTccNqzMElZCCGE3HDasbPOsZAULIYTo+xw2rFpqVr1cECGEEF1y+LBqtEpaCSFEX9dpWCmlbm11/9xj9v22pwp1JrRcIqSXCyKEEKJLXdWsHm11/61j9t3VzWU5o5qbAaXPSggh+ryuwkp1cL+9x3ZF5lkJIYT96CqstA7ut/fYrrg7mwGorGvo5ZIIIYToiqWL/fFKqR3otahBxn2MxwN7tGQ9bHCQJwD78is5Py64l0sjhBCiM12FVcIZKUUv8PNwJtTblb25lb1dFCGEEF3oNKw0TTvc+rFSKgCYCBzRNC25Jwt2JsSHebEnT8JKCCH6uq6Grv+glEoy7ocBu9BHAX6ilHr4DJSvR8WHepNeUEmDzAwWQog+rasBFtGapu0y7t8JLNE07QpgLHY+dB0gIcyLhiaNg4XVvV0UIYQQnegqrFoPlZsKLATQNK0SsPvqSHyoNwB78yp6uSRCCCE601VYZSqlfqeUugYYCSwCUEq5AU49XbieNjDIA2eziT0yyEIIIfq0rsLqbuAs4FfATZqmlRnbzwE+6uyJSilXpdQmpVSKUmq3UurPxvZopdRGpVS6UupLpZSzsd3FeJxu7I86jfd1QpzMJgYHe7InV2pWQgjRl3UaVpqmFWia9htN067SNG1xq+0rNE37exfnrgemaJo2DBgOXKyUOgd4FXhD07TBQCl6IGLclhrb3zCO63HxYV7SDCiEEH1cp0PXlVLzO9uvadqVnezTgCrjoZPxowFTgOnG9lnA88A7wFXGfYA5wL+UUso4T49JCPXmm63ZlFQfxd/DuSdfSgghxCnqalLwOCATmA1s5CTXA1RKmYFkYDDwNnAAKNM0rdE4JAsIN+6HG6+FpmmNSqlyIAAoOpnXPFnxYV6APshi/KDAnnwpIYQQp6irPqtQ4I9AEvBP4EKgSNO0VZqmrerq5JqmNWmaNhyIAMYA8adZXpRS9yqltiilthQWFp7u6VpGBMogCyGE6LO66rNq0jRtkaZpd6APqkgHVp7stayMgRkr0GtqvkopW40uAsg27mcD/QGM/T5AcTvn+o+maaM1TRsdFBR0MsVoV5CXC4GeLmzPLOv6YCGEEL2iyysFG6P0rgU+BR4EZgLfnsDzgpRSvsZ9N/Ra2R700LreOOwOYJ5xf77xGGP/8p7ur7K5MDGYpXvyqa5v7PpgIYQQZ1xXyy19DKxHn2P1Z03TztY07UVN07I7e54hDFhhrNS+GX31ix+Ap4BHlVLp6H1SHxrHfwgEGNsfBZ4+pXd0Cq4dGUHN0SZ+2p13pl5SCCHESVCdVV6UUlbAthZR6wMV+oA/7x4sW5dGjx6tbdmy5bTPo2kak15bSaS/O5/eM7YbSiaEEH2XUipZ07TRvV2Ok9FVn5VJ0zQv48e71Y9XbwdVd1JKcfnQMNYfLKa8Ri7GKIQQfU2XfVaO4oLEEJqsGiv3FfR2UYQQQhxDwsowPMKXQE9nlu6RsBJCiL5GwspgMimmxoewcm8BVusZGYQohBDiBElYtTK0vw+V9Y3kV9b1dlGEEEK0ImHVSn8/dwAyS2p7uSRCCCFak7Bqpb+/HlZHSmp6uSRCCCFak7BqJdzXDaUgU8JKCCH6FAmrVpwtJsK8XSWshBCij5GwOkZ/f3cySyWshBCiL5GwOkZ/f3fpsxJCiD5GwuoY/f3cya+op66hqbeLIoQQwiBhdYzIADcAVu07/Qs7CiGE6B4SVseYFBvMwCAP7vskmZcXpFLf2ISmadQ3Sk1LCCF6i6XrQxyLv4czC343gZcWpPL+mkNUH20i2MuF2ZuOsP7pqZhMqreLKIQQDkfCqh1uzmZevmYIGjBnSxYuFlPzMkxhPm69XTwhhHA40gzYiV9PGEiD1Uqlcbn7jCIZJSiEEL1BwqoT0YEe3DAqghGRvgBkFFd38QwhhBA9QZoBu/C364fRZNVIeHaRhJUQQvQSx6xZFaVDyhcnfLjZpOjv70ZGkYSVEEL0BscMq7SF8O19UFt2wk+JCvDgcHENjU1W5iRncUiCSwghzhjHDCv/aP229NAJPyUq0INDRdVc9fbPPP51Ck/P3QFAfWMTq2UCsRBC9CjHDCu/KP225CTCKsCd+kYrmSU1XD40jI2HStiRVcZ/12Zw+383caCwqmfKKoQQwkEHWNjCqjTjhJ9yQWIImzNK+f3UGEK8XViVVshby9M5aITUocJqDhdXExviRYRxxWEhhBDdwzHDysULPIJOqhkwzMeNmbeMaH78m/MH8dpPac2P0/Ir+ceSfYR6u/L+7aMZGOSBq5O5W4sthBCOyjGbAQH8ok+qGfBYv5k0iLOj/HBzMuPubGb53gKarBrZZbVcOnMN095YTUOTtRsLLIQQjstxw8o/+qSaAY9lNik+/NXZzPvtuUQFeLD1SCkAH94xmt9PGcyRkhqW7cnvpsIKIYRjc9yw8ouG8ixorD/lU3i7OhEb4sWAAHc0DZwtJibFBvHQBbH083Hl0w1HurHAQgjhuBw3rPyjAQ02/BvqT28kX6S/PqBicJAnFrMJs0lxy5hI1qYXkVde1w2FFUIIx+a4YRVxNniGwNLnYdsnp3WqyAA9rOJCvZq3TYwNAmCb0TwohBDi1DluWAUMgsfSwMkDSg+f1qkG+HsAbcMqIcwbZ4uJbZknvkqGEEKI9jluWAEoBT7hUJF1WqdJCvdmSLgP58cFNW9ztpg4q58324/oYfXg51tJ+r+fePDzrVit2mm9nhBCOBrHDisA73Aozz6tU/i6O/P9784jPtS7zfYR/f3YkV1GZV0Di3fnEeTlwoIduXy1JfO0Xk8IIRyNhJVPOFScXlh1ZHikL3UNVmZvOkJDk8ZzlycyJsqfVxftJb+ijtEvLeWrzRJcQgjRFQkr7wioKoDGo91+6nMG+uNkVsxclo5JwegoP568OI7SmgZ+P3sbRVX1fLklk6ONVmqONnb76wshxC+FhJVPOKBBZU63nzrYy5WrhodTVd/IWf188HJ1YtQAPwYGebDxUAkAyYdLufG99Vz773UA1DU0cfXbPzNve8/U9oQQwh71WFgppforpVYopVKVUruVUg8Z2/2VUkuUUvuNWz9ju1JKzVRKpSuldiilRvZU2drwidBvT7PfqiP3TRwIwNhofwCUUtw4uj8A14wIB2B7Zhl78yo5XFxNWl4l2zPLeGLODnZll/dImYQQwt70ZM2qEXhM07RE4BzgQaVUIvA0sEzTtBhgmfEY4BIgxvi5F3inB8vWwtsIqx7qt4oJ8WL2r8/hwcmDm7fdfHZ/bj67P89clsDZUX6cM1APspVphezJrQDArBTvrDrQ/JzGJiufbDgsk4yFEA6px8JK07RcTdO2GvcrgT1AOHAVMMs4bBZwtXH/KuBjTbcB8FVKhfVU+Zr56LUbyk9v+Hpnxg0KwM/Dufmxr7szr1w3lEBPF766bxyzf30OUQHurEwrYE9uBR7OZibEBLInRw8uTdP447c7efa7XUz/YAMl1d3fvyaEEH3ZGemzUkpFASOAjUCIpmm5xq48IMS4Hw60HhqXZWzrWc4e4OoLh1bD0TN/qXqlFEopzo8LZv3BYrYcLiU+zJvEft4cKq6m5mgjP+zI5astWVw9vB9ZJbXMXLb/jJdTCCF6U4+HlVLKE5gLPKxpWkXrfZqmacBJzZBVSt2rlNqilNpSWNhNl5Mf/zs4uAK+vrN7zncKrh0ZTl2Dld05FSSEeZEQ5o2mQVpeJR+sOcjAQA/+ceNwhvX3ITWngh925HD5W2uYn5KD/mvUHSqqZkmqrPYuhPhl6dGwUko5oQfVZ5qmfWNszrc17xm3Bcb2bKB/q6dHGNva0DTtP5qmjdY0bXRQUNCxu0/NxMdh9N1weB1ovbO6xNAIX84dHADoSzUlhukTjD/dcISUrHLuPDcKk0kxONiTfQWVLNiRy67sCn4/ext3z9pCRV0D5bUN3PrBRu79ZAs5ZbVtzv/l5iP8+uMtbYJNCCHsRU+OBlTAh8AeTdP+0WrXfOAO4/4dwLxW2283RgWeA5S3ai7seSGJcLQSKs/cSx7roamxuDmZGRvtT4SfG14uFuZuzSLAw5lrR+oDQQYHe1FW08C6A8VckhTK/12RyIq0Av73cwYv/ZBKXkUdmgbfbmub84t25bEkNZ/U3Ir2XloIIfq0nqxZnQvcBkxRSm03fi4FXgEuVErtBy4wHgMsBA4C6cD7wAM9WLbjBcbqt0X7zujLtjYm2p/df76IwcFeKKWID9MXxn39xmF4uFgAGBzsCUB5bQNDI3y589xozo7y58vNmXy7LZs7xkUxNtqfr7dkUtfQ1Hzu/QX6ZVC+T+m9MBZCiFPVk6MB12qapjRNG6pp2nDjZ6GmacWapk3VNC1G07QLNE0rMY7XNE17UNO0QZqmDdE0bUtPla1dtrDavwRmT4fa3lkt3WRSzfcfviCW128Yxvlxwc3bYoywAn0BXYCrhvcju6yWJk3jjvEDuG3cADKKaxj/ynL251dSc7SRrOa6qUUAACAASURBVFK9WfD7Y/q4WqtraGLq6yv5wzc72gSdEEL0NlnBwsYzBFy8YcM7kLYAMjd1/Zz0pbDojz1WpHMHB3LdqIg228J8XPFwNgOQ1M8HgEuTwrCYFJPjghkQ4MHlQ/vx+a/HUlnXwNfJWRws1Ec5XpgYQnZZLZuM1TOOtTunnAOF1czelMnLC/b02PsSQoiTJWFlo5Reu9KMGkXpoa6fs/tb2PA2NNb3bNlaUUofZBHu69Y8d8vPw5mP7x7Dy9ckNR83flAgY6MDWL63gP0FlQD8fkoMXq4Wvuhg8dyth/Xa5IhIX35OL+qyLE1yqRMhxBkiYdWarSkQoOQEwqoyT7/todUvOvLIhbH86bKENtvGDwokzMetzbbJ8cGkF1SxfG8hFpPeB3b18HAW7Mzlrwv3cKCwqs3x2zJLifBz44KEEA4WVfPZxsNMeX1lu4vsbs4oIfG5RazZ303TB4QQohMSVq1FTwS/aPAfdGI1K1tYlZ3Zy3ycHxfMJUO6XtxjsnExyIU7c4kO9MDJbGLGOZFYrRrvrT7IpxsO8+mGw1zx1lreXXWArYfLGBnpx4j+vgD8deFeDhZWs3h3Po9/ncKOrJZ+vLnJWdQ3Wnnky+0UVHa8BJRtSL0QQpwOCavWht8CD22H4ISTq1mV981rUg0M8uT2cQMYHOTJ1caiufGh3uz680UkhnlzsLCaBTtyScuv5JUf95JXUceISF+GRPigFFTV6zWq57/fzZzkLP6yUO/Hamyy8tPuPEYN8KOk+iifbjjSYRkemr2Nu/63+ZTK39BkJflwqcwNE0JIWLXLPxpKM8Bq7fiYxqNQY/TrnOGa1cl44aokfnpkYpuFdF2dzAwO9uRAYRX78iu5Zng47946khGRvlyQEIKXqxODg/RRh+cM9KespgEXi4kNB0tYuDOX2ZszKa1p4NcTBjJqgB9LW62YYbVq7M1rmcu1O6eC5MOlpBe0bXLsSmZJDVe8tZbr3lnHyrSTa2rcdqSUo42d/O2EEHZHwqo9ftHQVN/5BOHqgpb7fbRm1ZlBQZ5kldZSXH2U2FAvLk4K49sHzqW/vzsAF50VyoSYQB69MA6TgrduGUGgpzMPfLaVZ7/bRbivG5Nig7gwMYTU3Aru/XgLD362lZnL93Pxm2tIySyjur6Rgkp98ElH1+dal17E+a+tYElqPh+sOcjhYn3k4rurDpBRXI2TWTVf++tE5JTVcu076/hg7cHT/A0JIfoSS28XoE/yj9ZvDywD73DwHwheobB3ASRdp48ctDUBApR13AzWVw0K9mi+Hxfiddz+xy+Ka76/7blp+Lg5MTTCl5SsMrxcLAyP9MXN2cyFiaH8ZeFeFttqVzv1m0W787jcrPeruTqZmJucxYOTB1NV30igpwv/WLIPTxczKZnlZBTX8OuP9Wl1e3IrefW6ISzalcfUhBCySmvZeqT0hN9XWl4lmgY/pOTywPmDu37CGXSgsAp/d+c2K/D3RXtyK4gN8cLcas6fEL1Nwqo9AcaH3Pzf6be+A2DEbbDiJb3WFTGqJawCYuy2ZmUTG+rZyZHg4+YEQKiPK6E+oW32RQd6cPXwfgwK8qS4+iiLduUR6OXMktT85nlgj0+L46UFe7jpvfWkZJVz5bB+zE/JwdlswmxSXDGsH9GBHiQfLmH53nzWpodRXH2UK4b2Y+OhYmZvOsKR4hq+3ZZNk6Zx17lR+Lq3/4Fva25Mza3gUFE1jU1WftiRy6VDwogLPT6UzxRN07jx3fVcMiSUl64e0mvl6EpmSQ2XzlzDGzcOb+7nPFZdQxNKgYvFfIZLJxyZNAO2xzcSpn8FN34MF74AZYdh9Wv6vkJjsqytiTDibP0qw531b/VB0YEeKAW+7k4Eebqc1rnevHkEv5saw/NXnsXapyZz3cgI0guqWJGmN5XeMiaSW8ZEkpJVTpiPK/NTcvBzd6LRaqW2oYmbRvfn0QtjmT5mAKU1DTw/fzeeLhbOjwtiZKQfdQ1WLnhjFW8u28dby/dzyT/XUNfQRFFVPd9szeJgqyH46QVVuBuTphfuzOXtFen8c9l+LnpzNc/N29VmZY60vEru+O8miqp6fp5cdpne5HqoqP3L0GzOKCEls/NVU+oamvjrj3tO+wKcFXUNvL0inYq640dp2mqmafmVHT7/rv9t5pEvt59WGYQ4WVKz6kjsRfptUyNsfK9lLlXhXv22Kh+UCcJHQsrnUJUH3v16rjyaBuvfhqE3gmdw18d3wdXJTLivG/183dDXHO4eFrOJaWeF8uIPqXy3LZtgLxc8XCz83xWJXDoklNED/PnTd7u4bGgo87fnsDa9mLHGlZInxgbiZFZkFNfw8jVJuDqZGTnAD4AAD2c+u2cse3IrefDzrSxOzee5ebsoq2lgclwQd50XzexNR8guq2NIuA8NTVa+T8mhqKqeCxJCiPR356N1h0gvqOKDO0bj7mzh223ZrNpXyB++2UmotytXDe/H6Cj/5vdSXtvQXKs8VnV9I+7O5i5/d+U1Dbyz6gAJxjqPtmWvQK9tLd1TQGpOBf9cto+oAA+WP35+h+dauief91YdZOPBEr66bxzOllP7rvnphsO89lMayYdLCfZy4fy4IC5O0ptsbWFq6zs8VkFlHesOFBN4ml9wjlXf2NTjNbXGJisWs3w/t1cSVl0xW/RLiCTPgoYaKDQWuq3MBY9gvYkQ9BGBPRlWpRmw+BkwO8HY+7rllC9fMwRPl+7/JxDu68blQ/WmvqhAvW/M1cnMhBh93tfrNw4D9InMlXWNOBkfIF6uTvxm0iCczSZmjB3QfK5/zxjJkHAf+vu7E+LtipNZ8crCPZTVNDBqgB8bD5XQaNVYs18fnTljbCQDgzx58YdUAC5JCuW6UREMifDmsa9S+OvCvbx4dRLrDxZjManm639ll9Xy31/pYbUuvYjb/7uJv10/tHnF+8q6BrYdKWNxah5fbs7k2hERvHLdEH7anc+qfQW8eFVS84fh7pxyquoaScuv5N1VB4gK0Aeu5JTVYrVqmEyKzRmlzX11vu5OHCyqJq+8jlAf13Z/r6v3FeJsNrE9s4z31xzkwcmDmbc9mz9/n8riRyZ2GSCLduWRVVrDd9uy8XSxsHyvXvP9aXce4wYG4uPuxMEivZaaUVTT7jlWGM8pqqqnoLKOYK/2y3oyPt94hD9+u5Oz+nkz664x3R6EAK8vTuO91QfZ+uyFPfJvXvQ8+ZpxIkbfBfetgpCklppVZR54hYCvcQmu8kz4/GbYOadnylBtDN+uOfGRcV2ZFBvEKKPm0t1+O0Xv9xsY6NHhMa5OZoK82n4wPTYtjt9NjWmz7dIhYc2jFD1cLIyI9COnvI4BAe7cO3EgNUebmoMK9JXpLx3S0rd2XkwgANeMiOC6kRHMSc4iu6yWnVll3DNhIM9ertf6fk4vovZoE5qm8dcf99Jo1fjbojTqGpp4a9l+hv55Mbf/dxOzN2UyItKPL7dkcvGba7j/s2Rmb8pk1T79b1Tf2MS9Hydz36fJrN6nlyujWP/wb2jSmkdIfrH5CJ4uFlY+fj6f3DUWgPUHj1/mqrymgdScClbvK+KCxGDOHRzA5xuP0GTV+OjnDEqqj/KlsYRWYWU9j3+dwtNzdwB6k9/N/1nPol15/Om7nby0YA/78qt46uI4/jV9BB/cPpqy2gZmLtevPn3AWEcyo7i63fltS1ILsI272JPbcVNhVX0jry9Oo7y2gcYmKzuyyjpsAt1wsBhns4ndORWsOslpCidiT24Fby1P52ijlYwOyiD6PvmKcTKC4vX1AI9WQ/ZWvanQxwirnG2w70c9zM66FkztfA/Y8wPk74Lznz7517aFVW33hVVPig3x4p0ZI4k3LiLZnc4bHMimQyVckhTGuEEBmBRYNZgQE8ia/UUMDvYkzMeNMdH+VNU1EuLd8u3/jvFRfJ2cxRNfp2DV9KbH8YMCiQvxYuHOPJ6bt4vdORWk5lZw89n9+WJzJg99sY2lewqYEhfMnedGM6y/D54uFt5fc5A1+4sYE+3Pj7ty+WpLJlMTQvhycybZxsUvl+7JRym9FdfX3YmymgaySms42mhl4c5crhsZQVSgB01WDR83J9YfKOaaEW0XL35iTkrzaMuJMUF4uFj43extfPTzIbZnluFsNvH5xiP8ZtIg7vl4S3Pf123jBrB4dz4bDpaw9XAZR5usxAR7klNWy2VD++FvjEq8ZUwk//35EFPigzlUVI3FpKg52kRhVX2bmlNmSQ1r9hdy5bB+fLc9h9ScCibFtlwA9VBRNR+sOYjVeK/vrDyAh4uF5XsK2JRRQpCXC+ufnnJcU9ye3AomxASyOaOEzRklxy3e3J7dOeX86btdvH/76C5rYu+tOtB8P7uslqRwny7PL/oeqVmdjKBYQNMDq7YEoieBiye4+cGBFfoxpYf0Ie/t2ToL1r4B1lO4/EYP1Kx62iVDwojupGZ1qi5OCiXIy4XrRobj7erEsP6++Lo78a9bRvKHS+I5Z6B+xeV3Zozkf3ee3ea5SeE+nDc4kHUHinF1MjEyUq9Zjon2x9PFwtfJWZhNiicuiuPla4Zw//mD+Gl3Pp4uFl67YRjnxQTi5eqEUop7Jw7ik7vH8uLVSVwzIpxlewpIL6hi5rJ0Rg3ww8tV/y5489mRAEyJ1/sa/744jYmvraCxSWP6WH2f2aQYG+3PktR8vtx8BE3TWJFWwLoDRSzdk0+YjyvuzmbOjwtm2lkh+Lk78dKCPTiZFc9dkUh2WS2LduWRklnG3edF4+Zk5rWf0vhw7SHiQ7042mSlv78bPz40gVVPTm4OKoA/XZbA4CBPfj97G4WV9Zxt9NsdNmqDX23JZMzLS7nzf5uxmBRPXhxPuK8be1pdyLO6vpGb3lvP11uymL3pCO+s1APi7eXpbMooYVJsEIWV9cfNmatraOJgUTWJ/bwZHeXPpoyW/fO2ZzP9/Q1YrRrztme3GViydn8R246UMXvj8dNGSquPcsO763h+/m5Kq4+SklXO2VH63znb6DP8anNLTbgnHS6ubm46FadHalYnIzhRv137pn47cJJ+69Mf8vRmF5zcYevHEHPh8c8v2g+NdXqToV9U+69hbdKHzI/9DYQNbdneXLM68TlHv1SxIV5sfuaC5scvXpWkD4Zwd+K+SYOatwd08I37gztGsz2zDHdnM65Oeqe+s8XEY9NiKa9t4LeTBzd/+3/q4ngSw7wJ9HRp8wF/rOljB/Dx+sNc+a+11DY08d9fjeaT9Yf5OjmL300ZTGI/b6bEB/PN1mw2HCwhKdybf948os0UggcnD+bJOTt4au5OftiR29y0aVIw9/7x+Lk742aMdHzvttGs3V/IwCBPLjorlBe+T+VfK9IBmBwXTG1DE59vPIKfuxP/mj6Sn3bnERvihcVsOq4m4u5s4e0ZI7nyX2sBPVTXHyzmX8vTMZsUK9IK6OfjRnpBFS9enUQ/XzcSwrzZmV2O1aqhFLy1PJ2Cynq+eWA836fkMHvTEaaPGcB/fz5EoKcLM28Zwfi/LuOHHTmMHxSAUoqjjVbS8ippsmrEh3rj7qz3oxVV1RPg4czMZfs5UFjN/JQcHv5yO37uTvz12qFcnBTa3Kz62cYj3H/+IKrqG1l3oJhgLxcKKuvZnFHK5oxSymr0EZjXjghnV3YFWaW1pOZU8NQ3O/BwtrD8sUkEe59+v9v3KTnMT8nhrVtG4OpkZkdWGf393Jm5LJ3vtmez6onzifBzP6FzVdU3kppTwZho/64PdiASVicjMBYGTdVrTgExLQMqfCP1sDI7w+AL9Ka+1ja+B1Hn6UPgQQ+tjsKqPBO2f6bvbxNWRl+GnTQDnkkn26zj6mRurn21due50e0ef8WwrgfORAd68Lfrh/LQF9u5ZUwkQyN8eWyaKxNjg+jn68Zt5+gDRgI9XSiqqmfG2AFtggpgWH9fFj08gT9+u5PZmzIZG+2PUnofXD/ftivqj4n2b/NhNmqAH+sPFqMUDO3vw5BwH8YPCmBKfDDuzhYGB3c+QTo2xIsXr0ri2Xm7uDgplFcX7WXVvkJigj25Zng4L18zhLqGpuYJzdPOCuHJOfk88tV21h8opqCynquG92NkpB8jI/14bFocTU0ac5Iz+fWEaHzcnLggUW8inbc9h28eGM/DX2ynqOooAAlhXoT66CF69ds/MzLSr7n/7P01B5t/d7/5NJn7Jg0ko6gaF4uJvIo6lqTm89bydFJzK3BzMjNjbCQWk+K8mEDmp+QAMCTCh3A/N7LLanhl0V48XSzUN1i59p11RAV48N5to3C2mJjx/kbGDQrgkQtj0TQNpRSpORXEhXqxbE8++ZX13Do28rhRoP9ZfZCd2eW8umgvj0+L4/p31zNjbCRp+RXNfYvPXp7InOQsRkb6MrDV3z4tr5LYEM/mc3645hBvLN3Hx3eNYUSkL54uluZ9dQ1NaBrNX1ociYTVyVAKLn8D3hnftuZk67fyH6gvgrv3B/0aVxYXyNsJPz4JkeNBM+ZiFe1rv+YFLZONW6+QAXbZDOhorhoeTmyIF4ONqzmH+rgeF3Thfm5U1DVwaQer5iulePGqJMZGBzAlIRhv1/aHzh/rvJhA1h8sJibYs/k5lw89udGpN4zuzzUjwrGYTbxy3VD83J2YmhDSvL/1B+QNoyJYtiefedtzGBHpy+PT4rhyeMvr2UbcbfjjVNyM2utvJg3CrBQ/7MjluXm72ZunD9BwdTIxIMCDSH93bhkTyZESvTbl6WLBqmnszqmgv78bCx+awG8+SWbOliycLSYuSQplc0YpL/6QSk55HZPjgliRVsicrVnEhnhxSVJo87qSQ8J9iPBzI/lwKUVVR3niojg8XSzM257N2vQi3lqejo+bE5sySsgoribE25U3l+5jakIIszcd4fFpsXy64Qh5FXUUVtRxy9hIvRZ8cTxerhZ2ZpfTz8eVj37OoJ+PG0cbrWw7UkZ6QRVKwRebjnB2lD+Pf51ChJ8b08dGomn6l4yb/7OBf948nKuG65OwbYNsHvx8K9X1jfz12iHcdHYkX2w6wtPf7MRsUvz08MTmf2eOQsLqZPkNgN9uBlfflm22EYEBg40LOFqh5KAeXDu+1PcdWddyfNG+js9vC6mq/Lbbm5sBO584KnpXQhcDSqaP6U9pTcfzt0Cfq9bR6hEdOXdwIK/9lMaI/qc3utPW/Hl9F4MclFL848bhrD9QzOT44A6XZnJ3bvmISQjz5h83DaeqvpHFqfk4mVXz/C79+Yq/Xquv7rFwZy4Wk+KjnzNYf7CY0QP8cTKbmJoQwjKjD2hQkCdxod68umgvHs5m/nLtEM59ZTllNQ1MSwxhcpzeRxju60aApwvhvm7N4XWp0Z96x/gonvg6hXeNQRhBRjPiSwtSqTnaxOxNR3AyK/698gA1R5uID/Vi5vJ0vtySSX5FPT5uB0jsp//N37l1FNe+s443lur/v1OyytA0+PWEaGatO8yDn2/F29VCfkUdf1uUhlJwmfGl5T+rD3LlsH4cbdJDbkyUvzEiE5buKeCmsyP5ZMNhwn3dyC6rZfW+QgkrcQKOnU9lq1kFxrQs1XRwFez4Sv8xOYHVWC0gKEFvBuyILaSOq1kZzYD15fpEZbP86ezRTcZgi+42JNyHK4b1O6GRdN3Fw8XCBYkhXR94jCuH92Nxaj4TY4J465YR7R5jq3luyyzTw8oYINF6qsWAQA/OGxzIzGX7uXpEOGE+biSF+7Ajq5ykcB+CvV0ZPyiACD+9CTXcuI0KcG8z8OePlybg5mymn68blw0JY/LfV1JztIm/3zAMD2czlXWNPDl3B65OJr7+zTien5/K3K1ZxIZ4sjg1n80ZJYyM9GVYf1/GDwpgzf4izCbVfCXti5PCCPB04ZUf93LfpEEM7+/LkZIa/vCN3jfp5mRmd04F/155gMHBntQ3Wrl7QjQXnRXK03N3sHBnLml5lezOqeC5yxP578+H2JxRwl3ntd9s/Usln3jdwdb/FBjXElbL/qxPIgaY9DSsegU8giBiNOxb1PG5OqtZKZNea6stBc+g4597uqxWvZxJ10FQXNfH27uMtfDZjfDwTvA4vg/LnphNqsMP/r5manwIY6L9O+wjbG1iTBAfrj3EeYP1uXIxwZ54uViorG8kOsADfw9nFj08oXm+3rhBAc1hBfDxXWMwGf094Ua/3/lxbVeA8fNw5oWrkpofnxcTyP78Kq4e3g+L2UTt0SZeXJDKxNggvFydeO36ofxuir4o8+VvraW0uoEP79BHnV4xrB9r9hdx6ZAwvjf6y2JCPBne35fEMG/GDQrAyWziXGDWugz25lXy0AUxLNyZy2s/pTWXwTYic9ygAL7YnMlLC1Kb19HclV3Oqn2FzX1qjkLCqjuEDoHrP4L4y/R+Ku8IqMiCxKv0tQV9+sOGd/QgC4qDbZ/oNSWPwOPP1TqsNE3vJ7M2QU2xvlpG6aGeC6uU2bDqVSg9DNe+1/3n72sK90JDNZQfsfuwsiduzma+um/cCR07blAAO/5vWvOoTZNJMWKAH6v3FTIgUB9dNyCgpZZ0y9mRVNc3MsQIq9ZzuhLCvDEpfepDZ964cTj1jS1LM7k5m5n34LnNo0FNJkVUoAeapnHXudGMHODbHI6XDQljw8FiHpoaw7I9+fi4OTX3IU6Mbft/9oph/UjLT+OSpFDumziQPbmVPP/9blwspubXsg0EWrO/iGtHhhPk5cKYaH++2ZbNgcJqh2oKlLDqDkpB0rUtjwNj9LAaeXtLreuil8A9UJ+TBXBkvd4cmHAlBLYaqVVlhFXTUT2U3P31W82q94eVHuqZEYENtbDiL/p9Fwf5D1BXrt/KdIA+zRZUNteNDMfVYmp38ElUoEeHq9rHhnix9dkLO1yx36a9S7gMDDr+/4RS+hy31jxcLPzjxuEAjBsYgEcnSzv9esJAJsUGNYdtYj/v40I8xNuVsdH++Lg5Nffn2UaBbjpUImElTtOA8frCtwMnt2wbebt+21gPZhd9Udoj66EiBy77e8txlfktzX2VeXpY2QZXBMXC/p9OfkRgxs/6sPr+Z3d8TNZmPWCh50Yc1pbCR5fptbbQPnCZjDpjUquElV25anh488i5k9VVUHWnd28bRWeNdM4W0wlNu/ji3nPaNPdFB3rwwlVnce5gx2oNkBUsesKkJ+GBjWBqZy6ExUXvtzqyXn+csbbt/spcve/Ldh9awsq2/WRrVj8+CT/9sfNjKozXcvPXmxx7QmEaFOzWB5/0Bc01KxlhKbqfk9nULau8H9svpZTi9nFRbZo/HYGEVU9pb21Am0ijqq/M+vWxqowwajyqB1E/vRmheZCFbai7bXttqb6807zfntjSTWVH9HO0szBpM1swhib1XFjZQrc4vWfOf7LqpWYlhL2QsOoN0RP123Pu12/3zIdlL8C75+qPQ42VK7Z+DHsX6Ivmugfqq76bLHoz3daP9YEaG96BhU/ogdSe2jL9Q7murG0IVeTo4WhTmQfOnvogjp4KqypjjbRTCauqwpZmu+4ifVa9a/Xf9cWde0JWst1dEFV0TvqsekP0RLhnGYQNgy0fwYJH2+4PMNa3O7Ie8nbpowYjRusDOTyC9CWZspP1YxY/o99qVrjs9eNfqzyz5X7Rfv1cJYfg3+fAxCf0vqOCVH1gh2cIuAfoIxVtIxG7k22uWPGBzo9rz/8u038HV/+7+8pjC786B2oGzNysj/q87PXu//uerHUzIWoCJFzevefNT4UPpsCMOR2vFCPsjtSseoNS+gev2QkueVWfh/XARrh3FcRfDuGj4Ox79HUGj1bqIwDDR+nPjZoA+37S1xmMu0wfIdhvpH4drcZ2Ls9e1iqsio3JyEv/T19QN2Mt/PxPWPkKlGeDV5geZtYGqG/nWkVWa/tNibOnw+YPOn6/lXn6II9qo2ZVmaNfZuVElWdBUZre59WdmpsBHSisdn8DWz7s/dpkfZVes60+/vpdp600o+2t+EWQsOptI2+DyX+A4Hi9T+rmz/TAuOx1uOVLvaYDLWEVe1HLh+y4B/Wln6Y8o9cO0n48/vzNNSul16xyd0DqPHDx1mtn2cl6cOWmgFdoy+u11xT44YWw9Pm222pKIG0B7F3Y8Xtc+Qp8em3bVTlKDnb1m2mR8bN+W5F94s85EfbWDFhdBO9OOL3QLjUWU67q5ctWVOgTZpv7MbtTVQcT64Vdk7Dqy8wWfWKxMkE/Y3WCQVP0x8rcMuBi4GR9PtfiP7UM1rApOwIWN30ycnG6vlahyUkfsVhfoQcVQFN952F1tFoPtsPr2m7P2abfFu2D6mL48Sn4cBp8MUNvbgR9RfrGOsjZ3rKm4vcP68P3T8RhY8RkZR40NZzYc05EXR+pWeXt1H93NvVV8OWtxwd6drL+u2zvS8mJsq38X5V3/L6aElj+Utu+zJ5i++JRXQS7voF/j9eXEesOlR0sWXa6cndA5qbuPac4YRJWfd2UZ+H2efp8K9BvB5yr93c5G0NXTWa4YZb+LfWr2/Vgyd2h/+cvzwSfCL25MG8n7Jqrt+MPvuD41/IK1QdygB5WrZv8CtMATb9tvd0WVuWZ+vD4zR/oYbr3B9jzvT5aMT9VP6YiC/qP0e9nb4F1b+nnslo7bsYEvWalTPrr20Ytnq6mBn31Cji1mtWhNS01s45Ym7o+pqEOPrwIVv+tZdvhdfrvLnVe22Nt4Z+z9eTLC/rvurOa1a65sPo1yNxwauc/Gbawqi+HA8v1KQ3d9bc9mZpVznb9+nEnMqp28Z/g+4dOr2xd2fAOLHyy5bGmHd/0rmn6v49jv5j+wklY9XXu/i2jB22u/0hvLmyt33C46m19dffX4+G9CfBmkv6B59sfht6of0BU5sKQG/Q5Wy7exnW5jMVPvcJaQnHuPfDeRP1btqZBwR59e3152w8BW1iBfgXlQVPgrkXgEawvZ1RyEBprgXxWKAAAFStJREFUW47xHaBfZmXErXpZSg7C/sUw927Y8t/j33/WFig5oF9HDPS+tda2fHRq87ZsfXJml5MfYFFTAh9fCQse6/y4zR/AP4d1HMKgT8ZuqG67En/udv02Z3vbY0uNsMo+xbCqLdX7QKH9WoftdW1/655kawaElvfZejDQqdj4H5h1xcnVrHZ+rY+sLUjt+tjyTD3sO5sCcjoqcvVm9q2z9PA8Wg1/G6j3M7ZWdkSvead+1zPl6KMkrOyRZ9DxK78DDLkezv8jeIfDJX9rWdrJxRsSroDpX8HwGRB3iT4PbPzv9X6v4HjjvCEtzYD1FXqT0+c3wN9jYOdXLa9TkNpSG8nZ1jLUvqler/WBfnmUgj16ba41jyAYfRec+4j++NBqvc8LYPvnx7+nZX/Wa3vn/0F/3LrfqqkRFv0Blr/Y9e/sWLaA8o3UFxxuqOv42MzNLbVDMGqXVv2DLndHx887sl7/PXXWP5exRr+11Zqg5cO79RcBaBkwUJ554n1OTY3wzb36uVoPOGiv1pGTot/m7+74fPm7u64tHmv3t8c3H5dntdy3BUVH0y9O1MGV+r+nIqNP70RqVrbXztzY+XGapgdsQ3XPrfCy+jW9ubyxTv9bFe3X513a+mxtbAsKRJ7TM+XooySsfmnOfwoe3ABj74NfLdBHFw6fru+LuVAf+u1kXHV20hMw+k4IMsLKKwxcvFrO5T9Q/wCoLtRvvYwLBs5/CN4Yoo8mrMjWQ9JkzIJoHVaFaXrgmSz6pVGgZQHegEHgGWqE1SJw8tCP3f65PvcmPxWObNT3T3hMX2oKWj7krE36h1JjrV77sg23P9Fh8bb+Kr8BxuNjalcNtXozZV253rT6zb0t+wr36rcWN/jugY4/vGwf+p1dv+yQEVblmS19NrnbAaX3L9WU6M1kWz/WA83DWDH8RGtX+Tv1fsqdc1r6q1DHf5A31OkT1KHjmlV9Fbw/BVb9rf39oNfEW48k1TT44VFYdswXioocvd8VQDOa4E43rGzvz/bloLqw/ea9lC9aana299pVX1RNcUv/bvPvsRNF6frv60Q1HtUvJxRiLENWkNoyH9H2783m8Dpw8YHgtusS/tJJWP2SufvrzYWxF3V+XNwl0P8cvbmw9dybe5bptbFRd+qPoyeBq4++SvnRSv3yGhY3GHYL+A8CJ/eWQR9B8fq30D3f602OwUZYeRhhpRQMnKQ3U1YXwNTn9Ca57+6HL2fAfy+CDf/Wzznydj1EXX30sDq8Dv7SD5L/ZxRUg/1L9HB5a+Tx3+LbYxtR6WuE1bGDLH58Uu+jWPRHfah9/s6WD7bCND1cb/pUD8yv7zj+/A11LcHZ0fXLjtbozYAeQWBt1Pv0qgr1LwC2PsUfHoZProX5v9c/hBOu0MPf9u36uNetbTsIJWuLfpu/q6W/Kjjh+Caygt16GbzC9PfZXlNXxlr9A7uzD/bFz+iDJWw11YpsvXaQs61tuSqyW74k2ZxICHSkdX8c6P9WNOvxow2zkuHb++DnmfoXAVs/WcbP8O1vIH1p++dvXRPsqrmyupj/b+/Mo6Sq7jz++dF2A8oO0rY0yCIQWQTaFoyi4hLANoorgo5KUDkSjZqJoyTOScy4JTpJPMQMinEjKiRIBCVuiGg0CgIZ1lYWESMKNi0iTZD9zh/fV1PVRTcE6Kaqq36fc+q8V7cer+/v3cf93d9y7+Xh/jDjp/uu98ZPYfwAuf62V8ApNwOmwVrs/UlWVv94D9r1q3o5twym1pSVmT1uZmVmtiShrIWZzTCzFdGxeVRuZjbWzFaa2SIzK6qtejlV0L4/XPOq1i0E6P9DKPlvKbsugzTnCzSB+MhvKdmh/alSRn2vg0atofuFikPlRCthx0Z9X66E7hfEJzrHlBXA2T+HXsN0317DYPS7MPI1GPaslEnpVK1KH1sFvkmhOrk3f6FOc+7vIa+x3Jd/e1CrgAD87zOVO9tlr8ADneHZy+LutpgrK2ZZbSmHKdepw5o9TpZMvVxY8LR+t3py+4E6jyO7QOez4YyfyPpLtujKl8UthuqU1YfTNaeteKS+f7U67vo7YYSOpdOg0xlA0LX53bRQcnV7oj0+WIotRkxZrVssZdCgmbaqibkRS6fJAoy5Ho+/TJ1mYuccY9Ws6F6Lqs7KDEGZil//I/7cYm7Snd9Udglv+iw+sInxr1hWr94B03+4Z/mWDfF4HMRd08lKee6jOn7yTlwJdDhNA4WFE+HZYRr4JJPoft5XPRc+K3mXTNl3ZuWiSWrzV8bofes6WJm9iZbVli/jyRSby2Spx5ZsyyJq07J6EhicVDYGmBlC6AzMjL4DnAN0jj6jgHG1WC9nX5x9p5RQjKN6yMoqHqklogbeDRc+DL0ul2IDzRUreSD+b2KbNzZoBv2uh4Lecvs0S9gpt0mB3JLXvwMNm2mrlHb9tC9Yl3N0Ta9h8eubttHo/uO3FIcLu9XhnXidRtAFx8vtWToNxvaBJ78rt+KfR0He4bK4nhspd9vWJMvqLz9SXG7hRHUcXQZr/hooCaXjGbDwj+qk138Ytwp6XKLj0ucrP8NYjKtJoTqXDatUj8TJ03+foI6p9xX6vuFj1aF+EyWqnDcWLp8MVz4fd6M2bw9dS1SHZAW5frlciKVT4ZP3tAzXp7MBU4e3/FVZVY2PUsZc+QqYPEIZbh+8qLp2if7LVhW3+ugNWb87t8r6Su6Iv/pYVke9XHjnQVmr6xJiemvm6li+QoOFVl1kOQM071BZCWyLFGbioGPLBpjziBJx1syv/Lc3ro5OIs9AQS8dE92dm8uUJp/XSCvDxCzwk2+SJXb+Q3q+s+5VIs+CifG/H0vssZzqldWa+RosvPuQ3vutG2WprZkHT19S9UT7pVNV5907FYOq31gDvbIPpKwOi1z26z+E5a/Bb6P5lp3O2PNeGU6tKasQwl+BZGf+EOCp6Pwp4IKE8glBzAaamVlBbdXNOQAKi9Xhd79QSRlNC+HCcfHswWQaNtMcsYF3QYMmUkC3LK46MaQqBt0Dp99eOROy6Cpo0QFad4fzHlTZ0b0Ve7ttFVz3hmJ12ytg+2aN5KeOhsPylP5//lilfU+/Ob6aRtu+0HmgrJqTboCLHoV+o2HoBGVNYlIc/a7X6HvOw3IdxZRxs7bQtl80it4m1+HnC+RWy6kPXQZqlDzuFMUk/vIjKYd5jyu5os+Vepb1ctWZL52qGGPe4XDC1fr3oN2bQVZR1xKdTx4Bz10Td3/FElV2bNEk7PfHS65OZ6o8Fl9s1FrKYuZ/SeGvmSurqXiEFH5eoz3T5lfMkNLt82/6PnG4BgQVCcoglpV57q9k0UwYosFFy87Q+Gi5D7/ZqBhgwxZ6vrENSI85RQph9y5YNBke7Am/6Q7jT4/HfhY/J+sy9witwpIYj4o9g9jk+YKkxaBDiCzOAIPu1XHeExoYHHs23P6JJugXXal3ZNJwmHq91u0EtX1OngYpGz+Vu3XLBll6K19XXabforlwm9dFnomWaoNXfwIrZ6j9EylfIffsabfq2tieeK2Pk6IqXw7HRlmwZaV6txq1Viw6Nu8yizjUawPmhxBikynWAfnReRsg0RG8JiqroYkXTkoYOiF+bibL6F+lZSe52BI57jx9QBbOidcqXpbIMf2Vwt/hNHVEFWtlPeUdrlHzusXwdsIaio3y4YrJlddCPH6ojk0LpeTye0gpH90HZvxMvyXux9X7cimgxwbKsln4RymuNidolLxzqzrr78+G9x6Sopr/pBJYiq5S7KH5MQr8h11QfM2ez+PkG2UtxDbzLDwRyqKpAaXTJO+GVXJ/VayTMu44QIkxJ14LH82U8uxxcXzx2A9ekLsxNsetz1Wau3f8UFmkg+6R3KvehImRu/bM/4Qlz0V7nxk8WSLr6NR/16LLjQskU6N8+NOV2kS0x8WySJZMkVX8zVeKhTZto4SRii+gTZFch7P/R51y235yQc+8S9meA36s53ZUTz2f6bdoekXRlYqlxuJd3zpXc/iO7qP6zbovmsu3A5a/DIPuk6vz5dskw8k/qByn7TZEsaa1CzWAeHmMlOWXH2mg1fwYWPaSYqYgZT/vCSmadYvg4sc0ODi8hWJ1L0dzpnLqS3F98jf9fux3FDurlyuPxelj4jGonpfIrb19s1z0q99WjG3TGt2/ff89348sIGUL2YYQgpnt94QFMxuFXIW0a9duH1c7GUtObtUL99arFx/9gyy8RM76KRT2hYmXQdO28Q6iukVdO54ePx90H7x5L3S7ID7vC9TJr5ihGFTXElkYR7SCi8Yr9takEC59Qh1dyQPqeDd9LkUW20qmy2CN0ItHxjMfE8ltGLeyAK56QXX+Zzm8/4iWu/rqY/jOXVJ4n82HSyfIfdT6OP2tgt6azhCLJ3a7QDIV9JJbtHE0diweKcUweYTcsG/9UkpyxEuyknteqjlAHQfIati9U9cCnHqr6tV1MAybqPlAHU7XIKNhc1jzPgyfJEsd5AreVqEBAUhRHd1Hg4Tchpp7NOdhuUx3bdccw27nS+5Zd2sOUqez5D47vKXc1Pk95FK++PdyG754k6yiTmfJQq5XT1Z7Ti58+8bKz7l5e621+eVKDbamXAvTvq/f2n1b7kKQNd6qi2SbOlo7IPS+IlLM0bvUd5SU3KdzNKh65Xa1x5IpioHm5OlvJHsbWh8n1+Q7v5ZVOvAeWXAtOqnNshQLtTXBDTCz9sD0EEKP6PsyYEAIYW3k5nszhNDVzB6JzicmX7e3+xcXF4d58+bVWv2dDGbndlk8DZrUzP22VagT6jlUVk2DpvF5boeKTZ/LoqkqS2zrJiXQxJJotlVUnqaQzBt3K1GlIkrxvvrFPSenx9j+T1lAhcWVO2tQVuBh9asfDHy1WpbLUT2UZfnRG9D9orji3PGNLJeyUllssRVQQDGo0mmKMe7eKSUzalbl++/YKpdo+QrFRmP33RtlH8pN2q6fVleZ9xi8dKus9pL7ldxy8s1aDg3kgty5Ne4aTiYEyfHOb2SBrXxdLsRew6semIAs3dJpehY5h+kZ7d655+DrADGz+SGE4hq52SHiUCurB4AvQwi/MLMxQIsQwm1mdi5wI1AC9APGhhD6VnPb/8eVlePUIiFIeWzdGI+ZpSNlH2ouWZuiuJs4kd27FMfbm3LeFwsnQX73yu7fOowrq8Qbm00EBgCtgC+AnwFTgT8B7YBPgKEhhA2mfZsfQtmDW4DvhRD2qYVcWTmO4+w/dVFZ1VrMKoQwvJqfzkouCNKYN9RWXRzHcZy6ja9g4TiO46Q9rqwcx3GctMeVleM4jpP2uLJyHMdx0h5XVo7jOE7a48rKcRzHSXtcWTmO4zhpT62uYFHbmNl6NLn4QGgFlNdgddIdlzdzySZZweWtCY4JIRy578vShzqtrA4GM5tX12ZwHwwub+aSTbKCy5utuBvQcRzHSXtcWTmO4zhpTzYrq/GprsAhxuXNXLJJVnB5s5KsjVk5juM4dYdstqwcx3GcOkJWKiszG2xmy8xsZbQJZEZhZqvNbLGZLTCzeVFZCzObYWYrouMh3sa25jCzx82szMyWJJRVKZ+JsVFbLzKzotTV/MCoRt47zeyzqI0XmFlJwm8/juRdZmaDUlPrA8PM2prZLDMrNbOlZnZzVJ6R7bsXeTOyfQ+KEEJWfYAc4COgI5AHLAS6pbpeNSzjaqBVUtn9wJjofAzwy1TX8yDkOw0oApbsSz60+/TLgAEnAXNSXf8akvdO4NYqru0WvdP1gQ7Ru56Tahn2Q9YCoCg6bwwsj2TKyPbdi7wZ2b4H88lGy6ovsDKEsCqEsB2YBAxJcZ0OBUOAp6Lzp4ALUliXgyKE8FdgQ1JxdfINASYEMRtoZmYFh6amNUM18lbHEGBSCGFbCOFjYCV65+sEIYS1IYS/R+cVwAdAGzK0ffcib3XU6fY9GLJRWbUBPk34voa9vxx1kQC8ZmbzzWxUVJYfQlgbna8D8lNTtVqjOvkyub1vjFxfjye4dTNGXjNrD/QB5pAF7ZskL2R4++4v2aissoH+IYQi4BzgBjM7LfHHIH9CxqaBZrp8EeOATkBvYC3wq9RWp2Yxs0bAFOCWEMKmxN8ysX2rkDej2/dAyEZl9RnQNuF7YVSWMYQQPouOZcDzyE3wRcw9Eh3LUlfDWqE6+TKyvUMIX4QQdoUQdgOPEncF1Xl5zSwXddzPhBD+HBVnbPtWJW8mt++Bko3Kai7Q2cw6mFkeMAx4IcV1qjHM7Agzaxw7BwYCS5CMV0eXXQ1MS00Na43q5HsBuCrKGjsJ+DrBnVRnSYrLXIjaGCTvMDOrb2YdgM7A+4e6fgeKmRnwGPBBCOHXCT9lZPtWJ2+mtu9BkeoMj1R8UAbRcpRJc0eq61PDsnVE2UILgaUx+YCWwExgBfA60CLVdT0IGSci18gO5LO/pjr5UJbY76K2XgwUp7r+NSTvHyJ5FqEOrCDh+jsieZcB56S6/vspa3/k4lsELIg+JZnavnuRNyPb92A+voKF4ziOk/ZkoxvQcRzHqWO4snIcx3HSHldWjuM4TtrjyspxHMdJe1xZOY7jOGmPKyvHqQIz25Ww4vWCmlyd38zaJ66g7jjOvjks1RVwnDTlmxBC71RXwnEc4ZaV4+wH0V5h90f7hb1vZsdG5e3N7I1o4dGZZtYuKs83s+fNbGH0OTm6VY6ZPRrtYfSamTWMrr8p2ttokZlNSpGYjpN2uLJynKppmOQGvCzht69DCD2Bh4AHo7LfAk+FEI4HngHGRuVjgbdCCL3QnlRLo/LOwO9CCN2BjcDFUfkYoE90n+trSzjHqWv4ChaOUwVmtjmE0KiK8tXAmSGEVdECpOtCCC3NrBwtibMjKl8bQmhlZuuBwhDCtoR7tAdmhBA6R99vB3JDCHeb2SvAZmAqMDWEsLmWRXWcOoFbVo6z/4RqzveHbQnnu4jHj89Fa90VAXPNzOPKjoMrK8c5EC5LOL4Xnb+LVvAHuAJ4OzqfCYwGMLMcM2ta3U3NrB7QNoQwC7gdaArsYd05TjbiozbHqZqGZrYg4fsrIYRY+npzM1uErKPhUdkPgCfM7D+A9cD3ovKbgfFmdg2yoEajFdSrIgd4OlJoBowNIWysMYkcpw7jMSvH2Q+imFVxCKE81XVxnGzC3YCO4zhO2uOWleM4jpP2uGXlOI7jpD2urBzHcZy0x5WV4ziOk/a4snIcx3HSHldWjuM4TtrjyspxHMdJe/4PjXXHWZbsBmMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}