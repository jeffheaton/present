{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/present/blob/master/youtube/video/fft-frequency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQI4U7A1h34o",
    "outputId": "d4d5133b-a1a4-460f-d79c-e6d97ff31a1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Note: using Google CoLab\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting kaleido\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 79.9 MB 1.2 MB/s \n",
      "\u001b[?25hInstalling collected packages: kaleido\n",
      "Successfully installed kaleido-0.2.1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False\n",
    "\n",
    "PATH = '/content/drive/MyDrive/projects/audio'\n",
    "\n",
    "!pip install -U kaleido\n",
    "\n",
    "# Configuration\n",
    "FPS = 30\n",
    "FFT_WINDOW_SECONDS = 0.25 # how many seconds of audio make up an FFT window\n",
    "\n",
    "# Note range to display\n",
    "FREQ_MIN = 10\n",
    "FREQ_MAX = 1000\n",
    "\n",
    "# Notes to display\n",
    "TOP_NOTES = 3\n",
    "\n",
    "# Names of the notes\n",
    "NOTE_NAMES = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "\n",
    "# Output size. Generally use SCALE for higher res, unless you need a non-standard aspect ratio.\n",
    "RESOLUTION = (1920, 1080)\n",
    "SCALE = 2 # 0.5=QHD(960x540), 1=HD(1920x1080), 2=4K(3840x2160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9eOd8Tm-jIW5",
    "outputId": "c2623125-3bc1-48f9-915f-2cdfb70c0d8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile # get the api\n",
    "import os\n",
    "\n",
    "# https://dsp.stackexchange.com/questions/48085/why-is-the-size-of-the-output-of-the-fft-of-a-signal-is-same-as-the-size-of-the\n",
    "#AUDIO_FILE = os.path.join(PATH,'popcorn_notes10.wav')\n",
    "#AUDIO_FILE = os.path.join(PATH,'piano_c4_s_44100_16s.wav')\n",
    "#AUDIO_FILE = os.path.join(PATH,'piano_c_major_scale.wav')\n",
    "AUDIO_FILE = os.path.join(PATH,'short_popcorn.wav')\n",
    "#AUDIO_FILE = os.path.join(PATH,'chord.wav')\n",
    "\n",
    "fs, data = wavfile.read(os.path.join(PATH,AUDIO_FILE)) # load the data\n",
    "audio = data.T[0] # this is a two channel soundtrack, get the first track\n",
    "FRAME_STEP = (fs / FPS) # audio samples per video frame\n",
    "FFT_WINDOW_SIZE = int(fs * FFT_WINDOW_SECONDS)\n",
    "AUDIO_LENGTH = len(audio)/fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqxOflIuM_eT"
   },
   "source": [
    "Several utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yg2kx9olG3ib"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_fft(p, xf, fs, notes, dimensions=(960,540)):\n",
    "  layout = go.Layout(\n",
    "      title=\"frequency spectrum\",\n",
    "      autosize=False,\n",
    "      width=dimensions[0],\n",
    "      height=dimensions[1],\n",
    "      xaxis_title=\"Frequency (note)\",\n",
    "      yaxis_title=\"Magnitude\",\n",
    "      font={'size' : 24}\n",
    "  )\n",
    "\n",
    "  fig = go.Figure(layout=layout,\n",
    "                  layout_xaxis_range=[FREQ_MIN,FREQ_MAX],\n",
    "                  layout_yaxis_range=[0,1]\n",
    "                  )\n",
    "  \n",
    "  fig.add_trace(go.Scatter(\n",
    "      x = xf,\n",
    "      y = p))\n",
    "  \n",
    "  for note in notes:\n",
    "    fig.add_annotation(x=note[0]+10, y=note[2],\n",
    "            text=note[1],\n",
    "            font = {'size' : 48},\n",
    "            showarrow=False)\n",
    "  return fig\n",
    "\n",
    "def extract_sample(audio, frame_number):\n",
    "  end = frame_number * FRAME_OFFSET\n",
    "  begin = int(end - FFT_WINDOW_SIZE)\n",
    "\n",
    "  if end == 0:\n",
    "    # We have no audio yet, return all zeros (very beginning)\n",
    "    return np.zeros((np.abs(begin)),dtype=float)\n",
    "  elif begin<0:\n",
    "    # We have some audio, padd with zeros\n",
    "    return np.concatenate([np.zeros((np.abs(begin)),dtype=float),audio[0:end]])\n",
    "  else:\n",
    "    # Usually this happens, return the next sample\n",
    "    return audio[begin:end]\n",
    "\n",
    "def find_top_notes(fft,num):\n",
    "  if np.max(fft.real)<0.001:\n",
    "    return []\n",
    "\n",
    "  lst = [x for x in enumerate(fft.real)]\n",
    "  lst = sorted(lst, key=lambda x: x[1],reverse=True)\n",
    "\n",
    "  idx = 0\n",
    "  found = []\n",
    "  found_note = set()\n",
    "  while( (idx<len(lst)) and (len(found)<num) ):\n",
    "    f = xf[lst[idx][0]]\n",
    "    y = lst[idx][1]\n",
    "    n = freq_to_number(f)\n",
    "    n0 = int(round(n))\n",
    "    name = note_name(n0)\n",
    "\n",
    "    if name not in found_note:\n",
    "      found_note.add(name)\n",
    "      s = [f,note_name(n0),y]\n",
    "      found.append(s)\n",
    "    idx += 1\n",
    "    \n",
    "  return found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t98k4AMRHy-o"
   },
   "source": [
    "Run the FFT on individual samples of the audio and generate video frames of the frequency chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7OinuERiRak",
    "outputId": "fad802f3-b9f7-4578-da93-dba1019388ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/content/*.png': No such file or directory\n",
      "Max amplitude: 3458114.1355447457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:26<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "!rm /content/*.png\n",
    "\n",
    "# See https://newt.phys.unsw.edu.au/jw/notes.html\n",
    "def freq_to_number(f): return 69 + 12*np.log2(f/440.0)\n",
    "def number_to_freq(n): return 440 * 2.0**((n-69)/12.0)\n",
    "def note_name(n): return NOTE_NAMES[n % 12] + str(int(n/12 - 1))\n",
    "\n",
    "# Hanning window function\n",
    "window = 0.5 * (1 - np.cos(np.linspace(0, 2*np.pi, FFT_WINDOW_SIZE, False)))\n",
    "\n",
    "xf = np.fft.rfftfreq(FFT_WINDOW_SIZE, 1/fs)\n",
    "FRAME_COUNT = int(AUDIO_LENGTH*FPS)\n",
    "FRAME_OFFSET = int(len(audio)/FRAME_COUNT)\n",
    "\n",
    "# Pass 1, find out the maximum amplitude so we can scale.\n",
    "mx = 0\n",
    "for frame_number in range(FRAME_COUNT):\n",
    "  sample = extract_sample(audio, frame_number)\n",
    "\n",
    "  fft = np.fft.rfft(sample * window)\n",
    "  fft = np.abs(fft).real \n",
    "  mx = max(np.max(fft),mx)\n",
    "\n",
    "print(f\"Max amplitude: {mx}\")\n",
    "\n",
    "# Pass 2, produce the animation\n",
    "for frame_number in tqdm.tqdm(range(FRAME_COUNT)):\n",
    "  sample = extract_sample(audio, frame_number)\n",
    "\n",
    "  fft = np.fft.rfft(sample * window)\n",
    "  fft = np.abs(fft) / mx \n",
    "     \n",
    "  s = find_top_notes(fft,TOP_NOTES)\n",
    "\n",
    "  fig = plot_fft(fft.real,xf,fs,s,RESOLUTION)\n",
    "  fig.write_image(f\"/content/frame{frame_number}.png\",scale=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vo01yEzHeSu"
   },
   "source": [
    "Use [ffmpeg](https://ffmpeg.org/) to combine the input audio WAV and the individual frame images into a MP4 video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzPw9WT-Lfmy",
    "outputId": "952402d0-b49d-43e1-e1f5-5c0b77843e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, image2, from 'frame%d.png':\n",
      "  Duration: 00:00:01.80, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgba(pc), 3840x2160, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
      "\u001b[0;33mGuessed Channel Layout for Input Stream #1.0 : stereo\n",
      "\u001b[0mInput #1, wav, from '/content/drive/MyDrive/projects/audio/short_popcorn.wav':\n",
      "  Metadata:\n",
      "    encoded_by      : Adobe Premiere Pro 2021.0 (Macin\n",
      "    encoder         : Adobe Premiere Pro 2021.0 (Macintosh)\n",
      "    date            : 2022-01-02\n",
      "    creation_time   : 22:33:34\n",
      "    time_reference  : 905687\n",
      "  Duration: 00:00:01.83, bitrate: 1602 kb/s\n",
      "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[0;35m[image2 @ 0x563912a46000] \u001b[0m\u001b[0;33mThread message queue blocking; consider raising the thread_queue_size option (current value: 8)\n",
      "\u001b[0m\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mprofile High, level 5.1\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'test.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 3840x2160, q=-1--1, 30 fps, 15360 tbn, 30 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc57.107.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc57.107.100 aac\n",
      "frame=   54 fps=2.8 q=-1.0 Lsize=    1021kB time=00:00:01.83 bitrate=4559.4kbits/s speed=0.0959x    \n",
      "video:989kB audio:29kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.312080%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mframe I:1     Avg QP:14.40  size: 29450\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mframe P:27    Avg QP:23.84  size: 21562\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mframe B:26    Avg QP:25.53  size: 15416\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mconsecutive B-frames: 24.1% 18.5% 50.0%  7.4%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mmb I  I16..4: 63.3% 34.9%  1.8%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mmb P  I16..4:  0.3%  2.8%  1.5%  P16..4:  1.4%  0.8%  0.4%  0.0%  0.0%    skip:92.8%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mmb B  I16..4:  0.1%  0.4%  0.7%  B16..8:  4.5%  1.5%  0.3%  direct: 0.1%  skip:92.4%  L0:55.5% L1:42.6% BI: 1.9%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0m8x8 transform intra:47.2% inter:38.1%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mcoded y,uvDC,uvAC intra: 19.9% 31.8% 29.6% inter: 0.5% 0.5% 0.5%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mi16 v,h,dc,p: 86% 13%  1%  0%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 23%  3% 70%  1%  0%  1%  0%  1%  0%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 37% 13% 28%  4%  3%  6%  2%  6%  2%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mi8c dc,h,v,p: 71%  9% 20%  1%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mref P L0: 51.3%  4.2% 30.7% 13.8%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mref B L0: 75.1% 20.0%  4.8%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mref B L1: 99.6%  0.4%\n",
      "\u001b[1;36m[libx264 @ 0x563912a4cd00] \u001b[0mkb/s:4499.67\n",
      "\u001b[1;36m[aac @ 0x563912aec000] \u001b[0mQavg: 167.014\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -y -r {FPS} -f image2 -s 1920x1080 -i frame%d.png -i {AUDIO_FILE} -c:v libx264 -pix_fmt yuv420p test.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBbcVFuhHZgP"
   },
   "source": [
    "Download the generated movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "6ohuRzpfLkYg",
    "outputId": "00e0517d-cae9-4d96-8e53-a73cb9c50bea"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_3e0192fc-c19a-4642-bd82-6f197786aa98\", \"test.mp4\", 1045615)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('test.mp4')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
