{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3.7 (tensorflow)","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"gan2video.ipynb","provenance":[{"file_id":"https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_3_style_gan.ipynb","timestamp":1586282121242}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"L2fejML3tCfv","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_3_style_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"IWl5ywCjtCf5","colab_type":"text"},"source":["### Generating High Rez GAN Faces with Google CoLab\n","\n","This notebook demonstrates how to run [NVidia StyleGAN2](https://github.com/NVlabs/stylegan) to generate a video where we morph from one face to another.  This produces a video that morphs between to images such as:\n","\n","![GAN](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/gan_progression.png \"GAN\")\n","\n","This code is a starting point for other offline reality augmentation projects that might use TensorFlow and video processing.  This script is based on [ffmpeg](https://en.wikipedia.org/wiki/FFmpeg), and assumes you have it installed.\n","\n","Some other useful links:\n","\n","* [YouTube Video About this Utility]()\n","* [More Basic Example of this Utility]()\n","* [GitHub Repository for this Utility]()\n","* [FFMPEG](https://www.ffmpeg.org/)\n","\n","Make sure to run this code on a GPU instance.  GPU is assumed.\n","\n","First, map your G-Drive, this is where your GANs will be written to.\n","\n","## Examining the Latent Vector\n","\n","Setup to use TF 1.0 (as required by nVidia). "]},{"cell_type":"code","metadata":{"id":"w2dEcHb9tCf6","colab_type":"code","outputId":"62f28674-fd11-45d6-e2a4-f1454791aa4d","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1586282236226,"user_tz":300,"elapsed":465,"user":{"displayName":"Jeff Heaton","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiewnZO_LaxRj3Ya9ykDsaEDK8Rpvu-CVIYpJ97=s64","userId":"18292667475657506830"}}},"source":["# Run this for Google CoLab (use TensorFlow 1.x)\n","%tensorflow_version 1.x\n","from google.colab import files"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"icRPLmPKtCf_","colab_type":"text"},"source":["Next, clone StyleGAN2 from GitHub."]},{"cell_type":"code","metadata":{"id":"tB0TryzptCf_","colab_type":"code","outputId":"86547e10-0cfe-487b-9961-ae001421141a","colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"status":"ok","timestamp":1586282242267,"user_tz":300,"elapsed":2509,"user":{"displayName":"Jeff Heaton","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiewnZO_LaxRj3Ya9ykDsaEDK8Rpvu-CVIYpJ97=s64","userId":"18292667475657506830"}}},"source":["!git clone https://github.com/NVlabs/stylegan2.git"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'stylegan2'...\n","remote: Enumerating objects: 93, done.\u001b[K\n","remote: Total 93 (delta 0), reused 0 (delta 0), pack-reused 93\u001b[K\n","Unpacking objects: 100% (93/93), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s1Sh0xmOtCgC","colab_type":"text"},"source":["Verify that StyleGAN has been cloned."]},{"cell_type":"code","metadata":{"id":"wewBEme5tCgD","colab_type":"code","outputId":"d69236f7-d014-4f7e-ba2c-731bf22b8235","colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"status":"ok","timestamp":1586282247308,"user_tz":300,"elapsed":1408,"user":{"displayName":"Jeff Heaton","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiewnZO_LaxRj3Ya9ykDsaEDK8Rpvu-CVIYpJ97=s64","userId":"18292667475657506830"}}},"source":["!ls /content/stylegan2/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["dataset_tool.py  LICENSE.txt\t\t README.md\t   run_training.py\n","dnnlib\t\t metrics\t\t run_generator.py  test_nvcc.cu\n","Dockerfile\t pretrained_networks.py  run_metrics.py    training\n","docs\t\t projector.py\t\t run_projector.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D92Md-Hw3eVA","colab_type":"text"},"source":["# Run StyleGAN2 From Python Code\n","\n","Add the StyleGAN folder to Python so that you can import it.  The code below is based on code from NVidia. This actually generates your images."]},{"cell_type":"code","metadata":{"id":"UgMm1sSutCgH","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.insert(0, \"/content/stylegan2\")\n","\n","import dnnlib"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZcFAjaz3mw1","colab_type":"code","colab":{}},"source":["# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n","#\n","# This work is made available under the Nvidia Source Code License-NC.\n","# To view a copy of this license, visit\n","# https://nvlabs.github.io/stylegan2/license.html\n","\n","import argparse\n","import numpy as np\n","import PIL.Image\n","import dnnlib\n","import dnnlib.tflib as tflib\n","import re\n","import sys\n","import os\n","\n","import pretrained_networks\n","\n","#----------------------------------------------------------------------------\n","\n","def expand_seed(seeds, vector_size):\n","  result = []\n","\n","  for seed in seeds:\n","    rnd = np.random.RandomState(seed)\n","    result.append( rnd.randn(1, vector_size) ) \n","  return result\n","\n","def generate_images(Gs, seeds, truncation_psi):\n","    noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n","\n","    Gs_kwargs = dnnlib.EasyDict()\n","    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","    Gs_kwargs.randomize_noise = False\n","    if truncation_psi is not None:\n","        Gs_kwargs.truncation_psi = truncation_psi\n","\n","    for seed_idx, seed in enumerate(seeds):\n","        print('Generating image for seed %d/%d ...' % (seed_idx, len(seeds)))\n","        rnd = np.random.RandomState(seed=1)\n","        tflib.set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n","        images = Gs.run(seed, None, **Gs_kwargs) # [minibatch, height, width, channel]\n","        path = f\"/content/tmp/image-{seed_idx}.png\"\n","        PIL.Image.fromarray(images[0], 'RGB').save(path)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ebMczvQuEHJv","colab_type":"text"},"source":["Specify the two seeds that we wish to morph betwen."]},{"cell_type":"code","metadata":{"id":"8jJ8prvsy3am","colab_type":"code","outputId":"840b707b-99ce-4b7d-a01a-90828be43329","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1586286214558,"user_tz":300,"elapsed":371,"user":{"displayName":"Jeff Heaton","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiewnZO_LaxRj3Ya9ykDsaEDK8Rpvu-CVIYpJ97=s64","userId":"18292667475657506830"}}},"source":["sc = dnnlib.SubmitConfig()\n","sc.num_gpus = 1\n","sc.submit_target = dnnlib.SubmitTarget.LOCAL\n","sc.local.do_not_copy_source_files = True\n","sc.run_dir_root = \"/content/drive/My Drive/projects/stylegan2\"\n","sc.run_desc = 'generate-images'\n","network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'\n","\n","print('Loading networks from \"%s\"...' % network_pkl)\n","_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n","vector_size = Gs.input_shape[1:][0]\n","\n","vec = expand_seed( [100,860], vector_size) # Morph between these two seeds\n","\n","print(vec[0].shape)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Loading networks from \"gdrive:networks/stylegan2-ffhq-config-f.pkl\"...\n","(1, 512)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K9sU6g3CETjv","colab_type":"text"},"source":["We can now do a morph over 300 steps."]},{"cell_type":"code","metadata":{"id":"7sUD8c5JCfkg","colab_type":"code","outputId":"406a8aa6-1e6c-45a9-d465-d3c91caad681","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1586286424532,"user_tz":300,"elapsed":207791,"user":{"displayName":"Jeff Heaton","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiewnZO_LaxRj3Ya9ykDsaEDK8Rpvu-CVIYpJ97=s64","userId":"18292667475657506830"}}},"source":["STEPS = 300\n","diff = vec[1] - vec[0]\n","step = diff / STEPS\n","current = vec[0].copy()\n","\n","vec2 = []\n","for i in range(STEPS):\n","  vec2.append(current)\n","  current = current + step\n","\n","temp_path = \"/content/tmp\"\n","\n","# Create a temporary directory to hold video frames\n","try:  \n","  os.mkdir(temp_path)\n","except OSError:  \n","  print(\"Temp dir already exists.\")\n","\n","generate_images(Gs, vec2,truncation_psi=0.5)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Temp dir already exists.\n","Generating image for seed 0/300 ...\n","Generating image for seed 1/300 ...\n","Generating image for seed 2/300 ...\n","Generating image for seed 3/300 ...\n","Generating image for seed 4/300 ...\n","Generating image for seed 5/300 ...\n","Generating image for seed 6/300 ...\n","Generating image for seed 7/300 ...\n","Generating image for seed 8/300 ...\n","Generating image for seed 9/300 ...\n","Generating image for seed 10/300 ...\n","Generating image for seed 11/300 ...\n","Generating image for seed 12/300 ...\n","Generating image for seed 13/300 ...\n","Generating image for seed 14/300 ...\n","Generating image for seed 15/300 ...\n","Generating image for seed 16/300 ...\n","Generating image for seed 17/300 ...\n","Generating image for seed 18/300 ...\n","Generating image for seed 19/300 ...\n","Generating image for seed 20/300 ...\n","Generating image for seed 21/300 ...\n","Generating image for seed 22/300 ...\n","Generating image for seed 23/300 ...\n","Generating image for seed 24/300 ...\n","Generating image for seed 25/300 ...\n","Generating image for seed 26/300 ...\n","Generating image for seed 27/300 ...\n","Generating image for seed 28/300 ...\n","Generating image for seed 29/300 ...\n","Generating image for seed 30/300 ...\n","Generating image for seed 31/300 ...\n","Generating image for seed 32/300 ...\n","Generating image for seed 33/300 ...\n","Generating image for seed 34/300 ...\n","Generating image for seed 35/300 ...\n","Generating image for seed 36/300 ...\n","Generating image for seed 37/300 ...\n","Generating image for seed 38/300 ...\n","Generating image for seed 39/300 ...\n","Generating image for seed 40/300 ...\n","Generating image for seed 41/300 ...\n","Generating image for seed 42/300 ...\n","Generating image for seed 43/300 ...\n","Generating image for seed 44/300 ...\n","Generating image for seed 45/300 ...\n","Generating image for seed 46/300 ...\n","Generating image for seed 47/300 ...\n","Generating image for seed 48/300 ...\n","Generating image for seed 49/300 ...\n","Generating image for seed 50/300 ...\n","Generating image for seed 51/300 ...\n","Generating image for seed 52/300 ...\n","Generating image for seed 53/300 ...\n","Generating image for seed 54/300 ...\n","Generating image for seed 55/300 ...\n","Generating image for seed 56/300 ...\n","Generating image for seed 57/300 ...\n","Generating image for seed 58/300 ...\n","Generating image for seed 59/300 ...\n","Generating image for seed 60/300 ...\n","Generating image for seed 61/300 ...\n","Generating image for seed 62/300 ...\n","Generating image for seed 63/300 ...\n","Generating image for seed 64/300 ...\n","Generating image for seed 65/300 ...\n","Generating image for seed 66/300 ...\n","Generating image for seed 67/300 ...\n","Generating image for seed 68/300 ...\n","Generating image for seed 69/300 ...\n","Generating image for seed 70/300 ...\n","Generating image for seed 71/300 ...\n","Generating image for seed 72/300 ...\n","Generating image for seed 73/300 ...\n","Generating image for seed 74/300 ...\n","Generating image for seed 75/300 ...\n","Generating image for seed 76/300 ...\n","Generating image for seed 77/300 ...\n","Generating image for seed 78/300 ...\n","Generating image for seed 79/300 ...\n","Generating image for seed 80/300 ...\n","Generating image for seed 81/300 ...\n","Generating image for seed 82/300 ...\n","Generating image for seed 83/300 ...\n","Generating image for seed 84/300 ...\n","Generating image for seed 85/300 ...\n","Generating image for seed 86/300 ...\n","Generating image for seed 87/300 ...\n","Generating image for seed 88/300 ...\n","Generating image for seed 89/300 ...\n","Generating image for seed 90/300 ...\n","Generating image for seed 91/300 ...\n","Generating image for seed 92/300 ...\n","Generating image for seed 93/300 ...\n","Generating image for seed 94/300 ...\n","Generating image for seed 95/300 ...\n","Generating image for seed 96/300 ...\n","Generating image for seed 97/300 ...\n","Generating image for seed 98/300 ...\n","Generating image for seed 99/300 ...\n","Generating image for seed 100/300 ...\n","Generating image for seed 101/300 ...\n","Generating image for seed 102/300 ...\n","Generating image for seed 103/300 ...\n","Generating image for seed 104/300 ...\n","Generating image for seed 105/300 ...\n","Generating image for seed 106/300 ...\n","Generating image for seed 107/300 ...\n","Generating image for seed 108/300 ...\n","Generating image for seed 109/300 ...\n","Generating image for seed 110/300 ...\n","Generating image for seed 111/300 ...\n","Generating image for seed 112/300 ...\n","Generating image for seed 113/300 ...\n","Generating image for seed 114/300 ...\n","Generating image for seed 115/300 ...\n","Generating image for seed 116/300 ...\n","Generating image for seed 117/300 ...\n","Generating image for seed 118/300 ...\n","Generating image for seed 119/300 ...\n","Generating image for seed 120/300 ...\n","Generating image for seed 121/300 ...\n","Generating image for seed 122/300 ...\n","Generating image for seed 123/300 ...\n","Generating image for seed 124/300 ...\n","Generating image for seed 125/300 ...\n","Generating image for seed 126/300 ...\n","Generating image for seed 127/300 ...\n","Generating image for seed 128/300 ...\n","Generating image for seed 129/300 ...\n","Generating image for seed 130/300 ...\n","Generating image for seed 131/300 ...\n","Generating image for seed 132/300 ...\n","Generating image for seed 133/300 ...\n","Generating image for seed 134/300 ...\n","Generating image for seed 135/300 ...\n","Generating image for seed 136/300 ...\n","Generating image for seed 137/300 ...\n","Generating image for seed 138/300 ...\n","Generating image for seed 139/300 ...\n","Generating image for seed 140/300 ...\n","Generating image for seed 141/300 ...\n","Generating image for seed 142/300 ...\n","Generating image for seed 143/300 ...\n","Generating image for seed 144/300 ...\n","Generating image for seed 145/300 ...\n","Generating image for seed 146/300 ...\n","Generating image for seed 147/300 ...\n","Generating image for seed 148/300 ...\n","Generating image for seed 149/300 ...\n","Generating image for seed 150/300 ...\n","Generating image for seed 151/300 ...\n","Generating image for seed 152/300 ...\n","Generating image for seed 153/300 ...\n","Generating image for seed 154/300 ...\n","Generating image for seed 155/300 ...\n","Generating image for seed 156/300 ...\n","Generating image for seed 157/300 ...\n","Generating image for seed 158/300 ...\n","Generating image for seed 159/300 ...\n","Generating image for seed 160/300 ...\n","Generating image for seed 161/300 ...\n","Generating image for seed 162/300 ...\n","Generating image for seed 163/300 ...\n","Generating image for seed 164/300 ...\n","Generating image for seed 165/300 ...\n","Generating image for seed 166/300 ...\n","Generating image for seed 167/300 ...\n","Generating image for seed 168/300 ...\n","Generating image for seed 169/300 ...\n","Generating image for seed 170/300 ...\n","Generating image for seed 171/300 ...\n","Generating image for seed 172/300 ...\n","Generating image for seed 173/300 ...\n","Generating image for seed 174/300 ...\n","Generating image for seed 175/300 ...\n","Generating image for seed 176/300 ...\n","Generating image for seed 177/300 ...\n","Generating image for seed 178/300 ...\n","Generating image for seed 179/300 ...\n","Generating image for seed 180/300 ...\n","Generating image for seed 181/300 ...\n","Generating image for seed 182/300 ...\n","Generating image for seed 183/300 ...\n","Generating image for seed 184/300 ...\n","Generating image for seed 185/300 ...\n","Generating image for seed 186/300 ...\n","Generating image for seed 187/300 ...\n","Generating image for seed 188/300 ...\n","Generating image for seed 189/300 ...\n","Generating image for seed 190/300 ...\n","Generating image for seed 191/300 ...\n","Generating image for seed 192/300 ...\n","Generating image for seed 193/300 ...\n","Generating image for seed 194/300 ...\n","Generating image for seed 195/300 ...\n","Generating image for seed 196/300 ...\n","Generating image for seed 197/300 ...\n","Generating image for seed 198/300 ...\n","Generating image for seed 199/300 ...\n","Generating image for seed 200/300 ...\n","Generating image for seed 201/300 ...\n","Generating image for seed 202/300 ...\n","Generating image for seed 203/300 ...\n","Generating image for seed 204/300 ...\n","Generating image for seed 205/300 ...\n","Generating image for seed 206/300 ...\n","Generating image for seed 207/300 ...\n","Generating image for seed 208/300 ...\n","Generating image for seed 209/300 ...\n","Generating image for seed 210/300 ...\n","Generating image for seed 211/300 ...\n","Generating image for seed 212/300 ...\n","Generating image for seed 213/300 ...\n","Generating image for seed 214/300 ...\n","Generating image for seed 215/300 ...\n","Generating image for seed 216/300 ...\n","Generating image for seed 217/300 ...\n","Generating image for seed 218/300 ...\n","Generating image for seed 219/300 ...\n","Generating image for seed 220/300 ...\n","Generating image for seed 221/300 ...\n","Generating image for seed 222/300 ...\n","Generating image for seed 223/300 ...\n","Generating image for seed 224/300 ...\n","Generating image for seed 225/300 ...\n","Generating image for seed 226/300 ...\n","Generating image for seed 227/300 ...\n","Generating image for seed 228/300 ...\n","Generating image for seed 229/300 ...\n","Generating image for seed 230/300 ...\n","Generating image for seed 231/300 ...\n","Generating image for seed 232/300 ...\n","Generating image for seed 233/300 ...\n","Generating image for seed 234/300 ...\n","Generating image for seed 235/300 ...\n","Generating image for seed 236/300 ...\n","Generating image for seed 237/300 ...\n","Generating image for seed 238/300 ...\n","Generating image for seed 239/300 ...\n","Generating image for seed 240/300 ...\n","Generating image for seed 241/300 ...\n","Generating image for seed 242/300 ...\n","Generating image for seed 243/300 ...\n","Generating image for seed 244/300 ...\n","Generating image for seed 245/300 ...\n","Generating image for seed 246/300 ...\n","Generating image for seed 247/300 ...\n","Generating image for seed 248/300 ...\n","Generating image for seed 249/300 ...\n","Generating image for seed 250/300 ...\n","Generating image for seed 251/300 ...\n","Generating image for seed 252/300 ...\n","Generating image for seed 253/300 ...\n","Generating image for seed 254/300 ...\n","Generating image for seed 255/300 ...\n","Generating image for seed 256/300 ...\n","Generating image for seed 257/300 ...\n","Generating image for seed 258/300 ...\n","Generating image for seed 259/300 ...\n","Generating image for seed 260/300 ...\n","Generating image for seed 261/300 ...\n","Generating image for seed 262/300 ...\n","Generating image for seed 263/300 ...\n","Generating image for seed 264/300 ...\n","Generating image for seed 265/300 ...\n","Generating image for seed 266/300 ...\n","Generating image for seed 267/300 ...\n","Generating image for seed 268/300 ...\n","Generating image for seed 269/300 ...\n","Generating image for seed 270/300 ...\n","Generating image for seed 271/300 ...\n","Generating image for seed 272/300 ...\n","Generating image for seed 273/300 ...\n","Generating image for seed 274/300 ...\n","Generating image for seed 275/300 ...\n","Generating image for seed 276/300 ...\n","Generating image for seed 277/300 ...\n","Generating image for seed 278/300 ...\n","Generating image for seed 279/300 ...\n","Generating image for seed 280/300 ...\n","Generating image for seed 281/300 ...\n","Generating image for seed 282/300 ...\n","Generating image for seed 283/300 ...\n","Generating image for seed 284/300 ...\n","Generating image for seed 285/300 ...\n","Generating image for seed 286/300 ...\n","Generating image for seed 287/300 ...\n","Generating image for seed 288/300 ...\n","Generating image for seed 289/300 ...\n","Generating image for seed 290/300 ...\n","Generating image for seed 291/300 ...\n","Generating image for seed 292/300 ...\n","Generating image for seed 293/300 ...\n","Generating image for seed 294/300 ...\n","Generating image for seed 295/300 ...\n","Generating image for seed 296/300 ...\n","Generating image for seed 297/300 ...\n","Generating image for seed 298/300 ...\n","Generating image for seed 299/300 ...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6fC8Sl-B9cx2","colab_type":"text"},"source":["We are now ready to build the video."]},{"cell_type":"code","metadata":{"id":"17C7u6VG27aE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":521},"outputId":"4664c27c-3d5e-4cf7-a2d1-5f5e6bf1bbe7","executionInfo":{"status":"ok","timestamp":1586286433720,"user_tz":300,"elapsed":7992,"user":{"displayName":"Jeff Heaton","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiewnZO_LaxRj3Ya9ykDsaEDK8Rpvu-CVIYpJ97=s64","userId":"18292667475657506830"}}},"source":["! ffmpeg -r 30 -i /content/tmp/image-%d.png -vcodec mpeg4 -y /content/gan_morph.mp4"],"execution_count":47,"outputs":[{"output_type":"stream","text":["ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, image2, from '/content/tmp/image-%d.png':\n","  Duration: 00:00:12.00, start: 0.000000, bitrate: N/A\n","    Stream #0:0: Video: png, rgb24(pc), 1024x1024, 25 fps, 25 tbr, 25 tbn, 25 tbc\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (png (native) -> mpeg4 (native))\n","Press [q] to stop, [?] for help\n","Output #0, mp4, to '/content/gan_morph.mp4':\n","  Metadata:\n","    encoder         : Lavf57.83.100\n","    Stream #0:0: Video: mpeg4 (mp4v / 0x7634706D), yuv420p, 1024x1024, q=2-31, 200 kb/s, 30 fps, 15360 tbn, 30 tbc\n","    Metadata:\n","      encoder         : Lavc57.107.100 mpeg4\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n","frame=  300 fps= 46 q=31.0 Lsize=     841kB time=00:00:09.96 bitrate= 691.6kbits/s speed=1.51x    \n","video:839kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.251075%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"spGj_vdlEpu2","colab_type":"text"},"source":["Download the video."]},{"cell_type":"code","metadata":{"id":"VzB7wSUH3MIC","colab_type":"code","colab":{}},"source":["files.download('/content/gan_morph.mp4')"],"execution_count":0,"outputs":[]}]}