{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdahG1GhAw3n"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/present/blob/master/youtube/colab/colab_starting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf9vlqXGeW4F"
      },
      "source": [
        "# CoLab Benchmarking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import psutil\n",
        "\n",
        "def human_size(bytes, units=[' bytes','KB','MB','GB','TB', 'PB', 'EB']):\n",
        "  return str(bytes) + units[0] if bytes < 1024 else human_size(bytes>>10, units[1:])\n",
        "\n",
        "mem = psutil.virtual_memory().total\n",
        "free_mem = psutil.virtual_memory().available\n",
        "hdd = psutil.disk_usage('/content/')\n",
        "\n",
        "print(f\"CPU Count: {os.cpu_count()}\")\n",
        "print(f\"Memory: {human_size(mem)}\")\n",
        "print(f\"Free Memory: {human_size(free_mem)}\")\n",
        "print(f\"HD Total: {human_size(hdd.total)}\")\n",
        "print(f\"HD Used: {human_size(hdd.used)}\")\n",
        "print(f\"HD Free: {human_size(hdd.free)}\")\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "devices = device_lib.list_local_devices()\n",
        "\n",
        "\n",
        "for d in devices:\n",
        "    t = d.device_type\n",
        "    name = d.physical_device_desc\n",
        "    l = [item.split(':',1) for item in name.split(\", \")]\n",
        "    name_attr = dict([x for x in l if len(x)==2])\n",
        "    dev = name_attr.get('name', 'Unnamed device')\n",
        "    print(f\" {d.name} || {dev} || {t} || {human_size(d.memory_limit)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_2gWAocBIoz",
        "outputId": "542cc46c-ebc9-4d0c-9bd8-33f196e80f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Count: 8\n",
            "Memory: 51GB\n",
            "Free Memory: 49GB\n",
            "HD Total: 166GB\n",
            "HD Used: 43GB\n",
            "HD Free: 123GB\n",
            " /device:CPU:0 || Unnamed device || CPU || 256MB\n",
            " /device:GPU:0 ||  Tesla V100-SXM2-16GB || GPU || 14GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google CoLab Free\n",
        "(as of 2021-12-20)\n",
        "\n",
        "* CPU Count: 2\n",
        "* Memory: 12GB\n",
        "* Free Memory: 11GB\n",
        "* HD Total: 78GB\n",
        "* HD Used: 43GB\n",
        "* HD Free: 34GB\n",
        "*  /device:CPU:0 || Unnamed device || CPU || 256MB\n",
        "*  /device:GPU:0 ||  Tesla K80 || GPU || 10GB"
      ],
      "metadata": {
        "id": "Yoh-49Em7vOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google CoLab Pro (Standard)\n",
        "(as of 2021-12-20)\n",
        "\n",
        "* CPU Count: 2\n",
        "* Memory: 12GB\n",
        "* Free Memory: 11GB\n",
        "* HD Total: 166GB\n",
        "* HD Used: 42GB\n",
        "* HD Free: 124GB\n",
        "*  /device:CPU:0 || Unnamed device || CPU || 256MB\n",
        "*  /device:GPU:0 ||  Tesla P100-PCIE-16GB || GPU || 15GB"
      ],
      "metadata": {
        "id": "z66PQoOnlI_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google CoLab Pro (High-RAM)\n",
        "(as of 2021-12-20)\n",
        "\n",
        "* CPU Count: 4\n",
        "* Memory: 25GB\n",
        "* Free Memory: 24GB\n",
        "* HD Total: 166GB\n",
        "* HD Used: 42GB\n",
        "* HD Free: 124GB\n",
        "*  /device:CPU:0 || Unnamed device || CPU || 256MB\n",
        "*  /device:GPU:0 ||  Tesla P100-PCIE-16GB || GPU || 15GB"
      ],
      "metadata": {
        "id": "qZo3h7nrmedF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google CoLab Pro+ (Standard)\n",
        "(as of 2021-12-20)\n",
        "\n",
        "* CPU Count: 2\n",
        "* Memory: 12GB\n",
        "* Free Memory: 11GB\n",
        "* HD Total: 166GB\n",
        "* HD Used: 42GB\n",
        "* HD Free: 124GB\n",
        "*  /device:CPU:0 || Unnamed device || CPU || 256MB\n",
        "*  /device:GPU:0 ||  Tesla V100-SXM2-16GB || GPU || 14GB"
      ],
      "metadata": {
        "id": "DnZKQzrQJQCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google CoLab Pro+ (High-RAM)\n",
        "(as of 2021-12-20)\n",
        "\n",
        "* CPU Count: 8\n",
        "* Memory: 51GB\n",
        "* Free Memory: 49GB\n",
        "* HD Total: 166GB\n",
        "* HD Used: 43GB\n",
        "* HD Free: 123GB\n",
        "*  /device:CPU:0 || Unnamed device || CPU || 256MB\n",
        "*  /device:GPU:0 ||  Tesla V100-SXM2-16GB || GPU || 14GB"
      ],
      "metadata": {
        "id": "nJupQZN7K48n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJUCBt5IHH0t",
        "outputId": "30709bf9-6aab-4a6a-c25a-3dc4637699fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 20 23:11:07 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9GDFaQ_eZoA",
        "outputId": "1adad981-b3bd-4ce4-c055-76cd52393ef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.7.0\n",
            "Pytorch Version: 1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"Pytorch Version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj9pnqzwezbw"
      },
      "source": [
        "# Installing Libraries\n",
        "\n",
        "Installing something not already included:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGp5uoxde2r9",
        "outputId": "1660a617-3d14-48c6-a67f-0f5cdade877e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ninja\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/de/393468f2a37fc2c1dc3a06afc37775e27fde2d16845424141d4da62c686d/ninja-1.10.0.post2-py3-none-manylinux1_x86_64.whl (107kB)\n",
            "\r",
            "\u001b[K     |███                             | 10kB 11.6MB/s eta 0:00:01\r",
            "\u001b[K     |██████                          | 20kB 16.9MB/s eta 0:00:01\r",
            "\u001b[K     |█████████▏                      | 30kB 10.4MB/s eta 0:00:01\r",
            "\u001b[K     |████████████▏                   | 40kB 7.8MB/s eta 0:00:01\r",
            "\u001b[K     |███████████████▎                | 51kB 5.3MB/s eta 0:00:01\r",
            "\u001b[K     |██████████████████▎             | 61kB 6.0MB/s eta 0:00:01\r",
            "\u001b[K     |█████████████████████▍          | 71kB 5.8MB/s eta 0:00:01\r",
            "\u001b[K     |████████████████████████▍       | 81kB 6.1MB/s eta 0:00:01\r",
            "\u001b[K     |███████████████████████████▍    | 92kB 6.4MB/s eta 0:00:01\r",
            "\u001b[K     |██████████████████████████████▌ | 102kB 5.1MB/s eta 0:00:01\r",
            "\u001b[K     |████████████████████████████████| 112kB 5.1MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.0.post2\n"
          ]
        }
      ],
      "source": [
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxNZ9_Z2fV2W"
      },
      "source": [
        "# UNIX Commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4GS9LgAfUBZ",
        "outputId": "540c9322-00d8-4509-b7c3-950067513454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         226G   39G  188G  18% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "shm             5.9G     0  5.9G   0% /dev/shm\n",
            "tmpfs           6.4G   24K  6.4G   1% /var/colab\n",
            "/dev/sda1       233G   41G  192G  18% /etc/hosts\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ],
      "source": [
        "!df -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_DQhD8Cf62T",
        "outputId": "cd66f7ed-5cf8-4471-910a-9385826a09da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "anscombe.json\t\t      mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  README.md\n"
          ]
        }
      ],
      "source": [
        "!ls /content/sample_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmj4SR5Ae8S2"
      },
      "source": [
        "# Uploading and Downloading Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm6366n4fCue"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for k, v in uploaded.items():\n",
        "  _, ext = os.path.splitext(k)\n",
        "  print(f\"You uploaded /content/{k}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vCuEl_VcfDUo",
        "outputId": "bbc2cb14-72f2-401f-f209-bb307d773875"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_35b6c591-758a-4506-875c-2db50c5c2691\", \"README.md\", 930)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/sample_data/README.md\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts-K7FUXgJb6"
      },
      "source": [
        "# Accessing GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX3x4GjDgRo3",
        "outputId": "71d7c6d7-4a38-481d-93f8-5d4d52d24ee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google GDrive\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"Note: using Google GDrive\")\n",
        "except:\n",
        "    print(\"Error, could not mount GDrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF_LpsxqgkH3",
        "outputId": "0f4783c8-c907-4290-b565-0733c496a703"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MyDrive\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI1_0l6XxTZD"
      },
      "source": [
        "# Preventing Timeouts\n",
        "\n",
        "For more information, see: [Google Colab session timeout](https://stackoverflow.com/questions/54057011/google-colab-session-timeout)\n",
        "\n",
        "\n",
        "```\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "colab_starting.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}