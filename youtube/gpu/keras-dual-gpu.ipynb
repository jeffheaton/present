{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/present/blob/master/youtube/gpu/keras-dual-gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jeff Heaton\n",
    "\n",
    "You can follow me at any of:\n",
    "\n",
    "* [YouTube](https://www.youtube.com/user/HeatonResearch)\n",
    "* [Website](https://www.heatonresearch.com/)\n",
    "* [GitHub](https://github.com/jeffheaton)\n",
    "* [Twitter](https://twitter.com/jeffheaton)\n",
    "\n",
    "\n",
    "## Multi-GPU Support\n",
    "\n",
    "Keras makes it easy to use more than one GPU for neural network training or scoring. This tutorial shows how to train a model for the [Cats vs Dogs](https://www.kaggle.com/c/dogs-vs-cats) dataset. Not all models will necessarily benefit from multiple GPUs.  Generally larger batch sizes and more complex neural networks benefit from multiple GPUs.\n",
    "\n",
    "The technique presented in this notebook can train with between 1 and 8 GPUs on a single host.  It is also possable to train larger numbers of GPUs on multiple hosts; however, a slightly different approach is needed. \n",
    "\n",
    "First, we will list what GPUs are available on the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /device:CPU:0 || Unnamed device || CPU || 256.0 MiB\n",
      " /device:XLA_CPU:0 || Unnamed device || XLA_CPU || 16.0 GiB\n",
      " /device:GPU:0 ||  RTX A6000 || GPU || 1.3 GiB\n",
      " /device:XLA_GPU:0 || Unnamed device || XLA_GPU || 16.0 GiB\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "devices = device_lib.list_local_devices()\n",
    "\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for d in devices:\n",
    "    t = d.device_type\n",
    "    name = d.physical_device_desc\n",
    "    l = [item.split(':',1) for item in name.split(\", \")]\n",
    "    name_attr = dict([x for x in l if len(x)==2])\n",
    "    dev = name_attr.get('name', 'Unnamed device')\n",
    "    print(f\" {d.name} || {dev} || {t} || {sizeof_fmt(d.memory_limit)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Cats vs Dogs Dataset\n",
    "\n",
    "First, we obain the Cats vs Dogs dataset.  We use the [tensorflow_datasets](https://www.tensorflow.org/datasets) library access this data. Any data can be used, **tensorflow_datasets** makes loading common datasets a simple process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "GPUS = [\"GPU:0\"]\n",
    "\n",
    "def process(image, label):\n",
    "    image = tf.image.resize(image, [299, 299]) / 255.0\n",
    "    return image, label\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy( GPUS )\n",
    "print('Number of devices: %d' % strategy.num_replicas_in_sync) \n",
    "\n",
    "batch_size = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "\n",
    "dataset = tfds.load(\"cats_vs_dogs\", split=tfds.Split.TRAIN, as_supervised=True)\n",
    "dataset = dataset.map(process).shuffle(500).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Distributed Training\n",
    "\n",
    "Training with multiple GPUs is not much different than training with a single GPU.  Wrapping the model creation and compilation with a mirror strategy scope is all that is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "EPOCHS = 5\n",
    "LR = 0.001 \n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "start = time.time()\n",
    "with strategy.scope():\n",
    "    model = tf.keras.applications.InceptionResNetV2(weights=None, classes=2)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
    "    )\n",
    "\n",
    "model.fit(dataset, epochs=EPOCHS)\n",
    "\n",
    "elapsed = time.time()-start\n",
    "print (f'Training time: {hms_string(elapsed)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 13:03.89 - Single A100\n",
    "* 15:54.81 - Dual Quadro RTX 8000\n",
    "* 18:30.76 - Single RTX A6000\n",
    "* 24:17.07 - Single TITAN RTX\n",
    "* 24:48.10 - Single Tesla V100-SXM2-16GB\n",
    "* 26:23.19 - Single Quadro RTX 8000\n",
    "* 37:48.45 - Single Tesla P100-PCIE-16GB\n",
    "* 50:36.50 - Single Quadro RTX 5000\n",
    "* 1:10:08.54 - Single Tesla T4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/5\n",
    "364/364 [==============================] - 453s 1s/step - loss: 0.5174 - sparse_categorical_accuracy: 0.7493\n",
    "Epoch 2/5\n",
    "364/364 [==============================] - 301s 826ms/step - loss: 0.2556 - sparse_categorical_accuracy: 0.8929\n",
    "Epoch 3/5\n",
    "364/364 [==============================] - 309s 848ms/step - loss: 0.1792 - sparse_categorical_accuracy: 0.9267\n",
    "Epoch 4/5\n",
    "364/364 [==============================] - 306s 842ms/step - loss: 0.1344 - sparse_categorical_accuracy: 0.9452\n",
    "Epoch 5/5\n",
    "364/364 [==============================] - 307s 844ms/step - loss: 0.1104 - sparse_categorical_accuracy: 0.9571\n",
    "Training time: 0:30:46.31\n",
    "\n",
    "8000\n",
    "Epoch 1/5\n",
    "364/364 [==============================] - 178s 489ms/step - sparse_categorical_accuracy: 0.7405 - loss: 0.5237\n",
    "Epoch 2/5\n",
    "364/364 [==============================] - 180s 494ms/step - sparse_categorical_accuracy: 0.8725 - loss: 0.2928\n",
    "Epoch 3/5\n",
    "364/364 [==============================] - 179s 492ms/step - sparse_categorical_accuracy: 0.9205 - loss: 0.1900\n",
    "Epoch 4/5\n",
    "364/364 [==============================] - 179s 491ms/step - sparse_categorical_accuracy: 0.9402 - loss: 0.1445\n",
    "Epoch 5/5\n",
    "364/364 [==============================] - 178s 490ms/step - sparse_categorical_accuracy: 0.9536 - loss: 0.1136\n",
    "Training time: 0:16:14.80\n",
    "\n",
    "Epoch 1/5\n",
    "727/727 [==============================] - 310s 427ms/step - loss: 0.5647 - sparse_categorical_accuracy: 0.7119\n",
    "Epoch 2/5\n",
    "727/727 [==============================] - 308s 424ms/step - loss: 0.3291 - sparse_categorical_accuracy: 0.8558\n",
    "Epoch 3/5\n",
    "727/727 [==============================] - 307s 422ms/step - loss: 0.2029 - sparse_categorical_accuracy: 0.9166\n",
    "Epoch 4/5\n",
    "727/727 [==============================] - 306s 421ms/step - loss: 0.1567 - sparse_categorical_accuracy: 0.9347\n",
    "Epoch 5/5\n",
    "727/727 [==============================] - 306s 421ms/step - loss: 0.1300 - sparse_categorical_accuracy: 0.9469\n",
    "Training time: 0:26:23.19"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
